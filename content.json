{"pages":[{"title":"About","text":"Hi! I’m Shiyu Liu, a current graduate student in Columbia Univeristy. My main interest includes full-stack development, big data analysis and cloud computing. I hava many experiences in Angular, Node.js, Flask, Postgres, MongoDB, Spark and AWS. I once interned in Huawei Technologies Co., Ltd. and participated in developing an integrated testing web application using Angular and jQuery. I also fulfilled building several full-stack or serverless websites using different technique stacks. I’m now looking for full time SDE job.Below is my resume! Feel free to contact me at sl4401@columbia.edu!PDF VERSION - last updated at 2019.9.13PDF版本 - 上一次更新在2019.9.13","link":"/about/index.html"}],"posts":[{"title":"Behavior Questions","text":"Behavior QuestionsThe STAR format stands for Situation, Task, Action, Result: Situation: An event, project, or challenge facedTask: Your responsibilities and assignments for the situationAction: Steps or procedure taken to relieve or rectify situationResult: Results of actions taken. Amazon leadership principles:Leadership PrinciplesWe use our Leadership Principles every day, whether we’re discussing ideas for new projects or deciding on the best approach to solving a problem. It is just one of the things that makes Amazon peculiar. Customer ObsessionLeaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. Although leaders pay attention to competitors, they obsess over customers. OwnershipLeaders are owners. They think long term and don’t sacrifice long-term value for short-term results. They act on behalf of the entire company, beyond just their own team. They never say “that’s not my job.” Invent and SimplifyLeaders expect and require innovation and invention from their teams and always find ways to simplify. They are externally aware, look for new ideas from everywhere, and are not limited by “not invented here.” As we do new things, we accept that we may be misunderstood for long periods of time. Are Right, A LotLeaders are right a lot. They have strong judgment and good instincts. They seek diverse perspectives and work to disconfirm their beliefs. Learn and Be CuriousLeaders are never done learning and always seek to improve themselves. They are curious about new possibilities and act to explore them. Hire and Develop the BestLeaders raise the performance bar with every hire and promotion. They recognize exceptional talent, and willingly move them throughout the organization. Leaders develop leaders and take seriously their role in coaching others. We work on behalf of our people to invent mechanisms for development like Career Choice. Insist on the Highest StandardsLeaders have relentlessly high standards — many people may think these standards are unreasonably high. Leaders are continually raising the bar and drive their teams to deliver high quality products, services, and processes. Leaders ensure that defects do not get sent down the line and that problems are fixed so they stay fixed. Think BigThinking small is a self-fulfilling prophecy. Leaders create and communicate a bold direction that inspires results. They think differently and look around corners for ways to serve customers. Bias for ActionSpeed matters in business. Many decisions and actions are reversible and do not need extensive study. We value calculated risk taking. FrugalityAccomplish more with less. Constraints breed resourcefulness, self-sufficiency, and invention. There are no extra points for growing headcount, budget size, or fixed expense. Earn TrustLeaders listen attentively, speak candidly, and treat others respectfully. They are vocally self-critical, even when doing so is awkward or embarrassing. Leaders do not believe their or their team’s body odor smells of perfume. They benchmark themselves and their teams against the best. Dive DeepLeaders operate at all levels, stay connected to the details, audit frequently, and are skeptical when metrics and anecdote differ. No task is beneath them. Have Backbone; Disagree and CommitLeaders are obligated to respectfully challenge decisions when they disagree, even when doing so is uncomfortable or exhausting. Leaders have conviction and are tenacious. They do not compromise for the sake of social cohesion. Once a decision is determined, they commit wholly. Deliver ResultsLeaders focus on the key inputs for their business and deliver them with the right quality and in a timely fashion. Despite setbacks, they rise to the occasion and never settle. Common questions:Tell me about yourself/ Tell me about your background?/Introduce yourselfMy name is Shiyu liu, a current graduate student in Columbia University. My main interests include full-stack development, cloud computing and big data analysis. I have a lot of experiences in web development using different technique stacks. In this summer I worked in test tools development team in huawei and developed a micro-service tesing web application using Angular and jQuery and my overall output codes are more than 2000 lines. (Job description and good fit). I believe that my previous experiences in software engineering and programming could help me succeed in this job. Why Amazon/ Why you are interested in our company? /Why do you think you are a good fit to our company? /Why did you apply? /Why should we hire you?/What makes you the best candidate?Firstly, amazon is one of the most impactful leading tech companies in the world. Amazon’s products are changing everyone’s daily life everyday. So it will be a great pleasure for me to join such a great company and make my small impact to the world.Seconly, I used amazon’s products by myself, like amazon prime and AWS. They are easy to use and I always felt surprised by its creativity and innovation. I’m pretty sure that there are so many clever and creative engineers working in Amazon so that working with these smart guys would a great enjoy for me and I could also learn a lot from them.Finally, My previous experiences have proved my stong background and ability in software development and programming. And I’m also confident that I’m a easy going and anbixious guy. THus I’m sure that I’m a good fit for the software engineer position in Amazon. Why switching major?In my undergraduate study, I have a lot of programming experiences in embedded system using C and C++. Those lower level programming experiences makes me love coding. My focus in columbia is electrical engineering in data driven which has a lot of chance to write web applications and mobile apps and I found they are very interesting and I really enjoy the feeling of creating my own applications. Thus I switch my direction and choose higher level programming. Introduce one of your past project?I’d like to introduce my project in my internship this summer. I worked in testing tools development team and our main job is to develop a micro-service testing web application for our hardware engineers. The main technique stacks we used are Angular, jQuery and Spring boot.What I’m resiponsible for in my intern is one of the apps of our web application - test report App. Its main function is to provide the testing result report for different hradwares. The overall output code in production environment is over 2000 lines.I also did some optimization for our web page and encapsulated some frequently used components in our angular framework. Tell me about a time you had to deal with tight deadline and you were able/not able to meet the target? / What most challenging things in this project? /Tell me about a difficulties situation you ever meet?/ fast learing experiences/ learn something new by yourself I initially did backend jobs in my internship and then my supervisor wanted me to change to frontend part. I have no idea of Angular framework before and I have to learn fast and start to develop the web page as quickly as possible because the deadline is approaching. I used half-day to search for the imformation of Angular on google and blogs and I also discussed with my mentor and team members who are responsible for frontend part. They gave me many useful suggestions on how to learn angular fast and solidly. Then I decided to watch one of high-rating udemy Angular course combined with the inner quick-start documentation. When I watches the video, I’m not just watch it, I would like to type the code following the teacher and make my own notes. To speed up, I also watched and practise at night and at the weekend. On the next Monday, I told my supervisor I’m ready for doing some small features. So I started from small features to large features. When I met something I don’t know in my study and development. I would like to first to search online and also read previous code wrote by others and if I still can not solve it, I would like to share what I thought with my team members and after discussion, I can always solve the problem. Finally I developed the whole test report page by myself successfully and the overall code is over 2000 lines in production environment and used by many hardware engineers. 项目进展的很慢怎么办？ /队友坑，队友不contribute怎么办? /帮同事，同学分担任务的经历 I think that happens sometimes and I do meet this situation. I will use one of my experience to show how I will solve this problem. In my big data analysis course work, my team members always can not finished their jobs which we have planed. So I firstly have a relex talk and discussion with my team members to know their reasons why they can not make a good contribution to the project, it’s because they have other deadline or they are not familiar with the topic. After talking, I know that they indeed have some other deadlines and they are not familiar with some part of their content. Secondly, I together with them made a more specific and suitable plan for us. I arranged the harder part jobs for my own because at that time I do not have other deadlines, but that did not mean I would do all the part of the project because I know it is a team project. One’s strength can never beat three’s. I also appointed to meet with them three times a week to see the update of all our work. Finally, I just try my best to do my part well and in our meeting, I would like to share my thoughts and also listen to their suggestions to revise my part. I also helped them on where they get confused woth their parts. We three graduatelly worked more like a team and after a final night’s job, we finished our project and get a high estimate from our professor. This is really an unforgetable memory for me. Tell me about a project that you had failed Tell me about a time you had conflict with your manager/peer/colleagues As a software engineer, I think this situation always happens. There are always some trade-offs between different solutions and it’s very normal to have conflict with team members. I think the key point here is that we are a team adn we all want to create great software for the company. So maybe choosing a relax environment and have a deep talk with whom has a conflit with me is a good choice. In my internship, I have confilct with my manager whether we should choose to use synchronise or asynchronise way to load resource tree. My manager is a litter busy and I did not want to waste our time. So I make a concret detailed comparation for these two solution and invite my manager to have a lunch. At a very relax environemnt, we just share out thoughts and discussed the pros and cons of different solutions. And after the lunch, we reached an agreement and finished that application well. We choose to use asychronised way since it is better for customer user experience. Your strength learn new things fast good communication skills and a good team member. Always willing to share my thoughts with other colleagues and discuss with them. I think I can always learn from others’ ideas. make plan and split large problem into small pieces Your weaknessCompared many computer science students, My foundation may not as good as them. However, I have proved to be a fast learner and I learned a lot of Computer science courses in Columbia. Whenever I found I lack some knowledge, I would like to do a fully search and read materials and lean it. Tell me about a time you took risk and succeed/failed Tell me about a time you come up with a simple solution to a complex problemTell me about a time you come up with a new approach to an old problem Tell me about a time you received negative feedback from your managerTell me about a time you made a decision without your manager’s approvalTell me about a time you had to make a decision when there is not enough data or informationTell me about a time you were assigned a project with unclear responsibilityTell me about a time you had to sacrifice short term gains for the long term goalsTell me about a time you were 50%/75% on a project and found you have made a mistake and have to change directionTell me about a time you came up with a solution that customer didn’t ask and they end up like itTell me about a time that customer tell you they want something but you know that’s not really what they wantTell me about a time you had to convince the team/convinced by the teamTell me about a project that you have to overcome big obstacleTell me about an experience that you have to earn trust/gain buy-in from another groupTell me about a time you step outside of your job scope and solved a problemWhat is your proudest/biggest innovationHow do you select metric to measure your project successHave you ever learn something new by yourself and end up using what you learn to solve problems at workIf you have conflicting goals, how do you make trad-offTell me about a time you have to seek outside help to dive deep on a problem to find the solutionTell me about a time you decided to take on a project instead of being assigned to you Experiences Huawei Intership:Situation:I worked in Huawei Technologies this summer and my team developed a micro-service testing web application for our hardware engineers and the main technique stacks are Angular and Spring boot. Task:The main job I did is to develop the test report module which shows the users test report for different hardwares. Action:The first difficulty for me here is that I have no idea of Angular framework before and I have to learn fast and start to develop the web page as quickly as possible. Thus I used half-day to search for the imformation of Angular on google and blogs and also discussed my supervisor on how to learn it quickly. Then I decided to watch one of high-rating udemy Angular course combined with the inner quick-start documentation. When I watches the video, I’m not just watch it, I would like to type the code following the teacher and make my own notes. To speed up, I also watched and practise at night and at the weekend. On the next Monday, I told my supervisor I’m ready for doing some small features. So I started from small features to large features and finally developed the whole test report page by myself. The second difficulty for me is that for the Harware Polymorph test report page, I need to make request to Hardware Polymorph API because different polymorph of a single harware may have different test results. However, for this API, the company does not have a good documentation and colleague responsible for this interface only provide me a simple example but the usage is actually very complex. So I make a inner phone call with this colleague and discussed with him. But since this API is only one of thousands API of the hardware testing result. He can not give detailed infos. So the colleague can not give a huge help. Then I visited our old version testing website and found that this API is also used in old version. So I contact the colleague responsible for old version website and discussed with her and she told me the one who wrote this part has left the company, but maybe I can use the old version website to call API and see the backend log file. So I together with her examined and clicked the old version website and analysed relationship between log and behouvior and finally summarize the usage of this API and finally finished Polymorph test report part. Result:The overall code is more than 2000 and they have been deployed to our production.Make a note for this API, give it to the colleague resipnsible for this API and also uploaded on inner blog of the company. 这个project 是你自己发掘的还是被指派的 怎么发掘的THis projoect is assigned by my supervisor. But When I developing this test report module, I also discovered some addtional tasks. For example, when I write the share to user component of web page which can share select information to other team members, I found that this function also exists in many places in our whole application. So I discussed with my supervisor and decided to encapsulated it into huawei’s angular framework which wiil be a good benefits for future work.过程中有哪些人参与, 他们的反应如何, 如果反应不好你怎么说服他们 他们对你的说服反应如何除了你的解法以外 有没有想过其他解法 为什么选你这个解法这个project 除了你提到的immediate results 以外 对公司整体的帮助是什么The components added into the huawei’s angular framework and it helps to improve the work efficiency when someone else meet the same requierment. They can use them easily and directly.你如何判断这个project 成功了/完成了/失败了比较难的follow up, 叫你讲一个跟刚刚完全相反的故事 例如刚刚问你 “Tell me about a time you took risk and succeed” 就变成 “Tell me about a time you took risk and failed” 或者我遇到的 “Tell me about a time that you convinced a group to follow your idea”变成 “Tell me about a time you were convinced by the team and gave up your idea” Restaurant Reservation Serverless Website.SituationThis is the coursework of our cloud computing courses and our goal is to utilize AWS tools to design a serverless wev application.TaskWe have three team members(One for recoomendation and crawl, one for front end) and my main job is for the backend of this serverless website.ActionThe first dilemma I meet is we want to use many tools in AWS and the communication between them are a kind of complex. The way I solve it is to firstly draw a detailed flow chart to make it more clear. Secondly I read all the related documents of tools we want to use on the AWS and write small demos of each tools to understood their usage because some of them are not easy to learn(like API Gateway) and finally use the result of last two steps to build our application and debug. ResultWe finally design a very beatiful websites. I learned a lot from this process, like mant tools in AWS. I also learn a lot from my teammates, they are patient, smart and collaorative. We finally get A score in this course. Movie Recommendation Web Application.Situation:This is the course work in our database course. Our main mission is to develop a website with relational database - postgres from scratch. Each team has two people and I collabrate with my parter for the whole project. Task:So the first step is to design the ER diagram, then turn them into realtional tables in postgres and finally develop a beautiful website to utilize the database we created. Action:The first problem we met is when we inserting our data into database, the real world data are not so optimized, our realtional databse has a lot of constrains and they may not have a good match with our table we designed. So it is very hard for us to insert the real data into our database perfectly. So we discussed and hesitate whether we should give up and just put fake data into it because the course does not reauire us to do that and the main point is to teach us how to use a relational database. But both of us did not want to give up because we hoped we can finally develop a pratical and real website but not something useless. So we continue refining our table and dataset and worked until very late and finally succeed.The second problem we met is that both of us do not have expereinces builing web application using falsk and jquery. We need to learn fast and finished the project in a few days. So we divide the job and I mainly focus on the backend and he focuse on frontend. Result:We finally designed a very beatiful website and get A in this course finally. TAs said they really like our web because it uses the real-world data and is a real application.","link":"/2019/09/28/Behavior%20Questions/"},{"title":"系统设计慢慢总结","text":"Design Search Autocomplete Systemhttps://www.youtube.com/watch?v=uIqvbYVBiCI","link":"/2019/11/20/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%85%A2%E6%85%A2%E6%80%BB%E7%BB%93/"},{"title":"CSAPP","text":"Representing and Manipulating InformationInformation Storage 计算机程序把计算机的内存看成一段非常大的bytes数组，这个连续的bytes数组被称为虚拟内存(virtual memory)。虚拟内存的每一个byte都会被一个唯一的数字表示，这个数字称为这块内存的地址。所有的地址组成的集合被称为虚拟地址空间(virtual address space) Data Sizes 每一台计算机都有一个字长(word size)，它指明了指针的大小(也就是地址的长度)，所以通过字长可以判断一台机器的虚拟地址空间的最大大小。比如一台机器的字长是w bit，那么它的虚拟地址的范围就是0到2的w次方减1。 需要明确的是，本书中默认地址字长和数据子长是相等的，所以统一用字长表示，但其实很多CPU的地址总线与数据总线不一样长，虚拟地址的范围是由地址字长决定的。比如早期8086CPU有16位数据总线，但是有20位地址总线，那么它的最大虚拟地址空间是2的20次方，也就是1MB。当然这里还有一个问题就是数据总线只有16位，我们从寄存器中取出的地址只有16位，这个时候需要通过段寄存器进行地址偏移来得到最后的20位地址。 C语言中定义的变量在32位和64位机器中可能有不同的长度，比如long在32位机器中是4个字节，但是在64位机器中是8个字节。如果想要确保所使用类型的字节大小，可以使用int32_t这种固定长度的自定义类型。 Addressing and Byte Ordering 对于跨越多个字节的程序对象，我们需要建立两条规则：我们使用多个字节中的哪一个表示这个对象？如何在内存中排列这些字节？ 对于第一条规则，现在计算机会将多字节对象存储为一块连续的字节序列，并且使用最小的地址作为整个对象的地址。比如一个int型的变量的地址是0x100，那么代表这个int变量会被存放在0x100，0x101，0x102，0x103这段连续的内存中。 对于第二条规则，现在计算机有两种排列方式，分别是大端存储(big endian)和小端存储(little endian)。大端存储指的是对象的高位字节先存储，小端储存指的是对象的低位字节先存储。假设我们要在0x100的地址处存储一个0x01234567的int变量，下面是例子：1230x100 0x101 0x102 0x10301 23 45 67 大端67 45 23 01 小端 大小端存储并没有好坏之分，只是对于多字节对象的存储排列形式不同而已，但是在某些情况下，我们需要注意大小端，常见的有C语言中的类型转换和union。假设我在一块内存中定义了一个int变量，并且将其强制类型转换为char[]数组，那么这个时候大小端排列就对char[]数组中存储的值有影响。 Introduction to Boolean Algebra a^b代表逻辑异或，异或只有在a和b一个为0一个为1时，结果才为1，否则为0。异或有一些有趣的性质，a^a = 0并且异或符合交换律，所以我们可以得出(a^b)^a = b。 布尔运算的另一个应用是可以表示集合运算，假设一个位向量a = [01101001]表示集合A = {0, 3, 5, 6}，另一个位向量b = [01010101]表示集合B = {0, 2, 4, 6}，这个时候或运算相当于取并集，与运算相当于取交集。计算机网络中的子网掩码就是一个与运算的应用。 Shift Operations in C x &lt;&lt; k表示将x按位左移k位，丢掉最高的k位，将最低的k位补0 x &gt;&gt; k表示将x按位右移k位，但是对于右移，我们常常将其分为逻辑右移和算术右移。逻辑右移指的是向右移动k位以后，在高位全部补位0；算数右移指的是向右移动k位后，在高位全部补上原本变量的最高位(0或者1)。 对于有符号数，大多数编译器都会使用算数右移，而对于无符号数，编译器会使用逻辑右移。在Java中，&gt;&gt;表示算术右移，&gt;&gt;&gt;逻辑右移。 Integer RepresentationsUnsigned Encodings 无符号数的编码很容易理解，能够编码的范围是0到2的w次方(w是字长) Two’s Complement Encodings 无符号数的编码无法表示负数，补码的存在是为了表示负数。补码所表示的数的第一位叫做符号位，它在计算时的权重是负的，所以如果一个4位的补码整数1000表示的是-8。 由于补码第一位的权重是负的，其他位的权重都是正的，所以用补码表示负数时，1000表示最小的负数-8，1111表示最大的负数-1。即使当位数增加的时候，111...111永远代表的是-1。 补码所能表示的负数比正数多一个，这是因为二进制能表示的数都是2的倍数，但是我们需要一个0000来代表0，这就造成了补码所能表示的负数总是比正数多一个。 符号数的编码还有原码和反码，但是他们比起补码由各自的问题，现代计算机都是统一使用补码表示有符号数：https://www.zhihu.com/question/20159860 Conversions between Signed and Unsigned 在C语言中当我们想要对有符号数和无符号数进行强制类型转换的时候，内部的实现是根据位的角度，而不是数的角度。当我们进行强制转换的时候，二进制的表示不会发生变化，但由于符号数和无符号数使用不同的编码，所以最终所表示的数也是不同的 假设我们有下面的一段程序： 123short int v = -12345;unsigned short uv = (unsigned short) v;printf(&quot;v = %d, uv = %u\\n&quot;, v, uv); //v= -12345, uv = 53191 这里我们会发现，无符号数53191和有符号数-12345有着相同的二进制表达0xCFC7，也就是说C语言在进行强制类型转换的时候不会改变二进制的表达，而只是使用不同的编码方式。 我们还发现无符号数53191和有符号数-12345之间存在某些联系，前面我们提到两者的二进制表达式完全一样的，只是补码将第一位的1翻译成负的32768(2的15次方)，而无符号数编码将第一位的1翻译成正的32768，所以其实两个数之间差了65536(2的16次方)。这个特性适用于其他位数，补码表示的负数与无符号数编码表示的正数相差2的w次方(两者二进制表达相同)。 Signed versus Unsigned in C 当C语言的表达式中，如果一个运算数是有符号的而另一个是无符号的，那么C语言会隐式的将有符号数强制类型转换为无符号数。所以我们会看到下面这些奇怪的表达式： 12-1 &lt; 0U //false，因为-1会被转换成无符号数，而-1的二进制表达式全是12147483647U &gt; -2147483647-1 //false，因为-2147483648会被转换成无符号数 Expanding the Bit Representation of a Number 当扩大一个无符号数的时候，我们在它的高位上填充0 当扩大一个有符号数(补码)的时候，我们在它的高位上填充它本来的符号位。 1234short sx = -12345;//12345, 二进制表达：cf c7unsigned short usx = sx; //53191，二进制表达：cf c7int x = sx; //-12345，二进制表达：ff ff cf c7unsigned ux = usx; //53191，二进制表达：00 00 cf c7 我们可以看到扩大后的无符号数与有符号数的二进制表达不再相同。 这里我们会发现一个有趣的结论，在有符号数的高位填充符号位不会改变补码所表示的数字。这对于正数(即添加0)是显而易见的，但是为什么在负数的高位填充1仍旧不改变补码的值呢？ 123101 代表 -4+1=31101 代表 -8+4+1 = 311101 代表 -16+8+4+1 = 3 其实原因就是原本负数的最高位由于更高位的填充变成正值，一来一去就是两倍的原本负数的最高位的值，再加上前面的正值，正好等于新的负数的最高位。 如果我们将short转为unsigned int，程序会先转变变量的大小，然后才是类型。假设sx表示一个short变量，对于(unsigned)sx，等价于(unsigned)(int)sx。 Truncating Numbers 上一节介绍了扩大有符号数或者无符号数，如果是缩小的话，二进制的高位会被丢掉。 Integer ArithmeticUnsigned Addition/Two’s Complement Addition 不论是无符号数的加法还是补码的加法，都会出现溢出的问题，其中无符号数的加法只会有正数的溢出，补码的加法不仅有正数的溢出，还存在负数的溢出，面对溢出的做法就是丢掉溢出位。 Unsigned Multiplication/Two’s Complement Mutiplication 乘法的运算也会导致溢出的产生，同样的，我们把溢出的位丢掉即可得到结果。 Multiplying by Constants 历史上，计算机的整数乘法是一种相对慢的运算，通常需要十个或更多的时钟周期来进行计算，然而加减法以及移位运算只需要一个时钟周期即可完成，所以编译器会尝试将乘法替换成加减法和移位运算。 我们知道对一个无符号数或者补码左移k位，相当于乘以2的k次方，我们可以利用这条规律来把整数表示为2的幂之间的加和，所以最终我们就可以实现用加法和移位运算代替乘法 Deviding by Powers of 2 整数的除法是比乘法还要慢的运算，通常需要30或者更多个时钟周期，如果所计算的除法是除以2的幂，这个时候可以使用右移运算代替，需要注意的是，无符号数使用逻辑右移，而补码使用算术右移。 需要注意的是，整数每右移一位相当于除以2，那么如果遇到除不开会怎样？答案是向下取整(正数和负数都是向下取整)。比如14(二进制是00001110)右移两位，结果是3(二进制是00000011)；-14(二进制是11110010)右移两位，按除法结果是-14/4 = -3.5，向下取整就是-4(二进制是11111100)。 Floating PointFractional Binary Number 二进制的小数通过在添加小数点来表示是，比如101.11表示的就是1*4+0*2+1*1+1*0.5+1*0.25 = 5.75。 一个很重要的规则：当我们把小数点向左移的时候，相当于对结果除以2；当我们把小数点向右移的时候，相当于对结果乘2.比如1011.1表示的就是11.5。 类似十进制小数无法表示某些数，比如三分之一，二进制小数也有一些无法表示的数，比如0.20。 IEEE Floating-Point Representation IEEE浮点数分为三个组成部分：符号位s(sign)，尾数M(significant)，阶数E(exponent)。这三个组成部分得到的结果是V = -1的s次幂 * M * 2的E次幂。至于这三个数是如何根据32位的float和64位的double计算出来的，可以参考三种不同的情况：Normalized Values，Denormalized Values，Special Case。 M在Normalized Values情况下表示1到2的小数，在Denomalized Values情况下表示0到1的小数，而阶数E就相当于在对M的小数进行左右移动(根据E是正数还是负数)，这也就是浮点数名字的由来，看起来就像小数点在移动。 Examples Numbers 从书中的例子可以看出来，Denormalized Values表示的是靠近0的很小的小数，最大的Denormalized Values与最小的Normalized Values是很接近的。 Data Lab位运算的一些小技巧 利用位的&amp;和|运算，也可以巧妙地达到类似&amp;&amp;和||的逻辑效果。用0x01表示true，0x00表示false。 判断两个数是否相等，可以使用^。所以使用!(a^b)就可以达到a和b相同时返回true(0x01)，不同时返回false(0x00) 123456789101112131415161718/* * isAsciiDigit - return 1 if 0x30 &lt;= x &lt;= 0x39 (ASCII codes for characters '0' to '9')* Example: isAsciiDigit(0x35) = 1.* isAsciiDigit(0x3a) = 0.* isAsciiDigit(0x05) = 0.* Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;* Max ops: 15* Rating: 3*/int isAsciiDigit(int x) {int y = x&gt;&gt;4;int flag = !(y^0x03);int z = x&amp;0xF;int zeroToSeven = !(z&gt;&gt;3);int eight = !(z^0x8);int nine = !(z^0x9);return flag &amp; (zeroToSeven | eight | nine);} 这道题就使用前两个技巧。首先flag的目的是为了确定x的高四位是0x3，所以这里的操作是先右移四位，然后判断是否与0x03相等，相等的话返回true(0x01)。其次我们需要确认低四位是1到9。这里是分别判断低四位是0到7或者8或者9，将它们的结果进行或运算。最后再与flag进行与运算。 巧用模的&amp;运算，可以保留某些位不变，其他位变为0 1234567891011121314/* * allOddBits - return 1 if all odd-numbered bits in word set to 1* where bits are numbered from 0 (least significant) to 31 (most significant)* Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1* Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;* Max ops: 12* Rating: 2*/int allOddBits(int x) { int y = 0xAA; y += y&lt;&lt;8; y += y&lt;&lt;16;//0xAAAAAAAA作为模 return !((y&amp;x)^y);} 这道题就巧用了0xAAAAAAAA作为模，与0xAAAAAAAA进行与运算后仍旧与0xAAAAAAAA相等，证明x的偶数位都是1。 浮点数运算 一个规则：1.1101 * 2 = 11.101。也就是乘2相当于小数点左移，除以2相当于小数点右移所以浮点数，M的小数点一开始在开头，我们可以看作是M的小数点在左移或者右移E的位数。 Machine-Level Representation of Programs","link":"/2021/11/08/Basics/CSAPP/"},{"title":"C语言","text":"计算机和编程语言 解释性语言vs编译语言：语言本无解释/编译之分，只是常用的执行方式而已，比如我们常说C语言是编译性语言，是因为大多数时候我们运行C语言都是先编译后运行，但是其实也是有C语言解释器存在的。 C语言发展与版本 1989年ANSI发布了第一个标准-ANSI C 1990年ISO接受了ANCI的标准-C89 C的标准在1995年和1999年两次更新-C95和C99 本课程使用C99版本教学 变量变量名 变量名在C语言里面属于标识符（identifier），命名有严格的规范。 只能由字母（包括大写和小写）、数字和下划线（_）组成。 不能以数字开头。 长度不能超过63个字符。 变量名区分大小写，star、Star、STAR都是不同的变量。 并非所有的词都能用作变量名，有些词在C语言里面有特殊含义，比如int，return，它们是C语言的关键字。 变量的声明 C语言的变量，必须先声明后使用。如果一个变量没有声明，就直接使用，会报错。每个变量都有自己的类型（type）。声明变量时，必须把变量的类型告诉编译器。int height; 变量的赋值 C语言会在变量声明时，就为它分配内存空间，但是不会清除内存里面原来的值。这导致声明变量以后，变量会是一个随机的值。所以，变量一定要赋值以后才能使用。 赋值操作通过赋值运算符（=）完成。下面示例中，第一行声明了一个整数变量num，第二行给这个变量赋值。 12int num;num = 42; 变量的声明和赋值，也可以写在一行。比如int num = 42;。多个相同类型变量的赋值，可以写在同一行。比如int x = 1, y = 2;。 注意，赋值表达式有返回值，等于等号右边的值。 1234int x, y;x = 1;y = (x = 2 * x); 上面代码中，变量y的值就是赋值表达式（x = 2 * x）的返回值2。 由于赋值表达式有返回值，所以 C 语言可以写出多重赋值表达式。 123int x, y, z, m, n;x = y = z = m = n = 3; 上面的代码是合法代码，一次为多个变量赋值。赋值运算符是从右到左执行，所以先为n赋值，然后依次为m、z、y和x赋值。 运算符算术运算符 算术运算符专门用于算术运算，主要有下面几种。 +：正值运算符（一元运算符），结合关系：自右向左-：负值运算符（一元运算符），结合关系：自右向左+：加法运算符（二元运算符）-：减法运算符（二元运算符）*：乘法运算符/：除法运算符%：余值运算符=：赋值运算符，结合关系：自右向左2. 我们可以看到，+和-既可以做一元运算符，也可以做二元运算符。做一元运算符的时候，指的是为一个值取正或取负，并且做一元运算符的时候，与赋值运算符一样，结合关系是自右向左3. 如果变量对自身的值进行算术运算，C 语言提供了简写形式，允许将赋值运算符和算术运算符结合成一个运算符。+= -= *= /= %=。由于赋值运算符的优先级最低，所以当出现a+=b+3时，C语言会先计算b+3的结果，然后计算a = a + (b+3)的结果 自增运算符，自减运算符 C 语言提供两个运算符，对变量自身进行+ 1和- 1的操作。++：自增运算符；–：自减运算符 12i++; // 等同于 i = i + 1i--; // 等同于 i = i - 1 这两个运算符放在变量的前面或后面，结果是不一样的。++var和–var是先执行自增或自减操作，再返回操作后var的值；var++和var–则是先返回操作前var的值，再执行自增或自减操作。 12345678910int i = 42;int j;j = (i++ + 10);// i: 43// j: 52j = (++i + 10)// i: 44// j: 54 关系运算符 C 语言用于比较的表达式，称为“关系表达式”（relational expression），里面使用的运算符就称为“关系运算符”（relational operator），主要有下面6个。 大于运算符&lt; 小于运算符= 大于等于运算符&lt;= 小于等于运算符== 相等运算符!= 不相等运算符 关系表达式通常返回0或1，表示真伪。C语言中，0表示伪，所有非零值表示真。比如，20 &gt; 12返回1，12 &gt; 20返回0。 关系运算符不宜连用：(i &lt; j) &lt; k。这个式子中，i &lt; j返回0或1，所以最终是0或1与变量k进行比较。如果想要判断变量j的值是否在i和k之间，应该使用下面的写法：i &lt; j &amp;&amp; j &lt; k 逻辑运算符 逻辑运算符提供逻辑判断功能，用于构建更复杂的表达式，主要有下面三个运算符。!：否运算符（改变单个表达式的真伪）。&amp;&amp;：与运算符（两侧的表达式都为真，则为真，否则为伪）。||：或运算符（两侧至少有一个表达式为真，则为真，否则为伪）。 下面是 否运算符 的例子。 12if (!(x &lt; 12))printf(&quot;x is not less than 12\\n&quot;); 上面示例中，由于否运算符!具有比&lt;更高的优先级，所以必须使用括号，才能对表达式x &lt; 12进行否运算。当然，合理的写法是if (x &gt;= 12)，这里只是为了举例。 对于逻辑运算符来说，任何非零值都表示真，零值表示伪。比如，5 || 0会返回1，5 &amp;&amp; 0会返回0。 逻辑运算符还有一个特点，它总是先对左侧的表达式求值，再对右边的表达式求值，这个顺序是保证的。如果左边的表达式满足逻辑运算符的条件，就不再对右边的表达式求值。这种情况称为“短路”。 逗号运算符 逗号运算符用于将多个表达式写在一起，从左到右依次运行每个表达式。x = 10, y = 20;。上面示例中，有两个表达式（x = 10和y = 20），逗号使得它们可以放在同一条语句里面。 逗号运算符返回最后一个表达式的值，作为整个语句的值。 12int x;x = 1, 2, 3; 上面示例中，逗号的优先级低于赋值运算符，所以先执行赋值运算，再执行逗号运算，变量x等于1。 12int x;x = (1, 2, 3); 上面示例中，由于有了括号的存在，先执行逗号运算，我们使用最右边的值作为表达式的值，然后赋给x，变量x等于3。 运算符优先级 运算符的优先级顺序很复杂。下面是部分运算符的优先级顺序（按照优先级从高到低排列）。https://en.cppreference.com/w/c/language/operator_precedence圆括号（()）从左到右所有单目运算符：自增运算符（++），自减运算符（–），一元运算符（+和-），否运算符（!）乘法（*），除法（/），取余（%）加法（+），减法（-）关系运算符（&lt;、&gt;等）== !=&amp;&amp;||赋值运算符（=）,其他赋值运算符（+=, -=）逗号运算符(,) 流程控制 https://wangdoc.com/clang/flow-control.html 老师有一点讲的很好：switch-case语句中，case并不是用来分割语句的，case只是用来决定语句从什么地方开始执行。我们在使用switch-case语句的时候，可以无视case，把剩下的所有语句当成一段要执行的代码，case只是选择从哪一句开始执行，然后程序会一直执行下面的代码，直到遇到break为止 数据类型函数 函数声明：C语言中的函数在使用前必须先进行定义，这点与Java不同，Java的函数可以定义在任何位置。如果C语言想要在未定义函数前就进行使用，那么就需要使用函数声明。123456789int twice(int);//函数声明int main(int num) { return twice(num);}int twice(int num) { return 2 * num;} 调用函数时给的值与参数的类型不匹配是C语言传统上的最大的漏洞，编译器总是悄悄的替你把类型转换好，但是这很可能不是我们所期望的，后续的语言，比如C++和Java在这方面很严格。 1234567void test(int t) { printf(&quot;%d&quot;, t);}int main() { test(2.4);} 上面的程序编译会通过，虽然会有一个warning，这种程序对于Java根本不可能通过编译 hello.c:8:10: warning: implicit conversion from ‘double’ to ‘int’ changes value from 2.4 to 2 [-Wliteral-conversion] test(2.4); ~~~~ ^~~ 1 warning generated. C语言在调用函数的时候，永远只能传值给函数 值传递（pass by value）是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 引用传递（pass by reference）是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 更精辟的理解：操作的是一块内存(引用传递)还是新开辟了一块内存(值传递)的区别 所以我们看到下面的程序是不会有效的： 12345678910void Swap(int x, int y) {int temp;temp = x;x = y;y = temp;}int a = 1;int b = 2;Swap(a, b); // 无效 对于Java来说：Java中本质上是值传递的，只不过对于对象参数(非primitive的所有对象)，值的内容是对象的引用(地址)，通俗的来说，如果Java中函数的参数是一个对象，那么当我们call这个函数的时候，传进去的是这个对象引用(地址)的一份拷贝。https://www.zhihu.com/question/31203609/answer/576030121 本地变量： 本地变量只在当前block中可用(函数参数也是本地变量)，程序进入这个块之前，其中的变量不存在，离开这个块，其中的变量就消失了。如果在块里面定义了和外面同名的变量，则掩盖掉外面的(这点Java是不支持的) 数组 https://wangdoc.com/clang/array.html 注意，如果引用不存在的数组成员（即越界访问数组），并不会报错，所以必须非常小心。 12int scores[100];scores[100] = 51; 上面示例中，数组scores只有100个成员，因此scores[100]这个位置是不存在的。但是，引用这个位置并不会报错，会正常运行，使得紧跟在scores后面的那块内存区域被赋值，而那实际上是其他变量的区域，因此不知不觉就更改了其他变量的值。这很容易引发错误，而且难以发现。 把一个数组的所有元素交给另一个数据，不能直接int a[] = {0, 1, 2}; int b[] = a;，而是只能遍历，后面介绍指针后会介绍具体原因。 求数组的长度：sizeof(a)/sizeof(a[0]) 数组作为函数参数的时候，我们无法直接通过上面的求数组长度的方法来得到它的长度，所以往往需要再用另一个参数来传入数组的大小，其原因是因为数组作为参数，传入的其实只是数组第一个值的地址，所以我们是没法知道长度的。这点与Java是不同的，Java的数组传入函数的是一个引用，可以直接使用a.length得到数组长度。 指针 运算符&amp;：获得变量的地址，它的操作数必须是变量 12int x = 1;printf(&quot;x's address is %p\\n&quot;, &amp;x); 上面示例中，x是一个整数变量，&amp;x就是x的值所在的内存地址。printf()的%p是内存地址的占位符，可以打印出内存地址 变量地址的长度在不同的编译器架构中是不同的，32位编译器架构的变量地址的长度是4个字节，，64位编译器架构的变量地址的长度是8个字节。所以变量地址并不总是和int(4个字节)的长度相同，我们也不应该使用int来表示地址。 &amp;只能取变量的地址，对于表达式来说，是没有地址可以取的，所以下面都是错误的表示：&amp;(a+b); &amp;(a++); &amp;(++a) 前面我们说过，一个变量的地址并不总是与int长度相等，所以我们需要一个用来储存地址的方法，指针就是保存地址的变量 1234int i;int* p = &amp;i;int* p,q;int *p,q; 上面的例子中，第三四行代表的都是p是一个指针，q只是一个int型的变量。所以，在C语言中，没有int*这种类型，而应该表达为*p是一个int类型的变量。如果要表示p和q都是指针，应该写为int *p, *q;。 运算符*：用来访问指针的值所表示的地址上的变量 123void increment(int* p) {*p = *p + 1;} 上面示例中，函数increment()的参数是一个整数指针p。函数体里面，*p就表示指针p所指向的那个值。对*p赋值，就表示改变指针所指向的那个地址里面的值。 上面函数的作用是将参数值加1。该函数没有返回值，因为传入的是地址，函数体内部对该地址包含的值的操作，会影响到函数外部，所以不需要返回值。事实上，函数内部通过指针，将值传到外部，是C语言的常用方法。 指针的作用：1.在函数中传入地址，那么我们修改改地址指向的变量，也就可以改变外面的变量，所以在C语言中写一个swap函数必须要传入地址。之前我们提到Java语言也是传值的，那么如果要写一个swap函数交换两个int值，那么往往需要借助数组或者对象，因为Java不提供指针。 2.当我们的函数需要多个返回值的时候，我们可以通过传入多个指针并把返回值写入这些指针指向的变量来达到这个目的 3.函数返回运算的状态，而运算的结果通过指针返回。由于C语言没有异常处理机制，所以我们的程序需要返回一个特殊值来说明是否运行正常，那么运算的结果就无法通过返回值来返回了，这时候可以使用指针。 指针最常见的错误：定义了指针变量，但是还没有指向任何变量(初始化)，就开始使用 12int *p;*p = 12; 这里p储存的地址完全是随机的，而我们想要改一个随地地址的变量的值。 数组的地址：数组是一连串连续储存的同类型值，只要获得起始地址（首个成员的内存地址），就能推算出其他成员的地址。请看下面的例子。 1234int a[5] = {11, 22, 33, 44, 55};int* p;p = &amp;a[0];printf(&quot;%d\\n&quot;, *p); // Prints &quot;11&quot; 上面示例中，&amp;a[0]就是数组a的首个成员11的内存地址，也是整个数组的起始地址。反过来，从这个地址（*p），可以获得首个成员的值11。 由于数组的起始地址是常用操作，&amp;array[0]的写法有点麻烦，C 语言提供了便利写法，数组名等同于起始地址，也就是说，数组名就是指向第一个成员（array[0]）的指针。 指针与数组：前面我们提到过，数组传入函数中，我们是不能用参数列表的数组变量去计算数组的长度的，原因就是数组传入函数的时候被decay成一个指针，指向数组的起始地址，所以如果对函数内的数组变量使用sizeof，得到的并不是数组的字节长度，而是数组起始地址端的字节长度。这也是为什么在C语言中，当我们想要将一个数组传入函数的时候，我们还需要传入数组的长度，因为传入的参数只是一个指针，我们还需要另外一个变量来指明数组的长度 []运算符可以对数组做，也可以对指针做；*运算符可以对指针做，也可以对数组做 数组与指针并不等价，只不过数组可以decay成指针来使用：不等价，数组能隐式转换成指针罢了。看到有书这么写的话应该考虑直接扔掉。数组和指针的区别应该是十分基础而显然的。定义一个指针对象 T *ptr; 后 ptr 这个对象里面没有 T 类型对象，不过可能可以通过 ptr 访问存在于别处的 T 类型对象。定义一个数组对象 T arr[N]; 后 arr 这个对象里面有 N 个 T 类型对象。将 arr 隐式转换成指针后，能访问的 T 类型对象是 arr 里面的对象。https://www.zhihu.com/question/362176701/answer/956286999 指针与const： 指针是const，表示一旦得到了某个变量的地址，不能在指向其他变量，但是已经指向的变量是可以改变的。数组其实就是一个const指针，int[] a等价于int * const a，这也就是为什么前面我们提到数组之间不能互相赋值(int[] a = b是不允许的)，因为这是在把一个const指针指向另一个变量。123int * const q = &amp;i;*q = 26; //okq++; //error 所指是const，表示不能通过这个指针去修改那个变量（并不能使得那个变量成为const，也就是说那个变量本身是可以改变的，但你不能用这个指针去改变它）1234const int *p = &amp;i;*p = 26; //error!(*p)是consti = 26;//okp= &amp;j;//ok 判断哪个被const了的标志是const在*的前面还是后面：1234int i;const int* p1 = &amp;i;//所指是constint const* p2 = &amp;i;//所指是constint *const p3 = &amp;i;//指针是const const数组： const int a[] = {1, 2, 3, 4, 5}。数组变量已经是const的指针了，这里的const表明数组的每个单元都是const int，无法通过a[i]进行修改，所以必须通过初始化进行赋值。 指针运算：对于指针的加1与减1并不是地址的加1或减1，而是表示指针的移动，移动的距离是取决于变量的大小，比如在32位编译器中int的大小是4，如果我们有一个int型的数组array[]，现在我们有int *p = array;，那么*(p+n)与array[n]是等价的。由于运算符*比+的优先级高，所以这里我们需要括号。 0地址：操作系统会为每个程序虚拟化一段内存，这些内存都有地址为0的一个的地址，但是这个0地址处储存着我们不能操作的数据，因此我们可以把用0指针代表返回的指针是无效的或者指针还没有被初始化(先初始化为0)。C语言中NULL是一个预定义的符号，代表0地址。 指针的类型：无论指针指向什么类型，所有的指针的大小都是一样的(大小取决于编译器)。但是指向不同类型的指针是不能直接互相赋值的，比如不能把一个int型的指针赋给double型的指针 指针的类型转换：123int i = 5;int *p = &amp;i;void *q = (void*)p; void*表示不知道指向什么东西的指针。这里把一个指向int的指针转化成void*的指针，但是这并不会改变p所指的变量的类型，他所指的仍旧是一个int型变量，只是这个时候我们用不同的眼光看待这个变量 动态内存分配：假设我们的程序中要定义一个长度为n的数组，这个n是通过命令行输入的，这个时候我们可以使用变量n作为数组大小，但是这个feature是C99才引进的，之前ANSIC并不支持变量作为数组长度，那么我们该怎么做呢？答案是使用动态内存分配，我们可以使用malloc函数分配一段长度为n*sizeof(int)的内存：int *a = (int*)malloc(n*sizeof(int))。malloc函数的输入是分配内存的字节长度，malloc函数返回的是void*，我们使用强制类型转化变成int型的数组。malloc函数需要引入#include &lt;stdlib.h&gt;，malloc函数用完以后一定要用free函数释放内存、如果内存地址不够分配，malloc函数返回NULL 字符串 C语言没有单独的字符串类型，字符串被当作字符数组，即char类型的数组。比如，字符串”Hello”是当作数组{'H', 'e', 'l', 'l', 'o'}处理的。编译器会给数组分配一段连续内存，所有字符储存在相邻的内存单元之中。在字符串结尾，C语言会自动添加一个全是二进制0的字节，写作\\0字符，表示字符串结束。字符\\0不同于字符0，前者的 ASCII 码是0（二进制形式00000000），后者的 ASCII 码是48（二进制形式00110000）。所以，字符串“Hello”实际储存的数组是{'H', 'e', 'l', 'l', 'o', '\\0'}。 字符\\0标志字符串的结束，但它不是字符串的一部分，我们计算字符串的长度的时候不包含这个0。其实这点很好理解，这个0只是因为C语言不提供字符串类型，所以需要有一种方式去标记字符串的结束。 如果字符串过长，可以在需要折行的地方，使用反斜杠（\\）结尾，将一行拆成多行。 12&quot;hello \\world&quot; 上面示例中，第一行尾部的反斜杠，将字符串拆成两行。 上面这种写法有一个缺点，就是第二行必须顶格书写，如果想包含缩进，那么缩进也会被计入字符串。为了解决这个问题，C 语言允许合并多个字符串字面量，只要这些字符串之间没有间隔，或者只有空格，C 语言会将它们自动合并。 123char greeting[50] = &quot;Hello, &quot;&quot;how are you &quot;&quot;today!&quot;;// 等同于char greeting[50] = &quot;Hello, how are you today!&quot;; 这种新写法支持多行字符串的合并。 123char greeting[50] = &quot;Hello, &quot;&quot;how are you &quot;&quot;today!&quot;; 字符串在内存中以字符数组的形式存在，所以不能用运算符对字符串进行操作(不能像Java一样字符串之间相加)。访问的时候可以使用指针或者数组，但是这两者在访问字符串的时候是有区别的。 1234// 写法一char s[] = &quot;Hello, world!&quot;;// 写法二char* s = &quot;Hello, world!&quot;; 那么这两种声明方式有什么区别呢？首先我们需要知道的是，C语言的字符串字面量(也就是”Hello, world!”)都是生成在代码段的内存中的，这段区域是只可读的，这个时候如果我们尝试s[0] = 'B'是会报错的，并且如果我们用指针方式声明相同的字符串，其实指针是会指向同一个地址的；而使用数组声明的字符串，编译器会给数组在栈区(stack，也就是局部变量和函数参数所在的地方，变量由系统自动分配与销毁)单独分配一段新内存，字符串字面量会被编译器解释成字符数组，逐个字符写入这段新分配的内存之中，而这段新内存是允许修改的，所以s[0] = 'B'是允许的。 口语中，我们常说用char*定义一个字符串，但是char*声明的并不一定是字符串，也可能只是一个指向单个字符的滋镇，只有当它所指的是一个字符数组并且结尾是一个0的时候，才能说它指的是字符串。 字符串数组：介绍过字符串以后，那么字符串数组应该如何表示呢？可能的方案有：1.char ** a 2.char a[][] 3. char * a[]。方案一并不是字符串数组，而是表示a是一个指针，指向另一个指针，那个指针指向一个字符(串)；方案二可以在一定程度上代表字符串数组，但是有一个问题，二维数组的第二个维度必须是确定的，那么这里我们的字符串就会有一个长度限制 3.方案三代表的才是字符串数组，这里数组中只存放char*，也就是指针。 C语言标准库提供了很多处理字符串的函数，我们在使用之前需要先加上头文件#include &lt;string.h&gt;。 size_t strlen(const char *s)：返回字符串长度(不包括结尾的0) int strcmp(const char *s1, const char *s2)：比较两个字符串的长度，如果s1==s2，返回0，如果s1&gt;s2，返回1，如果s1&lt;s2，返回-1 char * strcpy(char *restrict dst, const char *restrict src)：把第二个字符串拷贝到第一个字符串的位置，restricted代表两个字符串不重叠。返回的就是dst这个字符串，目的是为了能链起代码来 char * strcat(char *restrict s1, const char *restrict s2)：把s2拷贝到s1后面，s1必须有足够的空间。strcat和strcpy都可能出现安全问题，因为目的地可能没有足够的空间，可以使用安全的版本strncpy和strncat，n代表最多能拷贝的字符 char * strchr(const char *s, int c); char * strrchr(const char *s, int c)：在字符串中找第一个出现的c，没有返回0指针NULL，有的话返回对应指针，strrchr代表从右向左找，strchr代表从左向右找 enum，struct与union enum：https://wangdoc.com/clang/enum.html struct：https://wangdoc.com/clang/struct.html struct赋值：除了逐一对struct的属性赋值，也可以使用大括号，一次性对 struct 结构的所有属性赋值。 123456struct car {char* name;float price;int speed;};struct car saturn = {&quot;Saturn SL/2&quot;, 16000.99, 175}; 上面示例中，变量saturn是struct car类型，大括号里面同时对它的三个属性赋值。如果大括号里面的值的数量，少于属性的数量，那么缺失的属性自动初始化为0。 struct复制：struct变量可以使用赋值运算符（=），复制给另一个变量，这时会生成一个全新的副本。系统会分配一块新的内存空间，大小与原来的变量相同，把每个属性都复制过去，即原样生成了一份数据。这一点跟数组的复制不一样，务必小心。 12345678910struct cat { char name[30]; short age; } a, b;strcpy(a.name, &quot;Hula&quot;);a.age = 3;b = a;b.name[0] = 'M';printf(&quot;%s\\n&quot;, a.name); // Hulaprintf(&quot;%s\\n&quot;, b.name); // Mula 上面示例中，变量b是变量a的副本，两个变量的值是各自独立的，修改掉b.name不影响a.name。 上面这个示例是有前提的，就是 struct 结构的属性必须定义成字符数组，才能复制数据。如果稍作修改，属性定义成字符指针，结果就不一样。 123456struct cat { char* name; short age; } a, b;a.name = &quot;Hula&quot;;a.age = 3;b = a; 上面示例中，name属性变成了一个字符指针，这时a赋值给b，导致b.name也是同样的字符指针，指向同一个地址，也就是说两个属性共享同一个地址。因为这时，struct 结构内部保存的是一个指针，而不是上一个例子的数组，这时复制的就不是字符串本身，而是它的指针。并且，这个时候也没法修改字符串，因为字符指针指向的字符串是不能修改的。 struct作为函数参数：整个struct可以作为参数传入函数，这个时候是在函数内部新建一个struct并复制传入的struct的值；但是一般当struct很大的时候，常见的做法是传一个struct指针。 123void happy(struct turtle* t) {(*t).age = (*t).age + 1;} 上面示例中，(*t).age不能写成*t.age，因为点运算符.的优先级高于*。*t.age这种写法会将t.age看成一个指针，然后取它对应的值，会出现无法预料的结果。 (*t).age这样的写法很麻烦。C语言就引入了一个新的箭头运算符（-&gt;），可以从struct指针上直接获取属性，大大增强了代码的可读性。 123void happy(struct turtle* t) {t-&gt;age = t-&gt;age + 1;} 自定义数据类型：我们可以使用typedef来声明一个已有的数据类型的新名字，比如typedef int Length;。typedef命令也可以为struct结构指定一个别名，这样使用起来更简洁。 123456typedef struct cell_phone {int cell_no;float minutes_of_charge;} phone;phone p = {5551234, 5}; 上面示例中，phone就是struct cell_phone的别名。 union：https://wangdoc.com/clang/union.html","link":"/2021/10/15/Basics/C%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80-/"},{"title":"Computer Networking阅读笔记","text":"Computer Networks and the InternetWhat is the internet 计算机网络中，我们把所有连入网络的设备叫做主机(hosts)或者端系统(end systems)，端系统一般可以分成两大类：clients和servers 端系统之间由通信链路(communication links)和分组交换机(packet switches)连接。常见的通信链路包括同轴电缆，铜线，光纤和无线电频谱。常见的分组交换机有路由器(router)和链路层交换机(link-layer switch) 家用路由器与计算机网络中的路由器的区别： https://www.zhihu.com/question/52176116 The network edgeAccess Networks 接入网指将端系统物理连接到边缘路由器(edge router，即路径上第一台路由器)的网络。接入网按照使用环境主要分为家庭，公司和广域移动无线。 家庭接入网中比较流行的有数字用户线(Digital Subscriber Line, DSL)和同轴电缆。 数字用户线技术使用电话线传输网络信号，采用频分复用技术(分为三个频率的信道，电话使用0到4kHz低频，网络数据使用4kHz到50kHz中频或50kHz到1MHz高频)，因此在用户端需要一个DSL调制解调器(DSL Modem)，将网络数据的数字信号转换成高频电信号，这样才能和低频电话信号一起通过电话线发送。电话公司端需要使用数字用户线接入复用器(DSLAM)分离数据信号与电话信号，并发送到各自的网络中。 同轴电缆技术使用电视线传输网络信号，与数字用户线技术类似，同轴电缆在用户端也需要使用调制解调器(cable modem)，在电视服务商端也需要区分电视信号与网络信号。 除了以上两种技术，常见的家庭接入网还有光纤入户，拨号上网与卫星信号 公司接入网与家庭接入网的区别是公司通常将一个局域网连接到边缘路由器，也就是说公司的一个局域网可能连接有多个端系统，随后这个局域网在连接到边缘路由器以获得互联网连接。比较常见的局域网有以太网(Ethernet)和WiFi。 以太网的用户(端系统)通过双绞铜线连接到以太网交换机，以太网交换机再与因特网相连；WLAN(wireless LAN)的用户(端系统)与接入点进行数据收发，接入点与企业网连接(很有可能使用了有线以太网)，企业网再与因特网相连。基于IEEE802.11技术的WLAN被通俗的称为WiFi。 虽然以太网与WiFi最初是设置在企业或大学中的，但近来许多家庭将接入网与廉价的无线局域网技术结合起来，来产生强大的家用网络。 我们家里的路由器能生成一个小的局域网，这个局域网通过调制解调器连接到互联网。 Phsical Media 常见的物理媒介有：双绞铜线，同轴电缆，光纤，陆地无线电信道和卫星无线电信道 The network corePacket Switching 在不考虑传播时延的情况下，分组传播的速度由分组的大小(L bit)和链路最大传输速率(R bit/s)决定，从链路的一端传到另一端需要L/R秒 Store-and-Forward Transmission 分组交换采用存储转发运输(Store-and-Forward Transmission)。存储转发运输指的是分组交换机(packet switches)在开始发送某个分组的第一个比特前，必须已经接收到整个分组。假设我们要从A发送一个L bit大小的分组到B：A-&gt;router-&gt;B。从A到router与从router到B的通信链路的传输速度都是R b/s。如果没有存储转发运输，那么从A到B的时延就是分组的大小除以链路的传输速度，也就是L/R。但是如果考虑存储转发运输，那么分组必须先到达router，直到所有bit全部到达以后，才可以继续转发到B，所以时延是2L/R。 因此，在考虑存储转发运输的情况下，如果有N个通信链路(其中有N-1个router)，那么最后的时延就是NL/R Queuing Delays and Packet Loss 每台分组交换机有多条链路与之相连。对于每条相连的链路，该分组交换机都有一个输出缓存(output buffer)，它用于储存分组交换机准备发往这个链路的分组。如果一个到达的分组发现想要发送到的链路正在被别的分组占用，那么它就会被储存在这个输出缓存中。因此除了上面提到的存储转发时延，分组交换也存在排队时延。 如果一个分组在到达输出缓存的时候缓存已经满了，那么就会出现分组丢失(packet loss)，也就是丢包现象。 Forwarding Tables and Routing protocols 前面我们提到过，一个路由器可能连接有多条输出链路，那么路由器如何决定选择哪条链路呢？答案是分组的头部包含目的地的IP地址，而路由器具有一个转发表(forwarding table)，可以将目的地址映射成输出链路。 那么转发表是如何设置的呢？答案是由路由选择协议(routing protocol)自动设置的 Circuit Switching 除了分组交换以外，另一种常见的数据传递方式是电路交换，电路交换与分组交换的区别是电路交换会预留端系统间沿路径通信所需要的资源(缓存，链路传输速度等)，而分组交换不会，分组会按需使用这些资源，其后果是有可能需要进入buffer排队等待。我们常用的电话就是电路交换的代表，电话的“占线”就是电路交换的象征。 Multiplexing in Circuit-Switched Networks 电路交换网络中的复用技术包括频分复用(Frequency-Division Multiplexing, FDM)和时分复用(Time-Division Multiplexing, TDM) Packet Switching Versus Circuit Switching 分组交换比电路交换效率更好，具体的例子见书 A Network of Networks 用户-&gt;接入ISP(Access ISP)-&gt;区域ISP(Regional ISP)-&gt;第一层ISP(Tier 1 ISP)。较低层的ISP与较高层的ISP相连，较高层的ISP彼此互联。用户和内容提供商是较低层ISP的客户，较低层ISP是较高层ISP的客户。 Delay, Loss and Throughput in Packet-Switched NetworksOverview of Delay in Packet-Switched Networks 分组在从一个节点到另一个节点的过程中会经受几种不同类型的时延，主要有节点处理时延(nodal processing delay)，排队时延(queueing delay)，传输时延(transmission delay)和传播时延(propagation delay)，这些时延总体累加起来是节点总时延(total nodal delay) Processing Delay 节点处理时延指的是分组在到达节点后，节点处理该分组并继续发送所用的时间，比如router或者switch检查分组的头部来决定该分组该发送到那里的时间，或者router对分组进行字节校验所用的时间 Queueing Delay 排队时延是指由于分组所要发往的链路正在被占用，该分组在buffer中排队等待发送的时间 Transmission Delay 传输时延即是我们前面提到的L/R，也就是将所有分组发射到链路所需要的时间 Propagation Delay 传播时延指的是分组在进入链路后，从一端传播到另一端所用的时间，如果链路的长度是d，分组在链路中传播的速度是s(一般是光速或略小于光速)，那么传播时延就是d/s Comparing Transmission and Propagation Delay 传输时延与传播时延看起来很容易搞混，但在明白其中原理后就很容易分清。由于物理媒介的传输能力是有限的，每秒所能进入物理媒介的数据也就是有限的，如果我们有一个L bit的分组，而链路的最大传输能力只有R bit/s，那么意味着我们需要L/R秒才能把这个分组的所有bit都发射到链路中，这就是传输时延。当分组的最后一个bit进入到链路中后，它需要以接近光速的速度发送到下一个node，这个时间也就是传播时延。所以说传播时延发生在传输时延之后。 节点总时延(total nodal delay) = 节点处理时延(nodal processing delay)+排队时延(queueing delay)+传输时延(transmission delay)+传播时延(propagation delay) Queuing Delay and Packet Loss 我们假设a代表分组到达某个节点队列的平均速率(packets/s)，假设每个分组都有L bits，R(bit/s)为传输速率(即从队列中推出bits的速度)，那么我们可以得到一个流量强度(traffic intensity)的表达式：La/R La/R越接近0，代表排队时延越小；La/R越接近1，代表排队时延越大，并且离1越近，时延上升的越快；La/R大于1，则bit到达队列的平均速率超过从该队列传输除去的速率，那么这个队列趋向于无限增加，我们应该避免着这种设计。 La/R并不能完全代表排队时延，因为a只是一个平均速率，现实生活中的流量都是不规则的，有可能在短时间的内遇到很大的流量，那么排队时延就会很大 End to End Delay 前面我们讨论的都是一个节点上的时延，那么对于从源到目的地的时延(假设源主机与目的主机之间有N-1台路由器，并假设网络此时无堵塞，即没有排队时延)，那么：端到端时延 = N(节点处理时延(nodal processing delay)+传输时延(transmission delay)+传播时延(propagation delay)) TracerouteEnd System, Application, and Other Delays 除了上面提到的节点总时延，端到端还存在其他的时延，比如端系统中可能有一些其他的时延。 Throughput in Computer Networks数据吞吐量指的是在用户端，我们每秒可以接收到的比特数。在没有其他用户干扰的情况下，从一个主机到另一个主机的数据吞吐量取决于数据流过的链路中最小的传输速率，即吞吐量=min{R1, R2， R3…}。如果存在其他用户干扰(干扰流量)，那么由于需要和其他用户共享吞吐量，那么吞吐量就会相应减少 Protocal Layers and Their Service ModelsLayered Architecture 在讨论网络的分层前，书中有一个很好的将复杂系统分层的例子：航线功能。票务层： 票务购买 票务投诉行李层： 行李托运 行李认领登机口层： 登机口登机 登机口离机起飞/着陆层： 起飞 着陆飞行层： 按路线飞行 按路线飞行从图中我们观察到：1. 每个层次与它下面所有的层次结合在一起，实现了某些功能(服务)。比如在行李层及以下，实现了人和行李从行李托运到行李认领的转移；在登机口层及其以下，实现了人和行李从离岗登机口到到港登机口的转移，但登机口层的服务仅对完成了上两层的乘客有效。2. 每个层次的功能是通过结合在本层中执行某些的动作和使用直接下层提供的功能来达到的。行李层的功能是通过本层中执行某些的动作(行李托运/认领)和使用直接下层提供的功能(登机口层的功能)来达到的 利用分层的方式，我们可以将复杂的问题解耦并实现模块化，只要某个层的功能不改变，那么不论该层功能的实现方式如何改变，都不会影响整个系统。比如有一天登机口层不再按照头等舱-&gt;经济舱的顺序登机，而是按照身高登机，即我们对该层登机这一功能的实现方式进行了改变，结果是登机的功能以及其它层完全没有受到影响，乘客还是正常的进行了登机。 Protocal Layering 网络的实现与前面的例子是类似的，网络的设计者以分层的方式组织协议以及实现这些协议的网络硬件和软件。同样的，每次通过在该层中执行某些动作或使用直接下层的服务来提供服务，例如由第n层提供的服务可能包括报文从网络的一边倒另一边的可靠交付，这可能是通过第n-1层的边缘到边缘的不可靠报文传送服务，加上第n层的检测和重传丢失报文的功能来实现的。 一个协议层能够用软件，硬件或两者的结合来实现。诸如HTTP和SMTP这样的应用层协议几乎都是在端系统中用软件实现的，运输层协议也是如此。因为物理层和数据链路层负责处理跨越特定链路的通信，它们通常在与给定链路相关联的网络接口卡中实现。网络层经常是硬件与软件的的混合体。 应用层：应用层是与我们人类打交道的地方，负责把人类的语言转化可以在端系统间传输的信息。应用层协议主要包括HTTP，SMTP和FTP。DNS服务也是基于应用层的协议。应用层协议分布于多个端系统上，一个端系统中的应用程序使用协议与另一个端系统中的应用程序交换信息分组，这样的信息分组我们叫做报文(message)。 运输层：应用层将人类的语言转化为可传输的信息后，运输层负责在应用程序端点之间传送应用层报文。运输层有两种协议：TCP和UDP，它们都可以运输应用层报文。区别是TCP是一种面向连接的服务，确保应用层报文能够发送到目的地，并提供了流量控制和拥塞控制。UDP提供无连接服务，没有可靠性，也没有流量控制和拥塞控制。运输层的分组我们叫做报文段(segment)。 网络层：运输层提供在应用程序间的报文段运输，但是应用程序是跑在主机上的，负责由报文段有一个主机移动到另一个主机是由网络层来负责的。网络层有著名的IP协议，所以实现了网络层的因特网组件都必须运行IP协议，同时路由选择协议也属于网络层。网络层的分组我们叫做数据报(datagram) 数据链路层： 网络层负责在主机间传送datagram，但是这一过程中会经过很多条通信链路，在通信链路上如何运输是由数据链路层负责的。链路层协议包括以太网，WIFI等。链路层的分组称作帧(frame)。 物理层： 链路层的任务是将整个frame从一个网络节点移到下一个网络节点，物理层的任务是将该frame中的一个个比特从一个节点移动到下一个节点。比如，以太网具有很多物理层协议，有关于双绞铜线的，有关于同轴电缆的。 The OSI model 除了因特网五层协议栈，还有OSI七层协议栈。OSI在应用层和运输层之间增加了表示层和会话层。 Encapsulation 书中的图1-24展示了封装的原理，也就是每一层的分组通常由两部分封装：首部字段和有效载荷字段(payload field)，首部字段是本层增加的信息，有效载荷字段来自于上一层。比如运输层向网络层传递报文段，网络层会在头部添加源和目的端系统地址等IP信息。 由图中还可以看出，网络中的路由器实现了1-3层，也就是物理层到网络层，所以路由器可以使用IP地址寻址和路由；链路层交换机只实现了1-2层，也就是物理层和数据链路层，所以交换机是不能进行识别IP地址并路由的，但是它可以识别以太网地址。 Application LayerPrinciples of Network Applications 网络应用程序(软件)运行在端系统(网络边缘)上，它不能也不允许运行在网络核心(交换机和路由器)上，因为这些网络核心不包括应用层，他们往往只有网络层及其以下的层。 Network Application Architectures 网络应用程序主要分为两种架构：客户-服务器架构(client-server architecture)，对等(P2P)架构(peer-to-peer architecture) 客户-服务器架构有一个一直运行的服务器，服务器有一个固定的IP地址。所有向服务器发出请求的端系统叫做客户，客户与客户之间不会直接交流。 P2P架构是一种去中心化的架构，peer之间直接交流传递信息，没有客户和服务器之分。 很多应用混合了两种架构模式，比如很多实时聊天应用，服务器会跟踪客户的IP地址，但是客户之间的信息是直接互相传递的(不经过服务器) Processes Communicating 在构建网络应用程序前，还需要对运行在多个端系统上的程序是如何互相通信的有所了解。用操作系统的术语来说，进行通信的实际上是进程(process)而不是程序。当多个进程运行在相同的端系统上时，它们使用进程间通信机制相互通信，而对于网络应用程序，我们需要的是运行在不同终端上的进程间的通信。 在一对进程之间通信的场景中，发起通信的被认为是客户(client)，在会话开始时等待联系的进程是服务器(server) 报文从一个进程(应用层)发送到另一个进程(应用层)，需要经过下面的各种网络分层，进程是通过一个叫做套接字(socket)的软件接口向网络发送报文的。我们可以把套接字类比成门，进程是一所房子，当我们想要从房子中邮递一个包裹时，都需要先经过房子的门。套接字就是应用层和运输层之间的一层接口，当我们通过套接字发送一段报文后，我们就默认这段报文已经进入运输层了，剩下的事情就不是应用层需要考虑的了。 应用开发者可以控制套接字在应用层端的一切，但是对该套接字的运输层端几乎没有控制权。应用程序开发者对于运输层端的控制仅限于：1.选择运输层协议 2.也许可以设定几个运输层参数，比如最大缓存和最大报文长度。 一台端系统可以有多个进程在运行，那么如何区分哪个进程是在进行通信的那个呢？答案是使用端口号(port number)。所以IP地址加上端口号才能确定通信的真正地址。 Transport Services Provided by the internet TCP是一种面向连接的运输层协议。这种连接是全双工的，即连接双方的进程可以在此连接上同时进行报文收发。同时TCP提供可靠地数据传送服务，通信进程能够依靠TCP无差错并按照相应顺序交付所有发送的数据。另外TCP还提供拥塞控制机制 UDP是一种不提供不必要服务的轻量级运输协议。UDP是无连接的，并且不提供可靠数据传送服务，也就是说UDP协议不保证报文能到达接收进程，不仅如此，即使到达接收进程的报文也可能是乱序到达的。 Application-Layer Protocols 上面我们讨论了进程间通过套接字发送和接收报文进行通信，但是如何构造这些报文？在这些报文中的各个字段的含义是什么？进程何时发送这些报文？这些都是由应用层协议定义的。 应用层协议定义了：1.交换的报文类型，例如请求报文或者响应报文 2.各种报文类型的语法，如报文中的各个字段及这些字段的描述 3.字段的语义，即这些字段中信息的含义 4.确定一个进程何时以及如何发送报文，对报文进行响应的规则 The Web and HTTPOverview of HTTP Web页面(也叫做文档, document)是由很多对象组成的，一个对象通常是一个HTML文件，一个JPEG图片或者一段视频。通常一个Web页面会有一个HTML基本文件(base HTML file)和很多引用对象，也就是说在这个HTML基本文件中嵌入了很多其他的对象的引用。 URL：http://www.someSchool.edu/someDepartment/picture.gif。http://www.someSchool.edu是主机名，/someDepartment/picture.gif是路径名 HTTP协议使用TCP协议作为它的运输层协议，当我们把一个HTTP请求通过套接字发送到TCP一段以后，HTTP协议就不再管这个请求时如何发送到另一端的，这些完全是由底层的分层来处理的。从这里我们就看出了分层的好处：HTTP不需要考虑是否会丢失数据或者数据的顺序问题，这些一律由下面的TCP层来考虑，应用层只需要按照HTTP协议将请求从套接字发送出去就好了。 HTTP协议是一种无状态协议，即使我们向某个服务器短时间内发送相同的请求，服务器也不会说相同的东西已经返回过了，相反的，服务器会完全忘掉之前的请求，每次收到新的请求都会重新返回。 Non-Persistent and Persistent Connections TCP是一种面向连接的运输层协议，在建立连接时需要先进行三次握手。那么一个问题来了：当我们使用HTTP协议获取一个Web页面的多个对象的时候，是每次都建立一个新的TCP连接，还是只使用一个建立好的连接？这其实就引出了HTTP的两种连接方式：非持续连接和持续连接。HTTP既可以使用非持续连接，也可以使用持续连接，虽然HTTP默认使用的是持续连接，但是在客户端和服务器端也是可以配置成非持续连接的。 如果我们采用非持续连接，从服务器向客户传送一个Web页面的步骤会是这样的(假设该页面含有一个HTML基本文件和10个JPEG图片，并且这11个对象位于同一台服务器，该HTML基本文件的URL为http://www.someSchool.edu/someDepartment/home.index)： HTTP客户进程向服务器www.someSchool.edu的80端口发起一个TCP连接 HTTP客户经过套接字发送一个HTTP请求报文，该请求报文包含了路径名/someDepartment/home.index HTTP服务器经过它的套接字收到该请求报文，从其存储器(RAM或磁盘)中检索出目标对象，封装成一个HTTP响应报文，并通过套接字发送 HTTP服务器进程通知TCP断开该TCP连接(但是TCP直到确认客户已经完整的收到响应报文时，它才会实际中断连接) HTTP客户接收响应报文，TCP连接关闭。分析报文发现里面还有其他十个对象的引用 对每个JPEG图片对象重复前四个步骤 我们定义RTT是一个分组从客户到服务器再返回的时间，由于TCP连接需要进行三次握手，所以传递一个Web对象所需的时间大概是2RTT+传输Web对象所用的时间 由上面我们可以看出非持久连接有两个缺点：1.过多的连接会加重服务器的负担 2.每建立一个TCP连接都需要2RTT的时延，这样导致时延增大 对于HTTP1.1的持续连接来说，一个TCP连接可以发送多个Web对象请求，这些请求可以一个接一个的发出，而不必等待未决请求的回答 HTTP Message FormatHTTP Request Message HTTP请求的基本格式可以参照书中的图片，分为请求行(Request line), 首部行(Header lines), Entity body。一个例子如下： 123456GET /somedir/page.html HTTP/1.1Host: www.someschool.eduConnection: closeUser-agent: Mozilla/5.0Accepy-language: fr 第一行是request line，request line有三个部分组成：the method field，the URL field，HTTP version field。 接下来四行是header lines。Host说明了我们想要请求的Object所在的主机，这个看起来没用，因为我们已经建立了客户到服务器的TCP连接，但是这个header在web proxy的时候是有用的；Connection:close的意思是这个HTTP请求使用非持久连接；User-agent说明了客户端使用的的浏览器类型，这个header的作用在于服务器会根据客户浏览器类型的不同来发送不同形式的同一个web对象；Accept-language代表用户想要一个法语版本的web对象，如果没有的话服务器会发送一个默认版本。 上面的例子我们使用的是GET方法，如果使用POST方法的话，可以在Entity body部分放入想要发送的数据，需要注意的是Header lines和Entity body之间有一个空行。 HTTP的请求主要有GET, POST, HEAD, PUT, DELETE。HEAD与GET类似，但不会返回请求的web对象；PUT常用于上传；DELETE常用于删除 HTTP Response Message HTTP响应的基本格式可以参照书中的图片，分为状态行(Status line)，首部行(Header lines)，Entity body。一个例子如下： 123456789HTTP/1.1 200 OKConnection: closeDate: Tue, 18 Aug 2015 15:44:04 GMTServer: Apache/2.2.3 (CentOS)Last-Modified: Tue, 18 Aug 2015 15:11:03 GMTContent-Length: 6821Content-Type: text/html(data data data data data ...) 第一行是status line，由三个部分组成：the protocal version field, a status code, a corresponding status message。这个例子中使用的是HTTP 1.1版本，请求一起正常。 Connection: close告诉客户TCP连接将被断开在发送完报文以后；Date显示HTTP请求建立的时间，注意这个时间不是web对象创建或者最后一次修改的时间，而是服务器从系统中获取该web对象并发送出去的时间；Server显示报文是由一个Apache服务器发出去的；Last-Modified会在后面的web proxy部分讲解；Content-Length显示web对象含有多少bytes；Content-Type显示web对象时HTML文档 常见的HTTP状态码： 200 OK(请求成功，请求的信息包含在响应中)；301 Moved Permanently(请求的对象已经过被永远移走了，新的URL在Location这个Header那里，客户的软件会自动去获取新的URL)；400 Bad Request(服务器无法理解请求)；404 Not Found(请求的对象不存在于服务器中)；505 HTTP Version not Supporter(HTTP版本不支持) 除了上面我们提到的首部行，还有其他许多的首部行，客户或者服务器端根据相应的配置来增加需要的首部行 User-server Interaction: Cookies 前面我们提到过，HTTP协议是一种无状态(stateless)的协议，但是很多时候网站需要识别用户，比如在购物网站将物品接入购物车，我们希望下一次打开这个网站的时候，购物车里的物品仍旧存在。开发者为了实现中断和继续等操作，将user agent和server之间一对一的交互，抽象为“会话”，进而衍生出“会话状态”，也就是session的概念。session的相关信息会储存在服务器端，客户与服务器之间传递这个session信息可以使用cookie技术。 Cookie技术由四部分组成：1)HTTP响应中一个cookie首部行 2)HTTP请求中一个cookie首部行 3)一个保存在客户端并由浏览器管理的cookie文件 4)网站端用于存储cookie的后端数据库 下面我们用在亚马逊购物的例子来讲解cookie的原理： 当我们第一次访问亚马逊网站的时候，亚马逊将我们的请求识别为新的用户，并创建一个唯一识别码(session ID)，并且在HTTP响应中加入Set-cookie首部行，比如：Set-cookie: session-id=1678。当我们的浏览器收到这个HTTP响应后，发现里面有一个Set-cookie首部行，于是在他管理的cookie文件的最后面加上新的一行，这一行包括这个服务器的域名和返回的唯一识别码。随后当我们的浏览器再次访问亚马逊网站的时候，浏览器查询到cookie文件中有相应的cookie识别码，于是在以后所有对亚马逊网站的HTTP请求中都加入Cookie: 1678首部行。亚马逊服务器收到HTTP请求并根据相应的cookie唯一识别码，可以知道所有我们之前在网站中的活动情况。虽然网站不知道我们是谁，但是对我们的活动一清二楚，如果以后我们在亚马逊注册了账号，这个session ID也就会和账号绑定在一起，亚马逊也就知道我们所有的历史活动 Session与cookie：https://www.zhihu.com/question/19786827. 总结来说，session是服务器端保存的一个数据结构，用来跟踪用户的状态，Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session信息交互的一种方式，Cookie技术完全可以用来保存一些别的信息，而不只是保存session信息。 Web Caching web缓存器，也叫做代理服务器，是介于客户与服务器之间的一个中间服务器。web缓存器有自己的磁盘存储空间并且后保存最近请求过的对象的副本。所有的浏览器都可以配置成先定向到某个web缓存器。 如果我们将浏览器设置了代理，并且请求对象http://www.someschool.edu/compus.gif，那么将会发生： 浏览器创建一个TCP连接到web缓存器，并向web缓存器中的对象发送一个HTTP请求 web缓存器进行检查，看看本地是否存储了该对象副本。如果有，web缓存器就向客户浏览器用HTTP响应报文返回该对象 如果web缓存器中没有该对象，它就打开一个与该对象的初始服务器的TCP连接并请求该对象。初始服务器向微博、缓存器返回含有该对象的HTTP响应 web缓存器收到该对象后，在本地储存一份副本，并向客户返回这个对象 公司或者学校一般会安装代理服务器，这样如果有相同的请求发送到代理服务器上，那么代理服务器可以直接返回，不需要再去请求原服务器，这样减少了不必要的网络流量并且减少了响应时间(书中有一个对于有无web缓存器的响应时间的比较)，而且一般公司或者学校服务器的局域网比起互联网有较大的带宽。 web缓存器有很多的好处，但是缓存的一个重要问题就是缓存的对象是否没有过期。这里web缓存器使用一种conditional GET请求。我们知道web缓存器会保存一份对象的副本，同时它也会保存从服务器收到的Last-Modified首部行，当有相同的请求到达web缓存器的时候，web缓存器会先向原服务器发送一个conditional GET请求，也就是在这个HTTP请求中后加入一个If-modified-since的首部行，这个If-modified-since首部行的值就是之前web缓存器储存的Last-Modified首部行的值。服务器收到conditional GET请求后，会比较本地的对象最后改动的时间与If-modified-since首部行的值，如果对象在这个值之后进行了改动，那么就会返回一个200 Success并附上新的对象；如果没有改变，会返回一个304 Not Modified并且entity body为空，web缓存器在收到304后知道可以安全的使用现有的缓存。我们使用的web浏览器都自带缓存功能。 上面提到的是正向代理，现在还有流行的反向代理技术。正向代理所代理的是客服端，也就是代理服务器在客户一端进行代理与缓存；反向代理代理的是服务器端，也就是代理服务器在服务器一端进行代理与缓存，这里书中没有介绍，后面自己要进行深入学习。 Electronic mail in the Internet 电子邮件系统由三部分组成： 用户代理(user agent)，邮件服务器(mail server)，简单邮件传输协议(Simple mail Transfer Protocal, SMTP)。我们用Alice给Bob发邮件来举例说明邮件系统是如何运作的：Alice和Bob都各有一个用户代理，各自的用户代理也都使用各自的邮件服务器，当Alice在用户代理端编辑好邮件后，邮件先被发送到Alice端的邮件服务器，Alice短的邮件服务器尝试使用SMTP协议发送邮件到Bob端的邮件服务器，Bob的用户代理尝试从Bob端的邮件服务器取得邮件。 SMTP SMTP使用TCP作为底层传输协议，邮件从发送方服务器使用SMPT建立一个TCP连接到接收方服务器，SMTP不会使用中继服务器，即使两个email服务器在地球的两端，它们也会直接建立TCP连接。 SMTP使用持续连接 书中有关于使用SMTP协议命令建立握手的例子，后面应该使用telnet进行实践操作文章的方法实现了SMTP发邮件：https://stackoverflow.com/questions/1516754/connecting-to-smtp-gmail-com-via-command-line, 中间有一个报错(535-5.7.8 Username and Password not accepted.)，原因是需要去google账号里允许安全性较低的应用访问4. 使用telnet练习书中电子邮件的例子 telnet并不能连接现代email service因为现代email都是基于SSL的。按照这篇 Comparision with HTTP HTTP是pull protocol，TCP连接是由想要拉取信息的客户端建立的；SMTP是push protocal，TCP连接是由发送方服务器建立的 SMTP只支持7位ASCII码，HTTP没有这个限制 Mail Message Format 当使用SMTP协议命令建立好连接后，我们可以发送邮件的内容，邮件的内容包括body和headers，两者之间用一个空行隔开。常见的headers如下： 123From: alice@crepes.frTo: bob@hamburger.eduSubhect: Searching for the meaning of life Mail Access Protocols 90年代以前，接收方客户代理是直接登录到接收方邮件服务器去查看邮件的，因为SMTP是一个push请求，接收方需要的是一个pull请求，所以这个过程不能使用SMTP协议。相反的从发送方代理到发送方服务器是一个push请求，所以使用的是SMTP协议。 为了解决上面的问题，产生了很多邮件访问协议，包括Post Office-Version 3(POP3)，Internet Access Protocal(IMAP)和HTTP POP3是一种很简单的邮件访问协议，分为两种模式download-and-delete和download-and-keep。使用前者的模式，在一台机器上查询过邮件后无法在另一台机器上看到，使用后者的模式可以在多台机器上访问同一邮件。 IMAP邮件访问协议相比POP3更加复杂，增加了folder功能，我们可以在邮件服务器中创建相应的folder来管理邮件 现如今，越来越多的邮件供应商使用HTTP来作为用户代理与邮件服务器之间的协议。发送方从客户代理(browser)发送邮件到服务器不再使用SMTP，而是使用HTTP；接收方使用HTTP协议从服务器拉取邮件到浏览器端，而不再使用POP3或者IMAP。但是，服务器与服务器之间的传输仍旧使用SMTP DNS-The Internet’s Directory ServiceServices Provided by DNS 在计算机网络中，可以根据主机名或者IP地址来识别一个主机。对于人类来说，我们习惯使用主机名因为它便于记忆，但是路由器喜欢使用定长的，有着层次结构的IP地址。因此我们需要一种类似字典的服务，将我们人类喜欢的主机名翻译成IP地址，以进一步建立TCP连接。 DNS(domain name system)是一个由分层的DNS服务器实现的分布式数据库，DNS也是一个应用层协议，底端运输层使用UDP，默认端口是53 DNS是被其他应用层协议广泛使用的协议，当给我们的浏览器使用HTTP协议访问网站的时候，第一件事要做的就是使用DNS协议通过主机名获取IP地址。浏览器会提取我们想要访问的主机名，然后本机的DNS客户端向DNS服务器请求这个主机名的IP地址，收到响应后浏览器才能建立TCP连接。 DNS除了有进行主机名到IP地址的转换的功能，还有以下的功能： 主机别名(host aliasing)：有些主机有着复杂的主机名，为了方便人们记忆，我们可以为这个复杂的主机名起多个别名。比如一台名为relay1.west-cost.enterprise.com的主机，可能有两个别名为enterprise.com和www.enterprise.com。这种情况下，我们把relay1.west-cost.enterprise.com称为规范主机名(canonical hostname)。注意，只有在有别名的情况下，对应的我们才有规范主机名这一说，加入一个主机名足够简单并且没有别名，比如www.google.com，那么也就不存在规范主机名。 DNS的一大作用就是可以通过别名，得到规范主机名和其IP地址 邮件服务器别名(mail server aliasing)：与上面提到的主机别名一样，有些邮件服务器的主机名可能更为复杂，比如规范主机名可能是relay1.west-coast.hotmail.com，我们也可以为复杂的邮件服务器主机起别名，甚至一个公司的邮件服务器和web服务器可以使用相同的别名，这是通过MX记录实现了。 负载分配(load distribution)：DNS也被用于某些复制服务器上，对于一些繁忙的站点，往往需要有多个复制的服务器运行在不同的端系统上，每个服务器都有着不同的IP地址。这些IP地址集合会与一个规范主机名相联系，当有客户请求这个规范主机名的时候，DNS服务器会返回所有这些IP的集合，但是在每次返回之前都会循环这些地址的次序。因为客户总是选择IP地址排在最前面的服务器发送HTTP请求，所以DNS就在这些相同的服务服务器之间实现了负载分配。 Overview of How DNS works 我们可以把DNS看成一个分布式，有层次的数据库，没有一台DNS服务器拥有因特网上所有主机的映射。大致来说有三种类型的DNS服务器：根服务器(root DNS servers)，顶级域(Top-Level Domain, TLD)服务器和权威服务器(authoritative DNS servers)。当我们想要查询www.amazon.com的IP地址的时候，DNS客户端会先去根服务器上查找并返回com这一顶级域服务器的IP地址，随后DNS客户端去.com这一顶级域服务器查找并返回amazon.com这一权威服务器的IP地址，最后客户端从amazon.com这一权威服务器中找到www.amazon.com的IP地址。 世界上有400多个根服务器，分布于世界各地。根服务器只负责提供顶级域服务器的IP地址。当我看书看到这里的时候，产生了一个疑问，明明使用dig +trace www.google.com的时候，只返回了13个根服务器，为什么书中要说有400多个根服务器呢？所以我尝试dig +trace a.root-servers.net，返回的结果是a.root-servers.net. 3600000 IN A 198.41.0.4。我在网络上搜索这个IP地址，地点位于堪萨斯州，隶属于VeriSign Infrastructure公司。这个时候我想，难道是因为我的本地DNS在美国，所以返回的是离我最近的A root根服务器的IP？所以我尝试把本地DNS切换成百度的DNS服务器，拿到的IP地址仍然是198.41.0.4。原因是世界上原本只有13个根服务器，至于为什么是13，有专门的文章介绍，其他的根服务器都是镜像服务器，但是所有相同的镜像服务器与其对应的根服务器都有相同的IP地址，这里使用了Anycast技术。这就是为什么我怎么查询A root根服务器的IP地址都不会变。https://segmentfault.com/a/1190000023696737 顶级域服务器包括com，org，net，edu，gov以及国家的顶级域uk，cn，jp等。顶级域服务器负责提供权威服务器的IP地址 权威服务器中可能存有我们想要查找的主机名的IP地址，也可能这个权威服务器没有，那么这时候它会返回一个下一级的权威服务器，直到找到我们需要的主机的IP地址。比如我们想要寻找toy.amazon.com的IP地址，可能在dns.amazon.com这一权威地址就存储了toy.amazon.com的IP地址，也可能dns.amazon.com告诉我们它这里，诶呦，我么应该去dns.toy.amazon.com这个权威服务器去寻找。 除了上面提到的DNS服务器的层次结构，还有一种DNS服务器，并不隶属于前面的层次结构，但却十分重要，这就是本地DNS服务器，我们请求DNS的时候，不是直接去根服务器进行请求，而是去本地DNS服务器先进行请求。本地DNS服务器可以直接在电脑中设置，也就是说我可以设置本地DNS服务器为google提供的DNS服务器，也可以设置成baidu提供的，或者使用ISP提供的离我最近的DNS服务器，通常每人使用ISP提供的，因为速度最快。 DNS查询既可以是递归查询也可以是迭代查询，可以参考书中的图2.19和图2.20 DNS还有一个很重要的特性：DNS缓存。在一个请求链中，当某个DNS服务器接受一个DNS回答时，它能将结果存储在本地存储器中。这样的话，如果有一个相同的请求到达这个DNS服务器，直接返回结果。比如当我像本地DNS服务器请求Google.com的IP地址的时候，大概率已经被其缓存过了，所以根本不需要经过本地服务器-&gt;根服务器-&gt;TLD服务器-&gt;权威服务器这一条线。所以其实除了某些很冷门的顶级域，大部分的顶级域比如com的DNS服务器的IP地址都已经被缓存了，我们的请求根本不会经过根服务器。 DNS records and messages 前面我们说了，DNS是一个分布式的数据库，存储在数据库中的数据叫做资源记录(resource records, RRs). 一条资源记录是一个四元组：(Name, Value, Type, TTL)。 TTL是一条资源记录的生存时间，它决定了什么时候这条记录会从缓存中被删除。Name和Value的含义取决于Type的值。 如果Type=A，代表是Address record，那么Name就是一个主机名，Value是其对应的IP地址。(relay.bar.foo.com, 145.37.93.126, A) 如果Type=NS，代表的是Name server record，那么Name是一个域，Value是一个知道如何获得该域中主机IP地址的权威服务器的主机名。(foo.com, dns.foo.com, NS)。所以NS记录是帮助我们一步一步在DNS查找链中前进的记录，比如在根服务器中，一定会存储(com, dns.com, NS)这样的记录，这样我们才知道如果我们下一步要去dns.com这个com域的TLD服务器找DNS。 如果Type=CNAME，代表的是Canonical name record，那么Name是一个别名，Value是对应的规范主机名(真名)。(fake.liushiy.com, www.web.liushiy.com, CNAME) 如果Type=MX，代表的是Mail exchange record，那么Name是一个别名，Value是对应的规范邮件主机名(真名)。(fake.liushiy.com, www.mail.liushiy.com, CNAME)。这里我们可以看到，我们可以为邮件服务器和web服务器起相同的别名，当搜索DNS的时候，如果需要的是邮件服务器的真名，那么DNS客户端会去请求MX记录，如果需要的是其他服务的服务器真名，那么DNS客户端会去请求CNAME记录。 如果一台DNS服务器是用于某特定主机名的权威服务器，那么这个服务器中会有一条关于该主机名的A记录，这样客户端在到达这个DNS服务器的时候就可以通过主机名获取到IP地址了。当然大多数时候由于缓存的存在，即使某个服务器不是特定主机的权威服务器，也会存有缓存有相应的A记录。如果某个DNS服务器不是某个主机的权威服务器，那么它将存有一条NS记录，该记录给我们提供可能找到该主机DNS信息的权威服务器的主机名，这里可能有个疑问，也就是说只有一个A记录我们是不能继续往下进行链式搜索了，因为我们只知道主机名不知道IP地址，那么答案是这种服务器除了有一个NS记录外，也会存一个A记录，这个A记录的Name就是NS记录的Value。还是上面的例子，我们有个(com, dns.com, NS)这样一条NS记录，我们是没法去到dns.com这个TLD服务器的，所以还会有一条(dns.com, 123.123.123, A)的A记录。 DNS报文及它的内容见书中的图2.21DNS服务器和一个辅助权威DNS服务器，名字分别为dns1.network.com(212.212.212.1)和dns2.network.com(212.212.212.2)，域名注册机构会把这两个权威服务器的NS记录和A记录插入到TLD服务器中，同时我们还需要确保我们的域名的A记录插入到这两个权威服务器中。 前面我们讨论的都是如何获取DNS的记录，那么如何在DNS数据库中插入记录呢？答案是有专业的域名注册登记机构，将域名输入DNS数据库。假设我们的某个域名(www.liushiy.com)有一个基本权威 Peer-to-Peer File Distribution P2P比起client-server的优势在于client-server只有服务器在上传文件，其他的客户都是在下载，那么客户的上传速率就被浪费了，而P2P所有的用户都参与上传和下载。所以当分享同一个文件的时候，用户数量越多，P2P效果越好。具体的计算见书中。 P2P最有名的协议是BitTorrent，比较复杂，书中也只是简单提了一下。P2P这块比起前面几小节没那么重要。 Video Streaming and Content Distribution NetworksContent Distribution Networks 对于请求流量很大的网站或者视频网站，CDN技术有很大的帮助。CDN的原理是把一个网站的内容拷贝到世界各地的镜像内容分发网站，当用于请求内容的时候，会自动去到最近的CDN服务器中获取内容，而不需要全部去到中心服务器中，这样可以减少中心服务器的流量。很多有大量客户的网站或者视频网站都会自己建立或者购买CDN服务。 CDN服务本质上是一种web cache，他不会直接储存中心网站的所有内容，而是当有用户请求的时候，他再去中心网站拉去请求，在返回给客户的同时在自己本地缓存，这样如果有其他客户请求相同的内容，就可以直接返回了。 上面我们提到当客户请求内容的时候，会自动的去最近的CDN服务器请求，这是怎么办到的呢？答案是使用DNS技术，比如假设我们去Youtube请求一个视频，Youtube的权威服务器不会返回Youtube网站的IP地址，而是返回Youtube购买或自建的CDN网站的域名，比如a1105.somecdncompany.com。后面我们对于DNS的请求就进入了somecdncompany的私有DNS架构中了，它使用特定的算法返回给客户最近的CDK服务器的IP地址，于是客户就去到这个CDN服务器去请求内容了。 Wireshark DNS Lab DNS Lab使用的查询DNS的命令式nslookup，但是nslookup不支持迭代查询，这一点上不如dig +trace好用 nslookup -type=NS www.tencent.com的意思是寻找www.tencent.com的权威服务器，测试的时候我用dig +trace找到了腾讯的权威服务器。第一个块的意思是我们在c.gtld-servers.net这个服务器上找到了tencent.com.的NS记录，指向了四个权威服务器；接着在ns1.qq.com这个服务器上找到了www.tencent.com.的NS记录，也指向了四个权威服务器。在实验的时候，我很傻的跑了一句nslookup -type=NS www.tencent.com ns-tel1.qq.com，结果是没有answer。www.tencent.com. 86400 IN NS ns-tel1.qq.com.的意思是www.tencent.com.的权威服务器是ns-tel1.qq.com.，我跑的那句命令的意思是去www.tencent.com的权威服务器找它的权威服务器，这怎么可能找得到呢？自己怎么可能找到的自己呢？ 123456789101112131415tencent.com. 172800 IN NS ns1.qq.com.tencent.com. 172800 IN NS ns2.qq.com.tencent.com. 172800 IN NS ns3.qq.com.tencent.com. 172800 IN NS ns4.qq.com.CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN NSEC3 1 1 0 - CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAMCK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN RRSIG NSEC3 8 2 86400 20210824042516 20210817031516 39343 com. KAjDyjYoqq6PKGIFiVPSK63PL7G5kZs+/SibL2EvQnqc4CiS0vAuZ2LB p2cdbwFEH2Il3EUIzlH3AbXtlRzyZbpd7X4teLX1ZPX/f2gx6nwFK2A3 j+RzmROGkNAi/VOwvhv52We58iGCar+a54Yu+XfWu8PUi97228adtyhl E4sXQnx1rgyn5qzzTYg5B4yEMWKTCUK7tSo8RLFt/Wp+MA==VF2UKFM00JNRDJOAMAOL6M4S6MI030VN.com. 86400 IN NSEC3 1 1 0 - VF2UTHOP0RH8T5MV2F5D6VIBH626EP7Q NS DS RRSIGVF2UKFM00JNRDJOAMAOL6M4S6MI030VN.com. 86400 IN RRSIG NSEC3 8 2 86400 20210824044708 20210817033708 39343 com. e6zgkDoZSwzs5S9EFGgPVDKgvHvGrPkud6Ro8Qs2pPUYlmGiE2q2wFEt vOXA1VYU3izMpiYyDoDYHOwolBPIHEibdG/cF632wKAOJM+LPAJYDt0v zwQOZZrYhJ40WOSP9P/BtDTL7rmO3H5YnXbNUzle1d8AhEslIhAqix0c AlUL/oag1yovBIKo9/FAa8NNjx+Ub36FE3FDcF8c2uQ1zw==;; Received 996 bytes from 192.26.92.30#53(c.gtld-servers.net) in 1033 mswww.tencent.com. 86400 IN NS ns-cnc1.qq.com.www.tencent.com. 86400 IN NS ns-os1.qq.com.www.tencent.com. 86400 IN NS ns-cmn1.qq.com.www.tencent.com. 86400 IN NS ns-tel1.qq.com.;; Received 398 bytes from 157.255.246.101#53(ns1.qq.com) in 301 ms 12345shiyuliu@Shiyu-MacBookPro:~ $ nslookup -type=NS www.tencent.com ns-tel1.qq.comServer: ns-tel1.qq.comAddress: 123.151.66.83#53*** Can't find www.tencent.com: No answer DNS案例分析：对www.tencent.com进行DNS分析，经过层层NS记录查找，在ns-cnc1.qq.com这个服务器找到www.tencent.com的化名www.tencent.com.cdn.dnsv1.com。随后对这个主机名进行新一轮的查找，经过层层NS记录查找，在d.dnspood.net这个服务器找到www.tencent.com.cdn.dnsv1.com的化名lffgjgyi.tweb.sched.ovscdns.com。最后对这个主机名进行层层查找，最后找到多条A记录，也就是腾讯服务器的真实IP地址。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455shiyuliu@Shiyu-MacBookPro:~ $ dig +trace www.tencent.com; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; +trace www.tencent.com;; global options: +cmd. 479895 IN NS b.root-servers.net.. 479895 IN NS c.root-servers.net.. 479895 IN NS d.root-servers.net.. 479895 IN NS e.root-servers.net.. 479895 IN NS f.root-servers.net.. 479895 IN NS g.root-servers.net.. 479895 IN NS h.root-servers.net.. 479895 IN NS a.root-servers.net.. 479895 IN NS i.root-servers.net.. 479895 IN NS j.root-servers.net.. 479895 IN NS k.root-servers.net.. 479895 IN NS l.root-servers.net.. 479895 IN NS m.root-servers.net.. 479895 IN RRSIG NS 8 0 518400 20210901050000 20210819040000 26838 . CO4nAv6FI9pIG3VzDOEtvle2R1OqByvjG5H1w1J47bTlf5aisb49aPfH Fy9IgBL1ffeRC9J7L1k3cf/78zDpTKhgdwN2oE6hRFifODgba7FPsU2u 3W2Bk0NJE6kapJDjX6HTnUnFmpMhHEHR2zPqIa9IgSgIrrJL7TdL0a+8 JFSafxfKGHmGXRjIglLkImcoEk+D4DETIhhWNjyOaQ7aFo3iioeijk/M oVE+9v/hPrr4djB3bfIGfI4TDAdUWegCILe0LLXXG20RTpMtqYNL5d1R 1rzPWMIlnLD6HwBOQTsidSa86MnWIJOv6lpXfVTeDRF639ThkooW978z BFzEQQ==;; Received 1097 bytes from 192.168.0.1#53(192.168.0.1) in 14 mscom. 172800 IN NS a.gtld-servers.net.com. 172800 IN NS b.gtld-servers.net.com. 172800 IN NS c.gtld-servers.net.com. 172800 IN NS d.gtld-servers.net.com. 172800 IN NS e.gtld-servers.net.com. 172800 IN NS f.gtld-servers.net.com. 172800 IN NS g.gtld-servers.net.com. 172800 IN NS h.gtld-servers.net.com. 172800 IN NS i.gtld-servers.net.com. 172800 IN NS j.gtld-servers.net.com. 172800 IN NS k.gtld-servers.net.com. 172800 IN NS l.gtld-servers.net.com. 172800 IN NS m.gtld-servers.net.com. 86400 IN DS 30909 8 2 E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CF C41A5766com. 86400 IN RRSIG DS 8 1 86400 20210901170000 20210819160000 26838 . LHS6RGFU2XE72HDMmEXCGuWJCaMO36pnSrAQ4ziSXN+7Jm+FZu0+CE9t rCq5oKF5DqGTAmq6lA4vo2kPcZy8ywQy4Nq1cGUwXlHvZk+4MZsqffJg mDZMrdNBuYG+EcN8v+oa9DXMSwOYMnesilFHhhUpTLRPet/WeQzVt1Gg 5APdWPwd6LkNNA+0ir3BXpmg0gFsPNNdNKzq0x7tHA8mMt57gNb+iFP9 9zcVhQ0FnPfdUR2hKG9N7YKcWgxHskshFGnfQ0JyDfFwwNOnkBJGBh++ 52iwqEoqsIsJwn/Mov0qCgImX6jhFB4eGVYh2bStWQfZmpeqzxsPtflE EoXiWg==;; Received 1175 bytes from 199.9.14.201#53(b.root-servers.net) in 39 mstencent.com. 172800 IN NS ns1.qq.com.tencent.com. 172800 IN NS ns2.qq.com.tencent.com. 172800 IN NS ns3.qq.com.tencent.com. 172800 IN NS ns4.qq.com.CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN NSEC3 1 1 0 - CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAMCK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN RRSIG NSEC3 8 2 86400 20210824042516 20210817031516 39343 com. KAjDyjYoqq6PKGIFiVPSK63PL7G5kZs+/SibL2EvQnqc4CiS0vAuZ2LB p2cdbwFEH2Il3EUIzlH3AbXtlRzyZbpd7X4teLX1ZPX/f2gx6nwFK2A3 j+RzmROGkNAi/VOwvhv52We58iGCar+a54Yu+XfWu8PUi97228adtyhl E4sXQnx1rgyn5qzzTYg5B4yEMWKTCUK7tSo8RLFt/Wp+MA==VF2UKFM00JNRDJOAMAOL6M4S6MI030VN.com. 86400 IN NSEC3 1 1 0 - VF2UTHOP0RH8T5MV2F5D6VIBH626EP7Q NS DS RRSIGVF2UKFM00JNRDJOAMAOL6M4S6MI030VN.com. 86400 IN RRSIG NSEC3 8 2 86400 20210824044708 20210817033708 39343 com. e6zgkDoZSwzs5S9EFGgPVDKgvHvGrPkud6Ro8Qs2pPUYlmGiE2q2wFEt vOXA1VYU3izMpiYyDoDYHOwolBPIHEibdG/cF632wKAOJM+LPAJYDt0v zwQOZZrYhJ40WOSP9P/BtDTL7rmO3H5YnXbNUzle1d8AhEslIhAqix0c AlUL/oag1yovBIKo9/FAa8NNjx+Ub36FE3FDcF8c2uQ1zw==;; Received 996 bytes from 192.26.92.30#53(c.gtld-servers.net) in 1033 mswww.tencent.com. 86400 IN NS ns-cnc1.qq.com.www.tencent.com. 86400 IN NS ns-os1.qq.com.www.tencent.com. 86400 IN NS ns-cmn1.qq.com.www.tencent.com. 86400 IN NS ns-tel1.qq.com.;; Received 398 bytes from 157.255.246.101#53(ns1.qq.com) in 301 mswww.tencent.com. 60 IN CNAME www.tencent.com.cdn.dnsv1.com.;; Received 84 bytes from 116.128.153.20#53(ns-cnc1.qq.com) in 1324 ms 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849shiyuliu@Shiyu-MacBookPro:~ $ dig +trace www.tencent.com.cdn.dnsv1.com; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; +trace www.tencent.com.cdn.dnsv1.com;; global options: +cmd. 480233 IN NS d.root-servers.net.. 480233 IN NS e.root-servers.net.. 480233 IN NS f.root-servers.net.. 480233 IN NS g.root-servers.net.. 480233 IN NS h.root-servers.net.. 480233 IN NS a.root-servers.net.. 480233 IN NS i.root-servers.net.. 480233 IN NS j.root-servers.net.. 480233 IN NS k.root-servers.net.. 480233 IN NS l.root-servers.net.. 480233 IN NS m.root-servers.net.. 480233 IN NS b.root-servers.net.. 480233 IN NS c.root-servers.net.. 480233 IN RRSIG NS 8 0 518400 20210901050000 20210819040000 26838 . CO4nAv6FI9pIG3VzDOEtvle2R1OqByvjG5H1w1J47bTlf5aisb49aPfH Fy9IgBL1ffeRC9J7L1k3cf/78zDpTKhgdwN2oE6hRFifODgba7FPsU2u 3W2Bk0NJE6kapJDjX6HTnUnFmpMhHEHR2zPqIa9IgSgIrrJL7TdL0a+8 JFSafxfKGHmGXRjIglLkImcoEk+D4DETIhhWNjyOaQ7aFo3iioeijk/M oVE+9v/hPrr4djB3bfIGfI4TDAdUWegCILe0LLXXG20RTpMtqYNL5d1R 1rzPWMIlnLD6HwBOQTsidSa86MnWIJOv6lpXfVTeDRF639ThkooW978z BFzEQQ==;; Received 1081 bytes from 192.168.0.1#53(192.168.0.1) in 3966 mscom. 172800 IN NS a.gtld-servers.net.com. 172800 IN NS b.gtld-servers.net.com. 172800 IN NS c.gtld-servers.net.com. 172800 IN NS d.gtld-servers.net.com. 172800 IN NS e.gtld-servers.net.com. 172800 IN NS f.gtld-servers.net.com. 172800 IN NS g.gtld-servers.net.com. 172800 IN NS h.gtld-servers.net.com. 172800 IN NS i.gtld-servers.net.com. 172800 IN NS j.gtld-servers.net.com. 172800 IN NS k.gtld-servers.net.com. 172800 IN NS l.gtld-servers.net.com. 172800 IN NS m.gtld-servers.net.com. 86400 IN DS 30909 8 2 E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CF C41A5766com. 86400 IN RRSIG DS 8 1 86400 20210901170000 20210819160000 26838 . LHS6RGFU2XE72HDMmEXCGuWJCaMO36pnSrAQ4ziSXN+7Jm+FZu0+CE9t rCq5oKF5DqGTAmq6lA4vo2kPcZy8ywQy4Nq1cGUwXlHvZk+4MZsqffJg mDZMrdNBuYG+EcN8v+oa9DXMSwOYMnesilFHhhUpTLRPet/WeQzVt1Gg 5APdWPwd6LkNNA+0ir3BXpmg0gFsPNNdNKzq0x7tHA8mMt57gNb+iFP9 9zcVhQ0FnPfdUR2hKG9N7YKcWgxHskshFGnfQ0JyDfFwwNOnkBJGBh++ 52iwqEoqsIsJwn/Mov0qCgImX6jhFB4eGVYh2bStWQfZmpeqzxsPtflE EoXiWg==;; Received 1189 bytes from 199.7.91.13#53(d.root-servers.net) in 1024 msdnsv1.com. 172800 IN NS c.dnspood.net.dnsv1.com. 172800 IN NS d.dnspood.net.CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN NSEC3 1 1 0 - CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAMCK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN RRSIG NSEC3 8 2 86400 20210824042516 20210817031516 39343 com. KAjDyjYoqq6PKGIFiVPSK63PL7G5kZs+/SibL2EvQnqc4CiS0vAuZ2LB p2cdbwFEH2Il3EUIzlH3AbXtlRzyZbpd7X4teLX1ZPX/f2gx6nwFK2A3 j+RzmROGkNAi/VOwvhv52We58iGCar+a54Yu+XfWu8PUi97228adtyhl E4sXQnx1rgyn5qzzTYg5B4yEMWKTCUK7tSo8RLFt/Wp+MA==SQ33O0H4MV9I02VGSVRC1STI0J9S6AQL.com. 86400 IN NSEC3 1 1 0 - SQ348AROC5M6FCS12QPU0C1MPDTFTDM9 NS DS RRSIGSQ33O0H4MV9I02VGSVRC1STI0J9S6AQL.com. 86400 IN RRSIG NSEC3 8 2 86400 20210825041849 20210818030849 39343 com. Kj2RAJxb6DZfRiFTPMsH6Q45X6s9pgFlJkxO2NsJx+Gi/RBvRj6PDZ05 j+u6pqAU1MnMWyerJzD3IND6z9qm66uM+MHazukEOqPDctJrBgVyrQqe YT0QD0FpsojGcUAB6pGYxDFY9I5gLOWlYaDwNhyj9LNgurFMsDV1KP06 Y+HcXwJPoMkDrcPS2kFdupPMGmHEI/1m3Nz7bKc7pgo6CQ==;; Received 650 bytes from 192.54.112.30#53(h.gtld-servers.net) in 54 mswww.tencent.com.cdn.dnsv1.com. 600 IN CNAME lffgjgyi.tweb.sched.ovscdns.com.dnsv1.com. 86400 IN NS ns4.dnsv5.com.dnsv1.com. 86400 IN NS ns3.dnsv5.com.;; Received 157 bytes from 52.66.148.160#53(d.dnspood.net) in 1155 ms 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263shiyuliu@Shiyu-MacBookPro:~ $ dig +trace lffgjgyi.tweb.sched.ovscdns.com; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; +trace lffgjgyi.tweb.sched.ovscdns.com;; global options: +cmd. 478969 IN NS d.root-servers.net.. 478969 IN NS e.root-servers.net.. 478969 IN NS f.root-servers.net.. 478969 IN NS g.root-servers.net.. 478969 IN NS h.root-servers.net.. 478969 IN NS a.root-servers.net.. 478969 IN NS i.root-servers.net.. 478969 IN NS j.root-servers.net.. 478969 IN NS k.root-servers.net.. 478969 IN NS l.root-servers.net.. 478969 IN NS m.root-servers.net.. 478969 IN NS b.root-servers.net.. 478969 IN NS c.root-servers.net.. 478969 IN RRSIG NS 8 0 518400 20210901050000 20210819040000 26838 . CO4nAv6FI9pIG3VzDOEtvle2R1OqByvjG5H1w1J47bTlf5aisb49aPfH Fy9IgBL1ffeRC9J7L1k3cf/78zDpTKhgdwN2oE6hRFifODgba7FPsU2u 3W2Bk0NJE6kapJDjX6HTnUnFmpMhHEHR2zPqIa9IgSgIrrJL7TdL0a+8 JFSafxfKGHmGXRjIglLkImcoEk+D4DETIhhWNjyOaQ7aFo3iioeijk/M oVE+9v/hPrr4djB3bfIGfI4TDAdUWegCILe0LLXXG20RTpMtqYNL5d1R 1rzPWMIlnLD6HwBOQTsidSa86MnWIJOv6lpXfVTeDRF639ThkooW978z BFzEQQ==;; Received 1097 bytes from 192.168.0.1#53(192.168.0.1) in 3492 mscom. 172800 IN NS a.gtld-servers.net.com. 172800 IN NS b.gtld-servers.net.com. 172800 IN NS c.gtld-servers.net.com. 172800 IN NS d.gtld-servers.net.com. 172800 IN NS e.gtld-servers.net.com. 172800 IN NS f.gtld-servers.net.com. 172800 IN NS g.gtld-servers.net.com. 172800 IN NS h.gtld-servers.net.com. 172800 IN NS i.gtld-servers.net.com. 172800 IN NS j.gtld-servers.net.com. 172800 IN NS k.gtld-servers.net.com. 172800 IN NS l.gtld-servers.net.com. 172800 IN NS m.gtld-servers.net.com. 86400 IN DS 30909 8 2 E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CF C41A5766com. 86400 IN RRSIG DS 8 1 86400 20210901170000 20210819160000 26838 . LHS6RGFU2XE72HDMmEXCGuWJCaMO36pnSrAQ4ziSXN+7Jm+FZu0+CE9t rCq5oKF5DqGTAmq6lA4vo2kPcZy8ywQy4Nq1cGUwXlHvZk+4MZsqffJg mDZMrdNBuYG+EcN8v+oa9DXMSwOYMnesilFHhhUpTLRPet/WeQzVt1Gg 5APdWPwd6LkNNA+0ir3BXpmg0gFsPNNdNKzq0x7tHA8mMt57gNb+iFP9 9zcVhQ0FnPfdUR2hKG9N7YKcWgxHskshFGnfQ0JyDfFwwNOnkBJGBh++ 52iwqEoqsIsJwn/Mov0qCgImX6jhFB4eGVYh2bStWQfZmpeqzxsPtflE EoXiWg==;; Received 1191 bytes from 199.7.83.42#53(l.root-servers.net) in 1023 msovscdns.com. 172800 IN NS ns1.ovscdns.com.ovscdns.com. 172800 IN NS ns2.ovscdns.com.ovscdns.com. 172800 IN NS ns3.ovscdns.com.ovscdns.com. 172800 IN NS ns4.ovscdns.com.CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN NSEC3 1 1 0 - CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAMCK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN RRSIG NSEC3 8 2 86400 20210824042516 20210817031516 39343 com. KAjDyjYoqq6PKGIFiVPSK63PL7G5kZs+/SibL2EvQnqc4CiS0vAuZ2LB p2cdbwFEH2Il3EUIzlH3AbXtlRzyZbpd7X4teLX1ZPX/f2gx6nwFK2A3 j+RzmROGkNAi/VOwvhv52We58iGCar+a54Yu+XfWu8PUi97228adtyhl E4sXQnx1rgyn5qzzTYg5B4yEMWKTCUK7tSo8RLFt/Wp+MA==RVDEHMBPSB0379D5051JJP8Q8UU7FPEA.com. 86400 IN NSEC3 1 1 0 - RVDF6S6QPNNO8GHLHISI3D8FBAERQVJ1 NS DS RRSIGRVDEHMBPSB0379D5051JJP8Q8UU7FPEA.com. 86400 IN RRSIG NSEC3 8 2 86400 20210825155810 20210818144810 39343 com. YtSvi1oy1qGohuUdpmvYJwSdd4bKlB2+FeI1gqRY2Pqk9jLT+OMkpK6a UOljZEhReVGj+QLmqfZZg+410Zb0RNONLmFLUXBIsKHzIHpSaxlddjIb nqm/pbf0pjxb7IFi9iNV9BiovdBXjHBvASgYS5l+OgQGE6/63I1jyJK/ 930MqPgdcMpml/uW3rkipEVMkQrOQFk3K7FbGqvR7W6Jlw==;; Received 777 bytes from 192.26.92.30#53(c.gtld-servers.net) in 75 mslffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.44lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.99lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.146.90lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.84lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.72lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.30lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.146.99lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.146.98lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.146.86lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.29lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.78lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.43lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.77lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.149.16lffgjgyi.tweb.sched.ovscdns.com. 60 IN A 211.152.148.87;; Received 300 bytes from 203.205.194.114#53(ns2.ovscdns.com) in 1175 ms Transport LayerIntroduction and Transport-Layer Services 传输层协议为应用层进程提供逻辑通信。逻辑通信的意思是从应用的角度来看，主机间的进程似乎是直接连接在一起的，但实际上主机是通过很多路由器和通信链路连接在一起的，两台主机可能在地球的两端，他们只是从逻辑上是直接连接的，物理上并不是。 网络层与传输层的关系的一个类比：假设在东西海岸各有一个房子，A房子里有144个小孩，B房子里有这144个小孩的表哥，小孩和表哥之间每周都会互相写信。在每个房子，都有一个小孩负责收发信件(Ann在房子A，Bill在房子B)，每周Ann都会从所有的小孩那里收集新建，并且把信件投递给邮政服务，而另一端的Bill在收到这些信件后，会挨个分给每个小孩。在这个例子中，邮政服务提供了物理连接，它不负责为每个孩子之间提供连接，他只负责为两个房子之间提供连接，Ann和Bill提供了逻辑连接，因为它们负责每周的收发邮件。在孩子们的视角里，Ann和Bill就是他们的邮件系统，他们不需要知道后面发生了什么，只需要把信件发给Ann或者Bill就好了。应用消息=信件，进程=小孩，端系统=房子，传输层协议=Ann and Bill，网络层协议=邮政系统。 Ann和Bill只在两个房子里工作，他们不负责邮政系统的分拣邮件以及运输邮件，相同的，运输层协议只运作在两个终端，具体消息是如何在网络核心中传递的，运输层并不关心。 如果某一天Ann和Bill放假了，换了一对新人Susan和Harvey来接管邮件分发业务，这里我们就可以理解为运输层可以有多个新协议(TCP和UDP)。 Ann和Bill所能提供的服务是由邮政服务所限制的，比如如果邮政服务不能提供最大投递时间，那么Ann和Bill也不能可能保证邮件的最大头投递延迟，相同的，如果传输层的服务也被网络层所限制，如果网络层不能提供带宽和延迟保障，俺么运输层是无论如何也提供不了的。但是运输层可以提供某些网络层不提供的服务，比如可靠运输。 所以综上看来，传输层的最大作用是将网络中端到端的运输扩展为进程到进程的运输，端到端的运输由网络层负责，端到进程的运输由运输层负责，正因如此，运输层一个很重要的功能就是多路分解(transporter-layer multiplexing)和多路复用(transporter-layer demultiplexing)。同时运输层还提供一些网络层不具备的功能，比如拥塞控制和可靠运输。 Multiplexing and Demultiplexing 一台主机上会运行多个进程(比如同时看网页，发邮件，传文件)，但是传到这台主机的报文段都是统一从网络层获得的，那么运输层把相应的报文段发到对应的进程中(通过有唯一标识符的套接字，也就是端口号)，这就是多路分解。当从这些进程的套接字收集报文段并统一发送出去，这就是多路复用。 从上可知，运输层的多路分解和多路复用最重要的就是套接字的唯一标识符，也就是端口号，有了这个，运输层才知道把相应的报文发送到那个应用中去使用。所以传输层报文段长下面这个样子：32位Source port number | Destination port numberOther header fieldsApplication data(message)在传输层的报文段中最开始的就是源端口号和目的地端口号，各占16位(0-65535)，其中0-1023是一些周知端口号(well-known port numbers)。 UDP的多路复用与多路分解根据二元组：(Source port number, Destination Port Number)。接收端接收到报文段后根据Destination Port Number，把解析出来的应用层报文发送到对应的套接字中。 由于UDP的多路复用在解析的时候其实只是根据Destination Port Number，所以如果两个不同IP地址的主机，发送相同的信息到同一个IP地址和端口号的主机，那么他们会进入同一个套接字，也就进入了同一个进程。那么Source Port Number用在哪里呢？答案是用在返回信息的时候，根据上面的二元组，返回信息的时候就变成了(Destination port number, Source port number)，也就是源变成了目的地，目的地变成了源。 TCP的多路复用与多路分解根据四元组：(Source IP address, Source port number, destination IP address, destination port number)。TCP服务器端有一个专门的套接字1用来等待TCP连接，并根据四元组的值，创建一个新的套接字2来处理后续的TCP报文段，如果后续再有有相同四元组的报文段到达，这个专门的套接字1根据四元组把这个报文段发送到套接字2处。所以如果四元组有任一个值不一样，都会进入不同的套接字中。 值得一提的是，现代服务器中，套接字与进程往往不是一对一的了，而是使用一个线程来开启一个套接字并用于建立TCP连接。 Connectionless Transport: UDP UDP报文段结构如下，Lengh记录了UDP报文段的长度，Checksum用于进行差错校验 123416位 | 16位Source Port Number | Destination Port NumberLength | ChecksumApplication data(message) UDP除了提供多路分解与多路复用功能外，只提供最简单的差错校验。很多链路层协议提供差错校验，那么为什么UDP还需要提供差错校验呢：1.并不是所有链路层协议都提供差错校验 2.即使链路层没有发生问题，网络层也可能出现数据传输问题(比如在路由器的内存中出现问题)。UDP的差错校验是把除了Checksum外所有的16位数据进行加和(加和的时候如果有溢出，需要补到最后一位去)，然后求出反码得到的。那么当接收端拿到UDP报文段后，把所有的16位数据进行加和，如果结果不是111111111111111，那么代表传输过程中出现了错误。 Principles of Reliable Data Transfer rdt1.0是一个底层不会有任何差错的协议，由于底层不会有任何差错，所以我们的receiver不需要回复任何确认信息给sender端。 rdt2.0协议考虑了底层传输遇到比特位错误的情况，也就是某个比特位从0变成1或者从1变成0的情况。为了解决这一问题，rdt2.0引入了三种能力：1. 差错检测(error detection)，也就是使用类似UDP的checksum方法对接收到的报文进行差错检测 2. Receiver feedback，也就是receiver需要返回给sender一个信号告诉它上次的传输成功还是失败，rdt2.0我们使用ACK和NAK两种acknowledgement 3. Retransmission，也就是当sender接收到receiver端传来的错误信息后，会进行原信息的再发送。 rdt2.0只考虑了发送的报文会遇到比特位错误的情况，但其实返回的ACK或者NAK也可能遇到比特位错误，解决的方法还是在ACK和NAK中也加入差错检测，这样sender端在收到ACK或者NAK的时候就知道是否发生了比特位错误，如果发生了比特位错误，就直接进行原信息的重发送。但这时引出了另一个问题：receiver端不清楚我们重发送的信息到底是一个新信息还是一个重发送的老信息，它也就无法确定是处理这个新信息还是忽略这个老信息。那么解决办法就是引入序列号(sequence number)，receiver端通过检查序列号就知道发送来的信息是一个新信息还是一个重发送的老信息。这也就是rdt2.1 rdt2.2删掉了NAK，只使用ACK，原理是不管receiver端收到的是out of order的message还是corrupted的message，receiver都只是返回上次成功接收的message的ACK。 前面我们的协议都只考虑了比特位错误的情况，但没有考虑数据包在网络中可能丢失的情况，rdt3.0在此基础上增加了超时重传功能。 rdt协议有一个致命的缺陷就是他是一个stop and wait protocal，也就是说当sender端发送完一个message之后，会等待这个message的ACK返回，这样的效率太低且网络的throughput很低，解决办法是使用pipelined reliable data transfer protocols，主要有GBN和SR两种。 Go-Back-N(GBN)是一种滑动窗口协议，同一时间能够发送的message的数量由窗口的大小决定，具体窗口的定义见书中图3.19。GBN只有一个timer在进行计时，统计的是base处的message的时间，base处是窗口中第一个发出去但还没有收到ACK的message，当timeout的时候，所有base到nextseqnum-1的message都会被重新发送，这也是他被叫做Go-Back-N协议的原因。GBN协议的接收端没有窗口(也就是没有缓存)，所以如果到达的message不是我们需要的那个expectedseqnum，接收端就会扔掉它。GBN使用了cumulative acknowledgement，也就是假设n和n+1号message都被receiver端成功接收并处理了，但是返回的时候，n号message的ACK意外丢失了，sender端只收到了n+1号message的ACK，这个时候sender也会认为n和n+1号message已经被receiver端成功处理了，随即进行窗口的移动。在pipelined rdt协议中使用cumulative acknowledgement是很自然的做法。 GBN协议的一个很大的问题就是一旦接收端期待的message的接收遇到问题，即使后面的message都接收成功，也会导致所有messages的重传，这会导致大量的带宽被重传占用。为了解决这个问题，另一种协议Selective Repeat(SR)被引入，SR的基本思想就是为了避免过多的重传，在receiver端也设立一个窗口(也就是缓存)，当有乱序的message到达receiver端的时候，SR并不会将它们扔掉，而是缓存在窗口中，并且返回对应的ACK，同时sender端也不是只有一个计时器，而是对于每一个发送出去的message都有一个对应的计时器，如果在规定时间内没有接收到相应的ACK，就会触发超时重传机制。当sender端send_base处的message成功的接收到ACK时，sender端的窗口会移动到有最小sequence num的还未被ACK的message处；当receiver端的recv_base处的message被成功的接收到时，receiver端的窗口会移动到有最小sequence number的还没接收到message的位置。SR没有使用cumulative acknowledgement；同时SR的发送窗口与接收窗口并不一定同步对应(接收端窗口可能比发送端窗口先滑动，因为发送端窗口还没有收到ACK)；SR的窗口大小必须小于或等于sequence num的一半，否则会出现接收端窗口无法判断收到的message是重传还是新数据的问题。 由上面的分析以及书中的示例图可知，GBN的窗口是连续的，所以实现的时候其实只需要两个指针(base, nextseqnum)即可；SR的窗口是不连续的(ACK之中夹杂着还没有ACK的)，所以只用指针是实现不了的，我猜底层是一个类似数组的东西在进行维护。 Connection-Oriented Transport: TCPTCP Segment定义 TCP segment中数据的最大长度(maximum segment size, MSS)是由最大传输单元(maximum transamission)决定的，在以太网等链路层协议中，MTU的值一般为1500 bytes，那么减去IP协议的header(20字节)和TCP协议的header(20字节)，我们可以得出TCP segment中数据的最大长度一般为1460字节 TCP segment定义如下：12345678 32 bits(4 bytes)Source port number |Destination port number Sequence number Acknowledgment numberHeader lengh|Unused|CWR|ECE|URG|ACK|PSH|RST|SYN|FIN|Receive windowInternet checksum |Urgent data pointer Options Data 32位的Sequence number和32位的Acknowledgment number用于实现可靠数据传输 16位的receive window用于流程控制中返回receiver window的大小 4位的header length说明了TCP header的长度，一般来说TCP header的长度都是20字节，但是由于有options的存在，TCP header的长度可能大于20字节 options部分用于：1. sender和receiver沟通MSS的大小 2.sender和receiver沟通window scaling factor 3.定义timestamp option flag部分定义了TCP使用的标志位：1.ACK标志位用于表示这个TCP segment中包含了一个ACK，也就是Acknowledgment number，其实在TCP通信的时候，只有第一个发起连接的SYN信号的segment中的ACK是0，其他所有的segment的ACK一定为1(因为TCP就是通过seq和ack来实现pipelined rdt，通过这两个值知道数据传输的情况，比如数据是否丢失，数据是否被接收到，这个在上一章已经说明了) 2.RST, SYN, FIN用于TCP的连接与断开 3.CWR, ECE用于拥塞控制 4.PSH代表收到的数据要立刻传递到上一层 5.URG指的是紧急数据 Urgent data pointer指明了紧急数据存放的位置 TCP数据传输 TCP传输的sequence number其实是字节流，而不是像我们前面介绍所说的传递的segment的序号。一个segment的sequence number其实是这个segment的第一个字节在字节流中的序号。 TCP的acknowledge number指的是作为接收者，期待对方传来的下一个sequence number。也就是当我们传回一个n的acknowledge number的时候，我们的意思是“嘿，我承认我收到了n-1 sequence number前所有的数据，下一次请从n号sequence number开始发”。因此，接收端发送的acknowledge number = 接收到收到的sequence number + 收到的数据长度，比如A发给B一条信息[seq = 100, Length = 200]，那么B返回的信息将是[ack = 300]；值得一提的是有些TCP segment的数据长度为0，比如SYN和FIN信号，这种情况下接收端发送的acknowledge number = 接收到收到的sequence number + 1。 TCP使用了cumulative acknowledgments，假设A向B发送了三个segment：第一个segment包含字节号0-535，第二个segment包含字节号536-899，第三个segment包含字节号900-100，但是由于网络原因第二个字节未被B收到，那么此时B返回的acknowledgement number会是536，也就是TCP返回的acknowledgement number是字节流中第一个缺失的字节。 TCP的initial sequence number不是固定的，而是在三次握手阶段选定的随机值，三次握手的一个主要作用就是选定并互相确认ISN RFC中定义了很多上面这些细节，但是对于TCP的具体实现其实是没有定义的，所以本质上来说我们可以用GBN或者SR或者其他rdt协议实现TCP(早期TCP其实甚至是由stop-and-wait实现的)。现代操作系统上实现的TCP协议大致与GBN类似：1.都使用cumulative acknowledgments 2.sender端有一个滑动窗口 3.只使用一个timer，这个timer作用于有着最小sequence number的已经发送但还未被ACK的segment上。 但是有两点与GBN不同：1.TCP协议在receiver端也有一个滑动窗口(缓存)，用于接收out of order segment，这点与GBN直接扔掉out of order segment是不同的 2.当唯一的timer到时间后，TCP协议只会重发这个被计时的segment，而不是像GBN一样把后面的也都发了。 所以TCP可以看做GBN和SR的混合实现。 TCP中timeout的时间根据RTT进行计算，总结见书和这里：https://coolshell.cn/articles/11609.html 前面提过，TCP的重传只作用于当前序列号最小的未被ACK的segment，并且重传的第一个timeout是由RTT计算的，但重传以后后面的timeout时间不再根据RTT计算，而是不断倍增，假设第一个timeout时间根据RTT计算出来是0.75，那么下一个timeout时间就会是1.5，3， 以此类推。 TCP还有一个特别的重传机制：fast retransmit，fast retransmit不是根据timeou时间进行重传，而是当我们收到同一个segment的三条相同ACK，那么很大可能是这条segment丢失了，但由于后面的segment被正常接收了，所以根据cumulative acknowledgement，不断返回least missing sequence number，这个时候TCP会直接进行重传，而不是继续等待timeout。 TCP流程控制与滑动窗口 TCP sender端的滑动窗口与GBN相同，见图：https://github.com/ShiyuLiuColumbia/diagram/blob/main/Sliding%20window%20at%20TCP%20sender%20side.png. 窗口的大小N是由receive端传来的receive window决定的。 TCP receiver端的滑动窗口：https://github.com/ShiyuLiuColumbia/diagram/blob/main/Sliding%20window%20at%20TCP%20receiver%20side.png 所以TCP流程控制的本质是一项速度匹配机制：发送端发送字节流的速度需要与接收端应用读取字节流的速度匹配。`Receive window(这是sender端将要收到的滑窗的N，由receive端提供的) = Receive buffer(这其实是receive端滑窗的N)-[LastByteRcvd - LastByteRead] 流控这种由receiver端控制sender的方式也会造成一些问题。1.Zero Window： 假设receiver端发给sender端的一个ACK segment的receive window是0。并且后面恰好receiver端没有新的数据发送给sender端，就会出现sender端停止发送数据的情况，因为sender端认为receiver端没有可以接受数据的位置了，即使后面receiver端某些buffer被空了出来，sender端也永远不会知道了。解决办法是sender后面还会间隔一段时间发送空数据的segment到receiver，这样receiver的ACK segment可能会包含新的receive window的值。https://coolshell.cn/articles/11609.html#Zero_Window 2.Window shrinking，也就是receive window的值(比如20)发送出去后，receiver端的buffer减少了，使得receiver端没有足够的buffer接收数据了：http://www.tcpipguide.com/free/t_TCPWindowManagementIssues.htm 3. Silly Window Syndrome: 如果我们的接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送这几个字节。要知道，我们的TCP+IP头有40个字节，为了几个字节，要达上这么大的开销，这太不经济了。http://www.tcpipguide.com/free/t_TCPSillyWindowSyndromeandChangesTotheSlidingWindow.htm TCP三次握手与四次挥手 TCP三次握手与四次挥手的过程以及状态机的变化在书中及各个博客有很详细的描述，这里就不赘述了 https://coolshell.cn/articles/11564.html#TCP%E7%9A%84%E7%8A%B6%E6%80%81%E6%9C%BA TCP为什么要进行三次握手？TCP的三次挥手本质上是为了在不可靠的信道上可靠地传输信息，而这一需求最少需要进行三次握手，当然我们进行4次，5次或者更多次都是可以的，但是最少需要三次。TCP三次握手在干什么呢？最重要的就是sender端和receiver端进行沟通并交换彼此初始化信息，其中最重要的一个信息就是ISN。试想如果sender和receiver不交换彼此初始化信息就开始进行TCP传输，那岂不是乱了套，任何主机间直接就能进行通信了。 TCP为什么是三次握手？两次或者四次不行吗？https://www.zhihu.com/question/24853633/answer/115173386 https://www.zhihu.com/question/24853633/answer/573627478其实三次挥手的原理非常非常简单，就是sender端发送它的初始化信息(ISN，window)，receiver端ACK，然后receiver端也发送它的初始化信息(ISN，window)，sender端ACK。其中receiver端ACK和receiver端也发送它的初始化信息这两个message可以在一条segment中发送，所以就变成了三次握手。 TCP为什么是四次挥手？断开连接的时候，A先告诉B我要断开连接(发送FIN)，B发送ACK，随后B告诉A它要断开连接(发送FIN)，A发送ACK，这里B发送ACK和B告诉A它要断开连接不能像三次握手一样合在一起的原因是B发送完ACK后，B仍可能有数据需要发送给A，确认B自己那里没有再要发送的数据后，B才会发送FIN给A。所以其实如果B在ACK的时候也把FIN发出去了，那其实可以理解为三次(前提是B此时正好也没有其他数据要发送了)。需要注意的是，当一台主机发送了FIN信号后，这台主机就失去了发送数据的能力，但是他还是可以回复ACK的，因为ACK的消息是没有数据的(只有segement header) 为什么TCP4次挥手时等待为2MSL？https://www.zhihu.com/question/67013338/answer/248375813 TCP三次握手与四次挥手考点：https://www.zhihu.com/question/271701044/answer/398114686 Principles of Congestion Control 讲了一下Congestion control的原因与解决办法，感觉不是很重要。 TCP Congestion Control 拥塞控制需要解决三个问题：1.TCP sender如何检测到从它这一端到receiver端存在拥塞？ 2.检测到拥塞后，TCP sender如何限制传输的速度？3.TCP sender应该采取什么算法来根据端到端的拥塞情况改变它的发送速率？ 第一个问题：当TCP sender收到两种loss event的时候，证明传输路径中发生了拥塞，第一种信号是timeout，也就是在规定时间内没有收到某个segment的ACK并触发了timeout信号；第二种信号是sender端收到同一个segment的三个duplicate ACKs，这是证明传输路径中可能发生了丢包。当sender端检测到这两种信号的时候，sender端认为发生了拥塞，所以需要降低传输速率。反之，如果sender端收到ACK信号，证明线路中没有发生拥塞，且收到ACK的速度越快，证明线路越不可能拥塞，所以sender端在收到ACK时认为线路没有拥塞并且可以加快传输速率。TCP采取的策略就是每当收到ACK的时候，就提升自己的传输速率，直到收到loss event 第二个问题：前面我们在讲流控的时候提到了receive window(rwnd)，在sender端还定义了一个变量congestion window(cwnd)，这个变量就是用来控制sender端的发射速率的(假设rwnd无限大的时候)。LastByteSent-\bLastByteAcked&lt;=min{cwnd, rwnd} 第三个问题：目前TCP采取的算法有：1.slow start 2.congestion avoidance 3.fast recovery，其中前两个是必须的，第三个是推荐的。 slow start虽然叫做slow start，但是它在传输速率上的改变是指数级的，也就是cwnd呈指数级增长(cwnd = cwnd + 1 MSS, 1MSS-&gt;2MSS-&gt;4MSS-&gt;8MSS)，这是因为刚开始发送数据的时候，发送速度距离我们的网络带宽还查得很远，我们需要一个函数去快速迫近临界值。如果在slow start阶段遇到loss event，就会设定ssthresh(slow start threshold)为cwnd/2，并将cwnd设定回默认值1MSS；如果在slow start阶段cwnd&gt;=ssthresh，TCP会进入congestion avoidance阶段，原因是ssthresh的值是上一次遇到拥塞的一半，我们有理由相信我们已经逼近了拥塞的临界值，所以这个时候TCP选择更保守的congestion avoidance。 congestion avoidance阶段，cwnd是呈线性增长的(8MSS-&gt;9MSS-&gt;10MSS-&gt;11MSS)。如果遇到loss event，就回到slow start阶段 如果我们不考虑fast recovery(TCP Tahoe)，那么TCP就会在slow start和congestion avoidance之间来回切换。但是我们会发现两种loss event其实是不同的，timeout的严重程度是比3 duplicatge ACKs更严重的，因此有人进一步提出了改造算法TCP reno，TCP reno引入了fast recovery，当sender收到三个duplicate ACKs，会设定ssthresh = cwnd/2，cwnd = ssthresh+3MSS(加三的意思是收到三个duplicate ACK)，并进入fast recovery状态，在这个状态下，cwnd每收到一个duplicate ACK就加1MSS(cwnd = cwnd + 1 MSS, 这个公式与cold start相同，但是这里不是指数级增长，而是线性增长，因为这里cwnd是在每收到一个duplicate ACK的情况下才会加1，从书中的TCP reno的图3.52也能看出来)。如果在fast recovery阶段发生timeout，那么没什么好说的，直接回到slow start，如果在fast recovery阶段收到了正常的ACK，那么证明网络已经正常，那么回到congestion avoidance。所以fast recovery就是TCP在收到三个duplicate ACKs以后，先把cwnd减为之前的一半，线性增长cwnd并尝试确认网络到底有没有拥塞，如果真的有问题就回到slow start重新开始，没问题(收到ACK)就回到congestion avoidance继续线性增长。这么一看，fast recovery(快速恢复)倒是名副其实，因为如果网络并没有拥塞，只是瞬间丢包，那么TCP可以很快回到稳定的congestion avoidance阶段，而略去了slow start阶段。 网络上一段关于fast recovery的解释很好： Fast Recovery is now the last improvement of TCP. With using only Fast Retransmit, the congestion window is dropped down to 1 each time network congestion is detected. Thus, it takes an amount of time to reach high link utilization as before. Fast Recovery, however, alleviates this problem by removing the slow-start phase. Particulary, slow-start will be used only at the beginning of a connection and whenever an RTO(Retransmission TimeOut) period is expired.The reason for not performing slow-start after receiving 3 dup ACKs is that duplicate ACKs tell the sending side more than a packet has been lost. Since the receiving side can create a duplicate ACK only in the case that it receives an out-of-order packet, the dup ACK shows the sending side that one packet has been left out the network. Thus, the sending side does not need to drastically decrease cwnd down to 1 and restart slow-start. Moreover, the sender can only decrease cwnd to one-half of the current cwnd and increase cwnd by 1 each time it receives a duplicate ACK. TCP是相对公平的，多个TCP连接，由于有congestion control，最终各个连接分得的bandwidth是相同的，这也符合了TCP的设计理念：TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。这点与UDP是不同的，UDP是不公平的(UDP都不是面向连接的，也没有拥塞控制，何谈公平？)。但是TCP的公平是相对的，公平是针对每个连接的，但对于用户来说并不公平，因为一个用户可以开始多个并行TCP连接。 The Network Layer: Data PlaneOverview of Network LayerForwarding and Routing: The Data and Control Planes 网络层可以分为两个部分：数据平面(data plane)和控制平面(control plane)。数据平面负责的是转发(forwarding)，也就是当一个分组通过输入链路到达路由器的时候，路由器会决定这个分组发送到哪一个输出链路，转发的过程很快，通常只有几纳秒，一般是由硬件实现的；控制平面负责的是路由选择(routing)，也就是控制相应的路由器来规划出一条线路，确保分组最终能够从起点到达终点，一般由软件实现，所以控制平面控制的其实是数据平面。举个生活中的例子：控制平面就像是谷歌地图，为我们规划了一条线路；数据平面是开车的人，在每一个交叉路口都要进行一下具体的操作。 网络层中最重要的元素是转发表(forwarding table)，每一个路由器中都有一个转发表，路由器通过查询转发表来确认某个分组该如何转发；转发表是由控制平面通过某些路由选择算法计算得出，分为传统方法和SDN(software-defined networking)方法。传统方法就是在每一个路由器中运行路由选择算法，路由器可以和相连的其他路由器交换信息，最终计算出转发表，本质上是一种局部最优解的路由选择算法；SDN方法就是全局考虑所有的路由器，通过远程控制器(remote controller)计算出最佳路径，并把相应的转发表发到每一个路由器中，是一种全局最优解。具体的算法会在第五章介绍。 网络层提供了主机到主机的传输方法，也就是在主机到主机间有很多可能的路径，网络层告诉我们在遇到每一个路由的时候该如何继续传输数据，但是在一条数据链路上点对点的数据传输并不由网络层负责，而是由数据链路层负责。网络层就做了两件事：1.规划路线 2.转发。路由器实现了这两个功能，所以路由器属于网络层设备，路由器不需要实现运输层和应用层，因为他不需要实现进程到进程的传输，也不需要运行应用；链路层交换机没有这两个功能，所以交换机属于链路层设备 Network Service Model 网络层不提供任何确保的服务，只提供尽力而为服务(best-effort service) 在最开始我们介绍分组交换机(packet switches)的时候，我们说过常见的分组交换机有路由器(router)和链路层交换机(link-layer switch)，它们起到的作用都是转发。但是路由器是基于网络层datagram的header来做出转发的决定，所以他是网络层的设备；而链路层交换机是基于链路层frame的header来做出的转发决定，所以他是链路层的设备 What’s Inside a Router 路由器内部结构图见书中图4.4，分为input ports, switching fabric, output ports, routing processor。其中input ports, switching fabric, output ports属于数据平面，是由硬件实现的；routing processor属于控制平面，使用软件方法实现路由选择。 input ports指的是路由器上物理的接口，主要有三个作用；1.分组从物理层到数据链路层 2.分组从数据链路层到网络层 3.查询转发表决定分组的output ports，排队并最终进入到switching fabric switching fabric用来连接input ports和output ports output ports也有三个作用：1.从switching fabric接收分组并进行排队缓存 2.分组从网络层到数据链路层 3.分组从数据链路层到物理层 routing processor属于控制平面，在使用传统方法的控制平面中，routing processor负责与相邻的路由器交换信息并计算出转发表；在使用SDN方法的控制平面中，routing processor负责与remote controller交互并得到转发表(转发表的计算是在remote controller中进行的) 路由器中分组的转发分为两大类：destination-based forwarding和generalized forwarding。顾名思义，基于目的地的转发只根据目的地的IP地址进行转发的抉择，传统方法的控制平面使用这种转发方式；而一般性转发不仅会根据目的地IP地址，还会考虑其他因素(比如起点IP地址，起点或目的地的MAC地址等)来综合进行转发的抉择，SDN方法的控制平面使用这种转发方式 Input port processing and destination-based forwarding Input port的更详细的作用见书中图4.5 假设某一路由器使用传统控制平面，即使用destination-based forwarding，并且假设它有四个output ports，并且它的转发表如下所示： 12345Destination address range link interface11001000 00010111 00010000 00000000 through 11001000 00010111 00010111 11111111 011001000 00010111 00011000 00000000 through 11001000 00010111 00011000 11111111 111001000 00010111 00011001 00000000 through 11001000 00010111 00011111 11111111 2otherwise 3 这个转发表可以使用IP地址的prefix进行优化，prefix是通过比较IP地址区间的相同prefix得到的 12345Prefix link interface11001000 00010111 00010 0 11001000 00010111 00011000 111001000 00010111 00011 2otherwise 3 通过prefix转发表，当我们拿到一个IP地址的时候，进行prefix match，就能知道输入的端口了，但是这里有一个问题，有些情况下同一个IP地址可以被多个prefix match，比如11001000 00010111 00011000 10101010这个IP地址就可以同时被1和2接口的prefix match。解决办法是使用longest prefix matching rule，也就是找到table中符合prefix match规则的最长的IP prefix。 查询完转发表后，某一个分组已经知道了它的output ports，这个时候它需要进入switching fabric，但由于switching fabric可能正在处理其他分组，所以可能暂时需要在input port进行排队，具体排队的细节会在后面介绍 SwitchingSwitching主要分为三种：switching via memory, switching via a bus, switching via an interconnection network。具体细节见书中图4.6 Where does Queuing Occur分组在input ports和output ports都会导致排队，具体见书中图4.9 Packet scheduling由于在output ports存在排队，那么我们需要决定哪些分组出队列的先后顺序，常见的有FIFO(First-in-first-out), Priority Queueing, Round robin and weighted fair queueing(WFQ) The Internet Protocal(IP): IPV4, Addressing, IPV6, and MoreIPV4 Datagram Format IPV4 Datagram的结构图见书中图4.16 Version number: 占4位，用来指明使用的IP的版本 Header length: 指明IP datagram的header长度，由于IPV4有Options选项，所以header的长度是不确定的，但是一般的IP datagram都没有options选项，所以一般header长度都是20字节 Type of service: 指明IP datagram的服务类型，比如datagram可能用于实时流量(网络直播)，或者非实时流量(邮件) Dtagram length: 占16位，用来指明整个datagram的长度，所以理论上的最大长度是65535字节，但是由于链路层frame的长度限制，所以一般datagram都小于1500字节 Identifiew, flags, fragmentation offset: 用于fragmentation，值得注意的是只有IPV4使用了fragmentation，IPV6没有使用 Time-to-live: 确保datagram不会永远在网络中循环，没经过一个路由节点，TTL会减1，当变成0以后就会被路由器丢掉 Protocal: 指明了datagram包含的运输层segment使用的协议，6代表TCP，17代表UDP Header checksum: 对IP datagram的header进行checksum。为什么TCP/UDP和IP都实现了checksum？1.IP的checksum只作用于header，TCP/UDP作用于整个segment 2.IP和TCP/UDP并不一定配套使用，有可能其他的传输层协议就没有checksum，所以有必要在IP协议也进行checksum Source and destination IP address: destination IP address一般是通过DNS查询得到的 Options: 只有IPV4有，IPV6没有options选项 Data(payload): data可以包含TCP/UDP segment，也可以携带其他类型的数据，比如ICMP IPV4 Datagram Fragmentation 由于链路层的MTU并不一定相同(以太网是1500字节，别的链路层协议可能只有500字节)，IP datagram从起点到终点的过程中可能经过多种链路，在这种情况下，一个大的IP datagram会被拆分成多个小的datagram，这些小的datagram会在终点处重组。IPV6没有使用这种技术，而是如果数据链路的MTU不够使用，那么这个datagram就会发送失败并通知发送端以更小的长度来发送 IPV4 addressing 主机或者路由器与数据链路相连的边界叫做接口(可以理解为网卡)，IP地址是与网卡绑定的，而不是主机。由于主机一般只有一个网卡，所以我们总是说某某主机的IP地址是多少，但对于路由器来说，每一个进出接口都会被绑定一个IP，所以路由器总是与多个IP地址绑定的 子网的定义：如果将接口从主机和路由器剥离，形成的一个个的isolated island就是子网，见书中图4.19。一个很好的子网的例子就是公司的内网，我们假设某个公司内网与互联网相连只通过一个路由器，内网之间的连接都是通过交换机(以太网)或者无线连接的，假设我们把内网到互联网的端口断掉了，内网就成了一个isolated island，只能内网之间交换信息，而不能与外界通讯了。子网一个很大的特点就是子网内的主机通讯不需要通过路由器，不同子网间通讯需要路由器的参与 那么如果我们有多台主机的IP地址，如何判断它们是不是在一个子网里呢？这是由子网掩码(subnet mask)来定义的，子网掩码的表示方法有两种：223.1.1.0/24，这里的/24就是子网掩码，表示这个子网中IP的前24位都是相同的；另一种表示方法是255.255.255.0，表示的同一个意思，如果把255.255.255.0和IP地址进行与运算，如果结果都是一样的，代表这些IP在同一个子网中 如果a.b.c.d/x代表一个子网，那么我们一般说这个子网IP地址的前x位是它的网络号，网络号对于子网内的IP都是相同的。剩下的32-x位是主机号，子网中共有2的(32-x)次方个IP地址，子网中的每台主机可以分得一个IP地址5， 大的子网可以继续分成小的子网：假设某一个ISP得到的大的子网是200.23.16.0/20，那么这个子网共有2的12次方，也就是4096个IP地址，现在ISP可以把这个子网分给很多小公司，每个小公司有2的9次方，也就是512个IP地址，那么这个大的子网可以分成8个小的子网，子网地址分别是：200.23.16.0/23, 200.23.18.0/23 … 200.23.30.0/23 https://www.zhihu.com/question/29723388/answer/238290373. 前面我们说过，子网的主机间可以直接通讯，因为他们的IP地址在经过子网掩码与运算后相同，两台主机知道互相是在同一个子网(网段)里的，所以直接发送ARP请求对方主机的MAC地址后即可通信(第六章会学习) 当一个组织或公司被分配了一个子网的地址后，该如何给网络中的主机分配IP地址呢，通常使用的是DHCP(Dynamic Host Configuration Protocal)，这个协议用来为主机动态的分配IP地址。DHCP是一个client-server协议，在子网中会有一个DHCP server，负责分配IP地址。过程主要分为4步(书中图4.24)：1.DHCP server discovery，新加入的未分配IP地址的主机的IP地址是0.0.0.0，通过向255.255.255.255这个广播IP地址来告诉内网中所有主机自己需要一个新的IP 2.DHCP server offer，内网中的DHCP server收到广播的请求后指定一个待分配的IP地址，并且也通过255.255.255.255进行广播 3.DHCP request，新加入的主机收到DHCP server分配的IP地址后，再一次向255.255.255.255发送广播，表示自己要使用这个IP地址 4.DHCP ACK，同样的，DHCP server向255.255.255.255发送广播表示同意client使用这个地址。可以看到，在DHCP协议中，广泛的使用了255.255.255.255这个IP地址的广播作用，这是因为新加入的主机还没有被分配IP地址，还不能使用内网IP地址进行通信，所以只能使用广播 DHCP：https://www.zhihu.com/question/267097519 关于0.0.0.0, 127.0.0.1, 本地IP：0.0.0.0 在不同的情况下有不同的意义，例如，在socket bind中表示所有可用的interface；在网卡初始化时表示“还未获得IP”。比如一个程序选择监听在0.0.0.0，则表示要监听在所有的自己可用的IP（所有的网卡）上；在运行DHCP client之前将网卡IP设置为0.0.0.0，则表示此网卡要参与DHCP的IP申请过程。首先我们要先知道一个概念，凡是以127开头的IP地址，都是回环地址（Loop back address），其所在的回环接口一般被理解为虚拟网卡，并不是真正的路由器接口。所谓的回环地址，通俗的讲，就是我们在主机上发送给127开头的IP地址的数据包会被发送的主机自己接收，根本传不出去，外部设备也无法通过回环地址访问到本机。本机IP通常仅指在同一个局域网内，能同时被外部设备访问和本机访问的那些IP地址（可能不止一个）。像127.0.0.1这种一般是不被当作本机IP的。本机IP是与具体的网络接口绑定的，比如以太网卡、无线网卡或者PPP/PPPoE拨号网络的虚拟网卡，想要正常工作都要绑定一个地址，否则其他设备就不知道如何访问它。 现在有两台pc在同一个局域网内，分别为pc1与pc2，pc1上有一个网卡，IP地址为192.168.10.128pc1中sever监听127.0.0.1，则pc1中的client可以连上127.0.0.1，但是连不上192.168.10.128；而pc2中client什么都连不上。pc1中sever监听192.168.10.128，则pc1中的client可以连上192.168.10.128，但是连不上127.0.0.1；而pc2中client能连上192.168.10.128。pc1中sever监听0.0.0.0，则pc1中的client可以连上127.0.0.1和192.168.10.128，pc2中的client能连上192.168.10.128。 Network Address Translation(NAT) 由于IPV4地址是有限的，并不能保证每个主机都能分到，比如在家庭网络中，ISP往往只提供给我我们一个IP地址，但是我们有多个主机(电脑，手机等)，这个时候就需要使用NAT技术，顾名思义，NAT是一种将IP地址进行转译来达到扩展私有IP地址的目的，注意，这里扩展的只是私有IP地址，这个私有IP地址只在我们私有网络中才是有意义的。 NAT的工作原理是，私有网络(局域网，LAN)是一个子网，使用私有IP地址，当私有网络中的主机想要与互联网通讯的时候，在路由器处会进行(私有IP地址，端口)与(公共IP地址，端口)的转译，外界的互联网是看不到我们内部的私有IP地址的，它只是以为在于我们公有IP地址进行通讯。比如我们私有网络中有两台主机192.168.0.1和192.168.0.2，两台主机一台使用100端口浏览网页，一台使用200端口发邮件，那么这两个网络连接在路由器处会进行转译，假设我们的公有IP是67.72.0.3，那么路由器会使用两个端口，继续进行这两个网络请求，同时记录对应的NAT记录：(192.168.0.1, 100 : 67.72.0.3, 1), (192.168.0.2, 200 : 67.72.0.3, 2)。书中的图4.25清晰地表示了NAT的使用。由于端口号有16位，所以理论上仅通过一个公有IP地址，NAT支持65535个连接。 NAT被广泛使用在现在的私有网络中，但是有些反对的声音：端口是应该用来标记进程的，而不是用来标记主机的，这会造成某些问题，比如如果我们私有网络中的主机是一个服务器，他需要先接收请求后才能发送数据，由于请求进来的时候，NAT的翻译关系还不存在，所以是无法找到内网的主机的，这种情况下需要使用NAT穿透技术。 IPV6 IPV6的Datagram的结构图见书中图4.26 IPV6与IPV4网络之间传递datagram，需要使用tunneling技术，简单来说就是在一个IPV4 datagram的data部分塞入一个IPV6的datagram，这样IPV6的datagram就可以在IPV4的网络中传播了。 Generalized Forwarding and SDN 这一节介绍的是使用SDN控制平面并采用Generalized Forwarding。前面我们介绍过传统的控制平面，它是通过router本地运行routing算法来计算forwarding table，并且forwarding table只基于目的地IP地址；而SDN控制平面使用远程remote controller来计算forwarding table，forwarding table的计算也不仅仅是根据目的地IP地址，而是还可能根据其它的headers(比如出发地IP地址，MAC地址等)，所以它的计算量是相对更大的，这也是这种forwarding table采用remote controller远程计算的原因，另外Generalized Forwarding除了能提供分组转发功能外，它还能提供其它功能，比如分组丢弃(防火墙功能)或者改变分组的头部(NAT功能)等。所以总的来说，SDN控制平面是未来网络的发展趋势。 The Link Layer and LANsIntroduction to the Link Layer 数据链路层与传输层的类比：假设一个旅游代理正在为一个旅行团规划从大连到纳什维尔的路线，规划的结果是从大连到北京做高铁，从北京到芝加哥做飞机，从芝加哥到纳什维尔做大巴。在这个例子中，旅游团是datagram，每一个transportation segment是一个链路，交通方式是链路层协议，旅游代理是路由选择协议。也就是说传输层只负责路由的规划，但是datagram在每一条链路中是如何从起点传到终点的是由链路层负责的 链路层大部分实现在网卡(network adapter, or network interface card)处，90年代的时候，网卡都是一张单独的板子，但是现代的网卡都已经被集成到主板上了 链路层有两种信道，一种是广播信道，也就是frame会被发送给所有连接的主机；一种是点对点信道，也就是frame只会被发送给对应的主机 Error-Detection and Correction Techniques 主要分为三种，第一种是Parity check，也就是约定好该使用奇校验或者偶校验，接收端判断接收到的二进制的数据是不是奇数或者偶数，不是的话说明传输过程中一定出现了问题，但是这种方法并不保险，因为如果是多个bits发生改变，结果可能检测不出来。改进的的方法有二维奇偶校验 第二种是我们已经见过的checksum校验，第三种是链路层最常用的CRC校验 Multiple Accesss Links and Protocals 本章介绍了广播信道的实现方式，比如时分，频分或者更高级的方法，具体内容见书 Switched Local Area NetworksLink-Layer Addressing and ARP 主机或者路由器的网卡都有一个写死的链路层地址，我们称为MAC地址，如果一台主机或者路由器有多个网卡(接口)，那么每一个接口都会有一个IP地址，同时也会有一个MAC地址。MAC地址是与网卡的硬件绑定的，一个网卡生产出来，它的MAC地址就不能改变了，并且世界上没有任何两个网卡有相同的MAC地址。我们可以把MAC地址理解为身份证号，它是不会变的，IP地址理解为邮编，它是我们连接到互联网以后被分配的，如果一台设备没有连接到互联网，那么他就没有IP地址，但是MAC地址永远存在 链路层使用FF-FF-FF-FF-FF-FF做为广播的MAC地址，也就是说任何发送到这个MAC地址的frame都会被广播到子网中的其他设备上，前面我们讲过的DHCP就是通过这种方式进行广播的，它的IP destination是255.255.255.255，就对应了FF-FF-FF-FF-FF-FF这个MAC地址 我们在一条数据链路上传输frame，需要知道端点处两台设备的MAC地址，本机的MAC地址是已知的，但是终点设备的MAC地址是未知的，我们一般知道的是终点设备的IP地址，这个时候需要使用Address Resolution Protocal(ARP)协议。子网中每台主机和路由器中都会维护一个ARP表，里面存有子网中设备的IP地址与MAC地址的映射关系，如果我们发送的终点的IP地址已经在映射表中，那么很简单，我们拿到终点的MAC地址，写入frame中即可发送，但是如果映射表中没有终点的IP地址怎么办？这个时候就需要使用链路层的广播能力，起点会向FF-FF-FF-FF-FF-FF发送一个ARP请求，询问子网中所有的主机和路由器：你们的IP地址是不是终点的IP地址，是的话返回你得MAC地址，终点的主机或者路由器收到这个ARP请求后确认自己的IP与请求的相同，于是返回一个ARP response，里面写有自己的MAC地址。这样起点就有了终点的MAC地址，并且这个映射关系会被缓存在ARP表中，方便下次使用。 链路层的广播只对子网内的路由器和主机有效，路由器连接的外网是收不到广播的，路由器起到了隔绝广播的作用，使得广播只在子网中有作用。ARP使用了广播技术，所以ARP协议也只能查询子网中IP与MAC的映射关系 计算机网络中的通信可以分为三种：主机自己与自己通信，同一子网(网段)中的主机间通信，不同子网的主机间通信。自己与自己通信很简单，直接发给自己就好了。对于另外两种，首先主机需要判断目的地主机与自己在不在一个子网中，这是通过什么判断的呢？通过前面我们介绍的子网掩码，通过将子网掩码与两个IP做与运算，如果相同的话代表两台主机在同一个子网(网段)。如果在同一个子网，那么事情很简单，通过ARP协议获取目的地的MAC地址，然后发送frame即可。如果不在一个子网中，见图6.19，那么发送端主机会去请求子网中默认设备(一般是路由器)的MAC地址，由于路由器与发送端主机在同一个子网中，可以使用ARP协议获取路由器的MAC地址，frame被发送给路由器，值得注意的是，这个frame中包含的datagram的destination IP是接收端的IP，但是frame的destination MAC是路由器的MAC地址。路由器的input interface接收到这个frame以后，传递到网络层变成datagram，路由器的网络层前面我们介绍过，存在一个forwarding table，forwarding table查看datagram的destination IP得出需要forward的output interface，output interface与接收端在同一个子网中，可以使用ARP协议查到接收端的MAC地址，把这个frame发送到接收端。 我在学习的过程中遇到一个不理解的问题，frame在每条数据链路的传输都需要先知道链路终点的MAC地址，一般是通过ARP协议查询IP地址与MAC地址的映射来得到的。假设某个dataframe需要经过多个路由器才能到达终点，那么意味着在每个路由器节点，datagram需要获知下一个路由器节点的IP地址，这样才能根据IP地址获得下一个路由器节点的MAC地址，但是书中的forwarding table并没有下一个节点的IP地址，通过查询发现forwarding table中是会存下一个节点的IP地址的，这样的话整个流程是说得通的。https://www.zhihu.com/question/55015810 Link-Layer Switches 链路层交换机与路由器都是分组交换机(packet switches)，不同的是路由器工作在第三层，根据IP地址进行datagram转发，并且不是即插即用的，因为需要通过路由算法或者SDN配置forwarding table；而链路层交换机是根据MAC地址进行frame转发，是即插即用的。 链路层交换机对于子网中的主机和路由器是透明的，也就是说子网中的主机和路由器根本不知道链路层交换机的存在，所以链路层交换机是没有MAC地址的！ 那么链路层交换机是怎么做到在发送端与接收端之间转发frame的呢？答案是与路由器的forwarding table类似，链路层交换机中也有一个forwarding table，但是是根据MAC地址来进行interface的选择 那么一个很关键的问题就是：链路层交换机中的forwarding table是怎么生成的呢？是和网络层一样通过路由算法或者SDN设置的吗？答案是否定的。链路层交换机使用了子网的广播技术，当接收端的MAC地址不在forwarding table中时，链路层交换机会向所有的interface广播这条frame，同时记录发送端的MAC地址和它进入的interface。所以如果一个子网中的主机间不停的通过交换机发送数据，那么他的forwarding table是会不断被写满的，这叫做self-learning。链路层交换机之所以能采用这种方式的原因是；子网可以使用广播，且子网中设备较少，试想如果我们的网络层也使用广播技术，一旦MAC地址为止，就向全世界的网卡发送这条消息，那是多么可怕 Ethernet, Virtual Local Area Network 这些内容如果工作中遇到了，可以再深入了解 Retrospective: A Day in the Life of a Web Page Request 书中的英文解释和图例都很好，这里不再翻译One way then to take this “big picture” view is to identify the many (many!) protocols that are involved in satisfying even the simplest request: downloading a Web page. Figure 6.32 illustrates our setting: a student, Bob, connects a laptop to his school’s Ethernet switch and downloads a Web page (say the home page of www.google.com). As we now know, there’s a lot going on “under the hood” to satisfy this seemingly simple request. A Wireshark lab at the end of this chapter examines trace files containing a number of the packets involved in similar scenarios in more detail. 6.7.1 Getting Started: DHCP, UDP, IP, and EthernetLet’s suppose that Bob boots up his laptop and then connects it to an Ethernet cable connected to the school’s Ethernet switch, which in turn is connected to the school’s router, as shown in Figure 6.32. The school’s router is connected to an ISP, in this example, comcast.net. In this example, comcast.net is providing the DNS service for the school; thus, the DNS server resides in the Comcast network rather than the school network. We’ll assume that the DHCP server is running within the router, as is often the case.When Bob first connects his laptop to the network, he can’t do anything (e.g., download a Web page) without an IP address. Thus, the first network-relatedaction taken by Bob’s laptop is to run the DHCP protocol to obtain an IP address, as well as other information, from the local DHCP server: The operating system on Bob’s laptop creates a DHCP request message (Section 4.3.3) and puts this message within a UDP segment (Section 3.3) with destination port 67 (DHCP server) and source port 68 (DHCP client). The UDP segment is then placed within an IP datagram (Section 4.3.1) with a broadcast IP destination address (255.255.255.255) and a source IP address of 0.0.0.0, since Bob’s laptop doesn’t yet have an IP address. The IP datagram containing the DHCP request message is then placed within an Ethernet frame (Section 6.4.2). The Ethernet frame has a destination MAC addresses of FF:FF:FF:FF:FF:FF so that the frame will be broadcast to all devices connected to the switch (hopefully including a DHCP server); the frame’s source MAC address is that of Bob’s laptop, 00:16:D3:23:68:8A. The broadcast Ethernet frame containing the DHCP request is the first frame sent by Bob’s laptop to the Ethernet switch. The switch broadcasts the incoming frame on all outgoing ports, including the port connected to the router. The router receives the broadcast Ethernet frame containing the DHCP request on its interface with MAC address 00:22:6B:45:1F:1B and the IP datagram is extracted from the Ethernet frame. The datagram’s broadcast IP destination address indicates that this IP datagram should be processed by upper layer protocols at this node, so the datagram’s payload (a UDP segment) is thus demultiplexed (Section 3.2) up to UDP, and the DHCP request message is extracted from the UDP segment. The DHCP server now has the DHCP request message. Let’s suppose that the DHCP server running within the router can allocate IP addresses in the CIDR (Section 4.3.3) block 68.85.2.0/24. In this example, all IP addresses used within the school are thus within Comcast’s address block. Let’s suppose the DHCP server allocates address 68.85.2.101 to Bob’s laptop. The DHCP server creates a DHCP ACK message (Section 4.3.3) containing this IP address, as well as the IP address of the DNS server (68.87.71.226), the IP address for the default gateway router (68.85.2.1), and the subnet block (68.85.2.0/24) (equivalently, the “network mask”). The DHCP message is put inside a UDP segment, which is put inside an IP datagram, which is put inside an Ethernet frame. The Ethernet frame has a source MAC address of the router’s interface to the home network (00:22:6B:45:1F:1B) and a destination MAC address of Bob’s laptop (00:16:D3:23:68:8A). The Ethernet frame containing the DHCP ACK is sent (unicast) by the router to the switch. Because the switch is self-learning (Section 6.4.3) and previously received an Ethernet frame (containing the DHCP request) from Bob’s laptop, the switch knows to forward a frame addressed to 00:16:D3:23:68:8A only to the output port leading to Bob’s laptop. Bob’s laptop receives the Ethernet frame containing the DHCP ACK, extracts the IP datagram from the Ethernet frame, extracts the UDP segment from the IP datagram, and extracts the DHCP ACK message from the UDP segment. Bob’s DHCP client then records its IP address and the IP address of its DNS server. It also installs the address of the default gateway into its IP forwarding table (Section 4.1). Bob’s laptop will send all datagrams with destination addressoutside of its subnet 68.85.2.0/24 to the default gateway. At this point, Bob’s laptop has initialized its networking components and is ready to begin processing the Web page fetch. (Note that only the last two DHCP steps of the four presented in Chapter 4 are actuallynecessary.) 6.7.2 Still Getting Started: DNS and ARPWhen Bob types the URL for www.google.com into his Web browser, he begins the long chain of events that will eventually result in Google’s home page being displayed by his Web browser. Bob’s Web browser begins the process by creating a TCP socket (Section 2.7) that will be used to send the HTTP reques (Section 2.2) to www.google.com. In order to create the socket, Bob’s laptop will need to know the IP address of www.google.com. We learned in Section 2.5, that the DNS protocol is used to provide this name-to-IP-address translation service.8. The operating system on Bob’s laptop thus creates a DNS query message (Section 2.5.3), putting the string “www.google.com” in the question section of the DNS message. This DNS message is then placed within a UDP segment with a destination port of 53 (DNS server). The UDP segment is then placed within an IP datagram with an IP destination address of 68.87.71.226 (the address of the DNS server returned in the DHCP ACK in step 5) and a sourceIP address of 68.85.2.101.9. Bob’s laptop then places the datagram containing the DNS query message in an Ethernet frame. This frame will be sent (addressed, at the link layer) to the gateway router in Bob’s school’s network. However, even though Bob’s laptop knows the IP address of the school’s gateway router (68.85.2.1) via the DHCP ACK message in step 5 above, it doesn’t know the gateway router’s MAC address. In order to obtain the MAC address of the gateway router, Bob’s laptopwill need to use the ARP protocol (Section 6.4.1).10. Bob’s laptop creates an ARP query message with a target IP address of 68.85.2.1 (the default gateway), places the ARP message within an Ethernet frame with a broadcast destination address (FF:FF:FF:FF:FF:FF) and sends the Ethernet frame to the switch, which delivers the frame to all connected devices, including the gateway router.11. The gateway router receives the frame containing the ARP query message on the interface to the school network, and finds that the target IP address of 68.85.2.1 in the ARP message matches the IP address of its interface. The gateway router thus prepares an ARP reply, indicating that its MAC address of 00:22:6B:45:1F:1B corresponds to IP address 68.85.2.1. It places the ARP reply message in an Ethernet frame, with a destination address of00:16:D3:23:68:8A (Bob’s laptop) and sends the frame to the switch, which delivers the frame to Bob’s laptop.12. Bob’s laptop receives the frame containing the ARP reply message and extracts the MAC address of the gateway router (00:22:6B:45:1F:1B) from the ARP reply message.13. Bob’s laptop can now (finally!) address the Ethernet frame containing the DNS query to the gateway router’s MAC address. Note that the IP datagram in this frame has an IP destination address of 68.87.71.226 (the DNS server), while the frame has a destination address of 00:22:6B:45:1F:1B (the gateway router). Bob’s laptop sends this frame to the switch, which delivers the frame to the gateway router. 6.7.3 Still Getting Started: Intra-Domain Routing to the DNS Server The gateway router receives the frame and extracts the IP datagram containing the DNS query. The router looks up the destination address of this datagram (68.87.71.226) and determines from its forwarding table that the datagram should be sent to the leftmost router in the Comcast network in Figure 6.32. The IP datagram is placed inside a link-layer frame appropriate for the link connecting the school’s router to the leftmost Comcast router and the frame is sent over this link. The leftmost router in the Comcast network receives the frame, extracts the IP datagram, examines the datagram’s destination address (68.87.71.226) and determines the outgoing interface on which to forward the datagram toward the DNS server from its forwarding table, which has been filled in by Comcast’s intra-domain protocol (such as RIP, OSPF or IS-IS, Section 5.3) as well as the Internet’s inter-domain protocol, BGP (Section 5.4). Eventually the IP datagram containing the DNS query arrives at the DNS server. The DNS server extracts the DNS query message, looks up the name www.google.com in its DNS database (Section 2.5), and finds the DNS resource record that contains the IP address (64.233.169.105) for www.google.com. (assuming that it is currently cached in the DNS server). Recall that this cached data originated in the authoritative DNS server (Section 2.5.2) for googlecom. The DNS server forms a DNS reply message containing this hostname-to-IPaddress mapping, and places the DNS reply message in a UDP segment, and the segment within an IP datagram addressed to Bob’s laptop (68.85.2.101). This datagram will be forwarded back through the Comcast network to the school’s router and from there, via the Ethernet switch to Bob’s laptop. Bob’s laptop extracts the IP address of the server www.google.com from the DNS message. Finally, after a lot of work, Bob’s laptop is now ready to contact the www.google.com server! 6.7.4 Web Client-Server Interaction: TCP and HTTP Now that Bob’s laptop has the IP address of www.google.com, it can create the TCP socket (Section 2.7) that will be used to send the HTTP GET message (Section 2.2.3) to www.google.com. When Bob creates the TCP socket, the TCP in Bob’s laptop must first perform a three-way handshake (Section 3.5.6) with the TCP in www.google.com. Bob’s laptop thus first creates a TCP SYN segment with destination port 80 (for HTTP), places the TCP segment inside an IP datagram with a destination IP address of 64.233.169.105 (www.google.com), places the datagram inside a frame with a destination MAC address of 00:22:6B:45:1F:1B (the gateway router) and sends the frame to the switch. The routers in the school network, Comcast’s network, and Google’s network forward the datagram containing the TCP SYN toward www.google.com, using the forwarding table in each router, as in steps 14–16 above. Recall that the router forwarding table entries governing forwarding of packets over the inter-domain link between the Comcast and Google networks are determined by the BGP protocol (Chapter 5). Eventually, the datagram containing the TCP SYN arrives at www.google.com. The TCP SYN message is extracted from the datagram and demultiplexed to the welcome socket associated with port 80. A connection socket (Section 2.7) is created for the TCP connection between the Google HTTP server and Bob’s laptop. A TCP SYNACK (Section 3.5.6) segment is generated, placed inside a datagram addressed to Bob’s laptop, and finally placed inside a link-layer frameappropriate for the link connecting www.google.com to its first-hop router. The datagram containing the TCP SYNACK segment is forwarded through the Google, Comcast, and school networks, eventually arriving at the Ethernet card in Bob’s laptop. The datagram is demultiplexed within the operating system to the TCP socket created in step 18, which enters the connected state. With the socket on Bob’s laptop now (finally!) ready to send bytes to www.google.com, Bob’s browser creates the HTTP GET message (Section 2.2.3) containing the URL to be fetched. The HTTP GET message is then written into the socket, with the GET message becoming the payload of a TCP segment. The TCP segment is placed in a datagram and sent and delivered to www.google.com as in steps 18–20 above. The HTTP server at www.google.com reads the HTTP GET message from the TCP socket, creates an HTTP response message (Section 2.2), places the requested Web page content in the body of the HTTP response message, and sends the message into the TCP socket. The datagram containing the HTTP reply message is forwarded through the Google, Comcast, and school networks, and arrives at Bob’s laptop. Bob’s Web browser program reads the HTTP response from the socket, extracts the html for the Web page from the body of the HTTP response, and finally (finally!) displays the Web page! Security in Computer NetworkssWhat is Network Security 网络安全的三个要素： 1.机密性 2.消息完整性 3.端点鉴别 Confidentiality: 机密性指的是只有发送端和接收端才能知道传输的消息的含义，中间人是不能知道的，那么消息的传输就需要加密 Message integrity：消息完整性指的是接收端需要确定它收到的消息是完整的，而不是被恶意或者偶然缺失掉了 End-point authentication：发送端与接收端互相确认彼此身份 Principles of Cryptography 对称加密算法：对称加密算法的原理是发送端与接收端事先沟通好一个加密解密所用的key，发送端用这个key，使用约定好的加密算法将信息加密后，接收端使用相同的key将原本的信息解密出来。最简单的对称加密算法就是移项式密码，所有的字母都由他后面第k个字母代替，接收端接收到加密信息后，把每个字母向前移k即可得到原信息。常见的对称加密算法有AES(Advanced Encryption Standard)。对称加密算法最大的问题就是在计算机网络中，发送端和接收端如何沟通好对称加密使用的key。 为了生成一个只有发送端和接收端才知道的key，DH秘钥交换算法应运而生，算法的数学细节这里不多讨论具体见：https://www.wst.space/ssl-part-2-diffie-hellman-key-exchange/. 过程是发送端与接收端分别生成一个秘钥，各自进行某些运算后发给对方，然后各自再使用收到的信息加上自己的秘钥就能生成一个只有彼此知道的秘钥key，即使中间人知道了发送端和接收端发送的信息，也无法猜测出两端各自的秘钥，也就猜测不出最终生成的秘钥key。 非对称加密算法：非对称加密算法的原理是接收端生成一个公钥keyA和私钥keyB，使用公钥加密的信息，只有使用私钥才能进行解密，这样发送端可以把想要加密的信息用公钥进行加密，接收端收到加密信息后使用私钥进行解密。这其中的数学原理不多讨论，一个通俗易懂的原理在这：https://www.zhihu.com/question/33645891/answer/192604856?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=632331097145479168. 最著名的非对称加密算法是RSA算法。 TLS在加密消息的时候，通常还是使用对称加密算法，因为它的性能最好，秘钥交换算法和非对称加密算法用来生成对称加密算法所需要使用的key。 Message Integrity and Digital SignaturesCryptographic Hash Function 散列(哈希)函数可以把一串信息哈希成固定长度的内容，哈希是不可逆的，主要用来保障数据完整性，即发信人将原始消息和哈希值一起发送，收信人通过相同的哈希函数来校验原始数据是否完整，但是仅用哈希函数是不够的，后面我们会介绍。哈希算法主要有MD4、MD5、SHA。MD4 1990年 输出128位 （已经不安全）MD5 1991年 输出128位 （已经不安全）SHA-0 1993年 输出160位 （发布之后很快就被NSA撤回，是SHA-1的前身）SHA-1 1995年 输出160位 （已经不安全）SHA-2包括SHA-224、SHA-256、SHA-384，和 SHA-512，分别输出224、256、384、512位。 (目前安全) Message Authentication Code 假设现在发送端要发送一段信息m，并且使用哈希算法，发出一段延长的信息(m, H(m))，接收端通过同样的哈希算法计算出H(m)=H(m)，确认信息是完整的，但是有一个问题是，我们无法确认接收端收到的m，确实是由发送端发来的：比如中间人可以截住发送的信息，然后自己发送一个(m’, H(m’))给接收端。解决的办法是发送端和接收端使用一个相同的secrets，接收端发送的时候，发送(m, H(m+s))，然后接收端验证H(m+s)=H(m+s)。H(m+s)被叫做message authentication code(MAC)，现在主流的MAC是HMAC SSL/TLS详解 SSL/TLS历史：SSL协议最早由NetScape公司在90年代提出，经过几个版本的发展(SSL1.0, SSL2.0, SSL3.0)在99年的时候，SSL3.0被纳入网络标准并更名为TLS1.0，随后推出了TLS1.1, TLS1.2和TLS1.3。TLS协议工作在应用层和传输层之间。 TLS的基本原理是使用对称加密，对称加密的秘钥由非对称加密或者秘钥交换算法生成，为了更好的解释数字证书的作用，后面的介绍默认TLS使用非对称加密+对称加密。假设服务器端有非对称加密的公钥A和私钥A’，当客户端想要与服务器端建立TLS连接的时候，会先发送一个client Hello，服务器端接收到client Hello消息后，会向客户端发送公钥A’，随后客户端使用公钥A’加密自己生成的一个秘钥X，并发送给服务器端，服务器端使用私钥A’解密信息，得到秘钥X。至此，客户端和服务器端达成了一致，获得了对称加密所需使用的X，后面的消息传递使用X加密即可。 上面的原理中有一个很严重的漏洞，就是无法防范中间人攻击，假设有一个中间人在截住了服务器端发送的公钥A，并且替换成了自己生成的公钥B，客户端毫不知情的使用公钥B对秘钥X进行了加密并发送给服务器端，此时中间人再一次截住了这段返回信息，并使用自己的私钥B’解密处秘钥X，同时在使用公钥A加密X返回给服务器端，那么就会造成一个很严重的后果：客户端和服务器端在毫不知情的情况下，被中间人得知了秘钥X，后续两者的对称加密在中间人眼里完全是无效的！所以现在，我们的问题就是：如何证明服务器端的公钥真的来自于服务器端？解决办法是使用数字证书(certificate)和数字签名(digital signature)，服务器的公钥写在数字证书中。 服务器的数字证书主要包含以下信息：1.Subject name(即该数字证书是签发给谁的) 2.Issuer name(包括签名算法，签发组织等) 3.Public key info(包括公钥所使用的的加密算法，公钥，数字签名等) 4.其他信息，这些细节随便点开任意一个HTTPS网站的证书即可看到。数字证书中除了数字签名，其他都是明文的，所以客户端在拿到服务器端的数字证书后，是能够直接读取到服务器端的公钥的。数字证书是怎么证明证书中公钥的来源者的身份的呢？通过数字签名。我们将数字证书中除了签名以外的明文内容设为P，对其使用哈希函数得到H(P)，数字证书的签发者有一对非对称秘钥，签发者使用私钥对H(P)进行加密，得到数字签名。客户端在收到数字证书后，会使用签发者的公钥对数字签名进行解密，得到H，同时客户端会使用相同的哈希函数计算H(P)，如果发现H==H(P)，那么证明数字证书确实来自于服务器，并且内容没有被改动，那么自然而然数字证书中的公钥也就是可信的了。 https://github.com/ShiyuLiuColumbia/diagram/blob/main/how-do-digital-signatures-and-digital-certificates-work-together-in-ssl.png 上面我们提到过，客户端会使用签发者的公钥对数字签名进行解密，那么一个问题来了：我们怎么知道签发者的公钥是可信的呢？其实我们并不能确定，所以上面的数字证书的签名其实可能是坏人使用它的私钥伪造的假签名。这就引出了证书链认证的问题：在我们的计算机中，内置了很多我们默认信任的根证书(root certificate)，它们来自于各个证书颁发机构(CA, Certificate Authority)。证书颁发机构保存有一对只有它自己知道的非对称秘钥K和K’。这些证书颁发机构生成的根证书的数字签名是由自己的私钥K’签署的，所以也叫做自签名证书。假设我们的服务器的证书的签发者就是CA，那么我们可以确认签发者的公钥(根证书)是可信的；但是很多情况下，服务器的证书并不是由CA签发的，而是由中间机构签发的，而中间机构的证书才是有CA签发的。那么证书链的认证是这样的( https://github.com/ShiyuLiuColumbia/diagram/blob/main/Chain_Of_Trust.svg )：客户端收到 http://baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 http://baidu.com 证书是否可信。于是，客户端根据 http://baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后根据 http://baidu.com 证书中提供的中间证书url请求该中间证书。请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。“GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 http://baidu.com 证书的可信性，如果验证通过，就可以信任 http://baidu.com 证书。在这四个步骤中，最开始客户端只信任根证书“GlobalSign Root CA”证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 http://baidu.com 证书，于是客户端也信任 http://baidu.com 证书 数字证书的原理：https://www.zhihu.com/question/24294477/answer/74783418?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=632331097145479168https://zhuanlan.zhihu.com/p/43789231?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=632331097145479168 TTL协议各个步骤详解：前面我们简单介绍了TTL的原理，但是其实TTL协议的步骤和细节很复杂，具体见：https://xz.aliyun.com/t/2531, https://www.wst.space/ssl-part-4-tls-handshake-protocol/。 其中有几个需要注意的点： Pre-Master Secret根据选择的加密套件的不同，产生的方法也不同，如果使用的是非对称加密算法(RSA)，那么Pre-Master Secret就完全由client生成并通过证书里的公钥加密发送给server；如果使用的是秘钥交换算法(DH)，那么client和server互相传递秘钥即可生成Pre-Master Secret，这个时候证书里的公钥不再用于加密(因为client不用像RSA那样生成Pre-Master Secret)，而是只用于对传递的秘钥进行签名，以确保两端发送的秘钥没有被篡改 TLS的Client Key Exchange和Server Key Exchange都是可选的步骤，原因就是只有使用DH算法才需要这些步骤 master_secret = PRF（pre_master_secret，“master secret”，ClientHello.random + ServerHello.random）[0..47];，master_secret会用来生成对称加密的秘钥和HMAC 4.TLS在client Hello和server Hello阶段会各自给对方传一个random number，并且计算master_secret的时候会使用这两个随机数，这是为了防止重放攻击(Replay Attacks)。假设中间人监听了client端发给server端的所有消息(包括建立TLS连接的消息和后面加密的数据消息)，虽然中间人无法对消息进行解密，但过了十分钟后，它可以将这些消息复制并重新发送给server端，server端对于重放攻击与前面的正常连接生成的pre_master_secret都是一样的，如果我们只是使用pre_master_secret来生成对称加密的秘钥的话，那么中间人在与server端建立连接后，可以继续发送之前监听到的加密过的数据消息，假设这些数据消息是在淘宝下单了一件东西，那么可能造成的影响就是同样的东西被下单多次。但是由于我们使用了ServerHello.random来生成的master_secret，所以每次建立的TLS连接都会产生不同的master_secret(由master_secre生成的对称秘钥也就会不同)，即使后面中间人发送了与之前相同的加密消息，也会因为对称秘钥不同被server拒绝(https://security.stackexchange.com/questions/218491/why-using-the-premaster-secret-directly-would-be-vulnerable-to-replay-attack)","link":"/2021/05/30/Basics/Computer%20Networking%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"title":"Git Cherry Pick","text":"http://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html Cherry pick 简单来说就是把另一个分支的某个commit直接放到当前的分支，如果在merge的时候遇到conflict，处理的方式与rebase类似","link":"/2021/05/28/Basics/Git%20Cherry%20Pick/"},{"title":"Hosts","text":"https://blog.csdn.net/qq_35246620/article/details/66970211 为什么有些网站通过host可以访问而直接输入ip不能？因为是虚拟主机，主机上放置了N个网站，而每个网站绑定1个或以上域名，所以用域名访问主机可以解析到网站目录，但用IP的话服务器就不知道解析到哪个目录了！因为http请求里包含了域名信息，所以用域名访问，虚拟主机服务器会根据域名来返回网站，直接用IP访问因为没有域名信息所以服务器不知道要访问的是哪个网站目录，只有共享IP的虚拟主机或者VPS才有这情况，像有邦定独立IP功能或者独立主机的那些服务器就不会有这问题了 。","link":"/2019/09/13/Basics/Hosts/"},{"title":"Intro to Operating System","text":"","link":"/2021/10/15/Basics/Intro%20to%20Operating%20System/"},{"title":"Java 8 新特性","text":"Lambda expressionsDefault Methods for Interfaces Java 8允许我们在接口中定义non-abstract method，这在Java 8之前是不被允许的。定义的方法是使用default关键词： 1234567interface Formula { double calculate(int a); default double sqrt(int a) { return Math.sqrt(a); }} 我们可以使用deault关键词定义的方法： 123456789Formula formula = new Formula() { @Override public double calculate(int a) { return sqrt(a * 100); }};formula.calculate(100); // 100.0formula.sqrt(16); // 4.0 这里我们使用了匿名内部类。匿名内部类的一个很大的好处就是：接口是不能实例化的，如果要实例化，我们需要先定义实现这个接口的类。但很多时候，我们其实是不关心实现接口的类是怎样的，而只关心接口的方法是如何重写(override)的。匿名内部类就可以帮助我们达到目的。 Lambda expressions 匿名内部类已经简化了我们对于接口的使用，但是大家还是觉得麻烦，我们其实只是想使用一下接口里的某个方法，为什么要定义这么多东西，于是Lambda表达式诞生了。对于一个复杂的匿名内部类：12345678List&lt;String&gt; names = Arrays.asList(&quot;peter&quot;, &quot;anna&quot;, &quot;mike&quot;, &quot;xenia&quot;);Collections.sort(names, new Comparator&lt;String&gt;() { @Override public int compare(String a, String b) { return b.compareTo(a); }}); 我们使用Lambda表达式可以简化成如下，即我们省略了类名以及重写对的方法名。123Collections.sort(names, (String a, String b) -&gt; { return b.compareTo(a);}); 如果Lambda表达式重写的方法只有一行，我们可以省略{}和return；同时函数参数的类型也可以由编译器自行判断。所以最终简化为：1Collections.sort(names, (a, b) -&gt; b.compareTo(a)); Functional Interfaces 从上面的例子我们可以看出lambda表达式的巨大作用，但这个时候我们有一个疑问：接口中可能有多个方法，Java编译器是怎么知道我们重写的是哪个方法呢？ 答案是Java编译器并没有那么聪明，我们只能在函数式接口上使用Lambda表达式。 函数式接口：接口的定义中有且只有一个抽象方法，我们把这样的接口叫做函数式接口。这里我们就可以理解为什么Java 8中要为接口引入default方法，原因就是default方法不算抽象方法，函数式接口中可以有多个default方法。这个时候我们可能还有疑问：Comparator接口有两个抽象方法：int compare(T o1, T o2);和boolean equals(Object obj);，为什么还是函数式接口呢？原因是boolean equals(Object obj);是Object自带的方法，并不算抽象方法(FunctionalInterface的定义中提到：If an interface declares an abstract method overriding one of the public methods of java.lang.Object, that also does not count toward the interface’s abstract method count since any implementation of the interface will have an implementation from java.lang.Object or elsewhere)。https://stackoverflow.com/questions/23721759/functionalinterface-comparator-has-2-abstract-methods. 所有的函数式接口可以使用Lambda表达式，因为它只有一个抽象方法，所以编译器可以知道要重写的就是这个方法。 Java提供一个@FunctionalInterface的注解，当我们想要定义一个函数式接口的时候，我们可以加上这个注解，那么编译器会帮助我们判断哦我们写的接口符不符合只有一个抽象方法的标准，不符合的话会报错。所以@FunctionalInterface注解和Override注解有着类似的作用。1234@FunctionalInterfaceinterface Converter&lt;F, T&gt; { T convert(F from);} 123Converter&lt;String, Integer&gt; converter = (from) -&gt; Integer.valueOf(from);Integer converted = converter.convert(&quot;123&quot;);System.out.println(converted); // 123 Method and Constructor References Java 8还新引入了方法引用，使用方法引用，我们可以进一步简化Lambda表达式。方法引用的原理就是引用的方法的参数与返回值与所需要方法的参数与返回值完全相同。123Converter&lt;String, Integer&gt; converter = Integer::valueOf;Integer converted = converter.convert(&quot;123&quot;);System.out.println(converted); // 123 这个例子中需要的override的方法是Integer convert(String from)，这与Integer valueOf(String input)是完全一致的，所以这里我们可以使用方法引用 四种方法引用Kind Syntax ExamplesReference to a static method ContainingClass::staticMethodName Person::compareByAge; MethodReferencesExamples::appendStringsReference to an instance method of a particular object containingObject::instanceMethodName myComparisonProvider::compareByName;myApp::appendStrings2Reference to an instance method of an arbitrary object of a particular type ContainingType::methodName String::compareToIgnoreCase;String::concatReference to a constructor ClassName::new HashSet::new 方法引用的三条规则：成员方法的方法签名，前面会追加 this 的类型。静态方法的方法签名，因为没有 this, 不会追加任何东西。当 :: 前是一个实例时，这个实例会作为第一个参数给绑定到目标方法签名上。 第二条规则很好理解，Integer.valueOf()就是一个很好的例子，下面分别解释第一条与第三条规则。 第一条规则：一个类中的方法正常来说我们是不能直接使用的，除非它是一个静态方法，但是对于lambda方法引用来说，它是可以使用的。同时会在方法的参数列表最前面增加一个this的类型。 1234public static void main(String[] args){ String[] s = new String[10]; Arrays.sort(s, String::compareTo);} 上面的例子中，Arrays.sort的第二个参数应该是一个实现了int compare(String a, String b)的comparator，我们查看String的compareTo方法int compareTo(String anotherString)发现参数并不相符。这里可以使用方法引用的原因就符合第一条规则，这里String的compareTo方法的签名其实是int compareTo(String this, String anotherString)。我们发现与compare方法是相符的。 第三条规则：对于第三条规则，我们可以按照第一条规则继续理解。String的compareTo方法的签名其实是int compareTo(String this, String anotherString)，但由于这里我们::前面是一个对象，而不是类名，所以String this会被这个对象所代替，这个时候String this就不能算做方法的参数了. 12345678910public class Test { public static void main(String[] args){ List&lt;String&gt; test = new LinkedList&lt;&gt;(); test.add(&quot;1&quot;); test.add(&quot;2&quot;); test.add(&quot;3&quot;); String fake = &quot;2&quot;; test.stream().map(fake::compareTo).forEach(System.out::println); }} map的参数是一个实现了R apply(T t)的Function，明显不符合int compareTo(String this, String anotherString)的参数。但是由于我们这里的fake变量是一个对象，所以方法签名其实是int compareTo(fake, String anotherString)，本质上只有一个参数，符合R apply(T t)的参数，所以可以使用。 因此，我们也就理解了为什么System.out::println可以用在void forEach(Consumer&lt;? super T&gt; action)，但是PrintStream::println不可以：Consumer需要override的方法是void accept(T t)，而PrintStream::println的方法参数是void println(printStream this, int t)，明显不符合。而System.out是PrintStream的一个静态对象，符合第三条规则，所以可以被forEach使用 构造器的方法引用例子：1234567891011class Person { String firstName; String lastName; Person() {} Person(String firstName, String lastName) { this.firstName = firstName; this.lastName = lastName; }} 12345interface PersonFactory&lt;P extends Person&gt; { P create(String firstName, String lastName);}PersonFactory&lt;Person&gt; personFactory = Person::new; Java编译器自动根据PersonFactory.create的参数类型选择合适的构造器 Lambda Scopeshttps://github.com/winterbe/java8-tutorial#lambda-scopes Built-in Functional InterfacesJava 8有很多定义好的函数式接口，在后面的Stream介绍中，他们会被广泛的使用。 PredicatesPredicates are boolean-valued functions of one argument. The interface contains various default methods for composing predicates to complex logical terms (and, or, negate) 12345678910Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;predicate.test(&quot;foo&quot;); // truepredicate.negate().test(&quot;foo&quot;); // falsePredicate&lt;Boolean&gt; nonNull = Objects::nonNull;Predicate&lt;Boolean&gt; isNull = Objects::isNull;Predicate&lt;String&gt; isEmpty = String::isEmpty;Predicate&lt;String&gt; isNotEmpty = isEmpty.negate(); FunctionsFunctions accept one argument and produce a result. Default methods can be used to chain multiple functions together (compose, andThen). 1234Function&lt;String, Integer&gt; toInteger = Integer::valueOf;Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf);backToString.apply(&quot;123&quot;); // &quot;123&quot; SuppliersSuppliers produce a result of a given generic type. Unlike Functions, Suppliers don’t accept arguments. 12Supplier&lt;Person&gt; personSupplier = Person::new;personSupplier.get(); // new Person ConsumersConsumers represent operations to be performed on a single input argument. 12Consumer&lt;Person&gt; greeter = (p) -&gt; System.out.println(&quot;Hello, &quot; + p.firstName);greeter.accept(new Person(&quot;Luke&quot;, &quot;Skywalker&quot;)); ComparatorsComparators are well known from older versions of Java. Java 8 adds various default methods to the interface. 1234567Comparator&lt;Person&gt; comparator = (p1, p2) -&gt; p1.firstName.compareTo(p2.firstName);Person p1 = new Person(&quot;John&quot;, &quot;Doe&quot;);Person p2 = new Person(&quot;Alice&quot;, &quot;Wonderland&quot;);comparator.compare(p1, p2); // &gt; 0comparator.reversed().compare(p1, p2); // &lt; 0 Streamstream解析举map为例： 123public interface Stream&lt;T&gt; extends BaseStream&lt;T, Stream&lt;T&gt;&gt; { &lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper);} 可以看到map的参数是一个函数式接口Function，有意思的是这个函数式接口的泛型分别是? super T和? extends R，那么它们代表了什么呢？首先我们需要明白的一点是：这个例子中的T与R是泛型的形参；?是泛型的实参。T和R在使用stream的时候会被实例化，比如我们T被String实例化, R被Integer实例化，这个时候我们就能清晰的理解了：map的输入是一个Function，Function的第一个泛型参数是String或String的父类(到底是什么在定义的时候还不知道，所以用?代替)，Function的第二个泛型参数是Integer或Integer的子类(到底是什么在定义的时候还不知道，所以用?代替)。我们要搞清楚，这里我么是在使用Function而不是定义Function，所以使用的是实参?，不能因为看到T和R就混淆，这里的T和R是Stream类的形参。再根据PECS原则：Producer Extends Consumer Super，进一步深入理解：Function的V apply(P p)方法会使用第一个泛型参数，并返回第二个泛型参数，所以第一个参数确实应该定义成producer，第二个确实应该定义成consumer。 加强版类型推断(Target Type)在泛型部分我们介绍了类型推断，也就是方法泛型不需要声明泛型的类别，Java会自动根据方法的参数判断，但是在stream中，只根据方法的参数判断是不够的，加强版类型推断还可以根据返回值判断泛型的类别： 12345678910public class Test { public static void main(String[] args){ List&lt;String&gt; test = new LinkedList&lt;&gt;(); test.add(&quot;1&quot;); test.add(&quot;2&quot;); test.add(&quot;3&quot;); String fake = &quot;2&quot;; test.stream().map(fake::compareTo).forEach(System.out::println); }} 这个例子中map需要一个实现了R apply(T t)的Function，T我们根据stream可以推断出是类型是String，但是R并不能由参数推断出来，而是由返回值推断出来是Integer 下面的内容来自官方教程： https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html Target TypingHow do you determine the type of a lambda expression? Recall the lambda expression that selected members who are male and between the ages 18 and 25 years: 123p -&gt; p.getGender() == Person.Sex.MALE &amp;&amp; p.getAge() &gt;= 18 &amp;&amp; p.getAge() &lt;= 25 This lambda expression was used in the following two methods: public static void printPersons(List&lt;Person&gt; roster, CheckPerson tester) in Approach 3: Specify Search Criteria Code in a Local Class public void printPersonsWithPredicate(List&lt;Person&gt; roster, Predicate&lt;Person&gt; tester) in Approach 6: Use Standard Functional Interfaces with Lambda Expressions When the Java runtime invokes the method printPersons, it’s expecting a data type of CheckPerson, so the lambda expression is of this type. However, when the Java runtime invokes the method printPersonsWithPredicate, it’s expecting a data type of Predicate, so the lambda expression is of this type. The data type that these methods expect is called the target type. To determine the type of a lambda expression, the Java compiler uses the target type of the context or situation in which the lambda expression was found. It follows that you can only use lambda expressions in situations in which the Java compiler can determine a target type: Variable declarationsAssignmentsReturn statementsArray initializersMethod or constructor argumentsLambda expression bodiesConditional expressions, ?:Cast expressions Target Types and Method ArgumentsFor method arguments, the Java compiler determines the target type with two other language features: overload resolution and type argument inference. Consider the following two functional interfaces ( java.lang.Runnable and java.util.concurrent.Callable): 123public interface Runnable { void run();} 123public interface Callable&lt;V&gt; { V call();} The method Runnable.run does not return a value, whereas Callable.call does. Suppose that you have overloaded the method invoke as follows (see Defining Methods for more information about overloading methods): 123void invoke(Runnable r) { r.run();} 123&lt;T&gt; T invoke(Callable&lt;T&gt; c) { return c.call();} Which method will be invoked in the following statement? String s = invoke(() -&gt; &quot;done&quot;);The method invoke(Callable) will be invoked because that method returns a value; the method invoke(Runnable) does not. In this case, the type of the lambda expression () -&gt; &quot;done&quot; is Callable. stream functionsstream的函数定义查看Java官方文档 How streams work A stream represents a sequence of elements and supports different kind of operations to perform computations upon those elements: 12345678910List&lt;String&gt; myList = Arrays.asList(&quot;a1&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;c2&quot;, &quot;c1&quot;);myList .stream() .filter(s -&gt; s.startsWith(&quot;c&quot;)) .map(String::toUpperCase) .sorted() .forEach(System.out::println);// C1// C2 Stream operations are either intermediate or terminal. Intermediate operations return a stream so we can chain multiple intermediate operations without using semicolons. Terminal operations are either void or return a non-stream result. In the above example filter, map and sorted are intermediate operations whereas forEach is a terminal operation. Most stream operations accept some kind of lambda expression parameter, a functional interface specifying the exact behavior of the operation. Most of those operations must be both non-interfering and stateless. What does that mean? A function is non-interfering when it does not modify the underlying data source of the stream, e.g. in the above example no lambda expression does modify myList by adding or removing elements from the collection. A function is stateless when the execution of the operation is deterministic, e.g. in the above example no lambda expression depends on any mutable variables or states from the outer scope which might change during execution. Different kind of streams Streams can be created from various data sources, especially collections. Lists and Sets support new methods stream() and parallelStream() to either create a sequential or a parallel stream. Parallel streams are capable of operating on multiple threads and will be covered in a later section of this tutorial. We focus on sequential streams for now: 1234Arrays.asList(&quot;a1&quot;, &quot;a2&quot;, &quot;a3&quot;) .stream() .findFirst() .ifPresent(System.out::println); // a1 Calling the method stream() on a list of objects returns a regular object stream. But we don’t have to create collections in order to work with streams as we see in the next code sample: 123Stream.of(&quot;a1&quot;, &quot;a2&quot;, &quot;a3&quot;) .findFirst() .ifPresent(System.out::println); // a1 Just use Stream.of() to create a stream from a bunch of object references. Besides regular object streams Java 8 ships with special kinds of streams for working with the primitive data types int, long and double. As you might have guessed it’s IntStream, LongStream and DoubleStream.IntStreams can replace the regular for-loop utilizing IntStream.range(): 123456IntStream.range(1, 4) .forEach(System.out::println);// 1// 2// 3 All those primitive streams work just like regular object streams with the following differences: Primitive streams use specialized lambda expressions, e.g. IntFunction instead of Function or IntPredicate instead of Predicate. And primitive streams support the additional terminal aggregate operations sum() and average(): 1234Arrays.stream(new int[] {1, 2, 3}) .map(n -&gt; 2 * n + 1) .average() .ifPresent(System.out::println); // 5.0 Sometimes it’s useful to transform a regular object stream to a primitive stream or vice versa. For that purpose object streams support the special mapping operations mapToInt(), mapToLong() and mapToDouble: 12345Stream.of(&quot;a1&quot;, &quot;a2&quot;, &quot;a3&quot;) .map(s -&gt; s.substring(1)) .mapToInt(Integer::parseInt) .max() .ifPresent(System.out::println); // 3 Primitive streams can be transformed to object streams via mapToObj(): 1234567IntStream.range(1, 4) .mapToObj(i -&gt; &quot;a&quot; + i) .forEach(System.out::println);// a1// a2// a3 Here’s a combined example: the stream of doubles is first mapped to an int stream and than mapped to an object stream of strings: 12345678Stream.of(1.0, 2.0, 3.0) .mapToInt(Double::intValue) .mapToObj(i -&gt; &quot;a&quot; + i) .forEach(System.out::println);// a1// a2// a3 Processing Order Now that we’ve learned how to create and work with different kinds of streams, let’s dive deeper into how stream operations are processed under the hood. An important characteristic of intermediate operations is laziness. Look at this sample where a terminal operation is missing: 12345Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return true; }); When executing this code snippet, nothing is printed to the console. That is because intermediate operations will only be executed when a terminal operation is present. Let’s extend the above example by the terminal operation forEach: 123456Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return true; }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s)); Executing this code snippet results in the desired output on the console:filter: d2forEach: d2filter: a2forEach: a2filter: b1forEach: b1filter: b3forEach: b3filter: cforEach: c The order of the result might be surprising. A naive approach would be to execute the operations horizontally one after another on all elements of the stream. But instead each element moves along the chain vertically. The first string “d2” passes filter then forEach, only then the second string “a2” is processed. This behavior can reduce the actual number of operations performed on each element, as we see in the next example: 123456789Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .anyMatch(s -&gt; { System.out.println(&quot;anyMatch: &quot; + s); return s.startsWith(&quot;A&quot;); }); // map: d2// anyMatch: D2// map: a2// anyMatch: A2 The operation anyMatch returns true as soon as the predicate applies to the given input element. This is true for the second element passed “A2”. Due to the vertical execution of the stream chain, map has only to be executed twice in this case. So instead of mapping all elements of the stream, map will be called as few as possible. Why order mattersThe next example consists of two intermediate operations map and filter and the terminal operation forEach. Let’s once again inspect how those operations are being executed: 12345678910111213141516171819202122Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;A&quot;); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));// map: d2// filter: D2// map: a2// filter: A2// forEach: A2// map: b1// filter: B1// map: b3// filter: B3// map: c// filter: C As you might have guessed both map and filter are called five times for every string in the underlying collection whereas forEach is only called once. We can greatly reduce the actual number of executions if we change the order of the operations, moving filter to the beginning of the chain: 123456789101112131415161718Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;a&quot;); }) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));// filter: d2// filter: a2// map: a2// forEach: A2// filter: b1// filter: b3// filter: c Now, map is only called once so the operation pipeline performs much faster for larger numbers of input elements. Keep that in mind when composing complex method chains. Let’s extend the above example by an additional operation, sorted: 1234567891011121314Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .sorted((s1, s2) -&gt; { System.out.printf(&quot;sort: %s; %s\\n&quot;, s1, s2); return s1.compareTo(s2); }) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;a&quot;); }) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s)); Sorting is a special kind of intermediate operation. It’s a so called stateful operation since in order to sort a collection of elements you have to maintain state during ordering. Executing this example results in the following console output:sort: a2; d2sort: b1; a2sort: b1; d2sort: b1; a2sort: b3; b1sort: b3; d2sort: c; b3sort: c; d2filter: a2map: a2forEach: A2filter: b1filter: b3filter: cfilter: d2First, the sort operation is executed on the entire input collection. In other words sorted is executed horizontally. So in this case sorted is called eight times for multiple combinations on every element in the input collection. Once again we can optimize the performance by reordering the chain: 12345678910111213141516171819202122Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; { System.out.println(&quot;filter: &quot; + s); return s.startsWith(&quot;a&quot;); }) .sorted((s1, s2) -&gt; { System.out.printf(&quot;sort: %s; %s\\n&quot;, s1, s2); return s1.compareTo(s2); }) .map(s -&gt; { System.out.println(&quot;map: &quot; + s); return s.toUpperCase(); }) .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));// filter: d2// filter: a2// filter: b1// filter: b3// filter: c// map: a2// forEach: A2 In this example sorted is never been called because filter reduces the input collection to just one element. So the performance is greatly increased for larger input collections. Reusing StreamsJava 8 streams cannot be reused. As soon as you call any terminal operation the stream is closed: 123456Stream&lt;String&gt; stream = Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; s.startsWith(&quot;a&quot;));stream.anyMatch(s -&gt; true); // okstream.noneMatch(s -&gt; true); // exception Calling noneMatch after anyMatch on the same stream results in the following exception: java.lang.IllegalStateException: stream has already been operated upon or closed at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:229) at java.util.stream.ReferencePipeline.noneMatch(ReferencePipeline.java:459) at com.winterbe.java8.Streams5.test7(Streams5.java:38) at com.winterbe.java8.Streams5.main(Streams5.java:28)To overcome this limitation we have to to create a new stream chain for every terminal operation we want to execute, e.g. we could create a stream supplier to construct a new stream with all intermediate operations already set up: 123456Supplier&lt;Stream&lt;String&gt;&gt; streamSupplier = () -&gt; Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;) .filter(s -&gt; s.startsWith(&quot;a&quot;));streamSupplier.get().anyMatch(s -&gt; true); // okstreamSupplier.get().noneMatch(s -&gt; true); // ok Each call to get() constructs a new stream on which we are save to call the desired terminal operation. Referencehttps://github.com/winterbe/java8-tutorialhttps://winterbe.com/posts/2014/07/31/java8-stream-tutorial-examples/","link":"/2021/06/25/Basics/Java%208%20%E6%96%B0%E7%89%B9%E6%80%A7/"},{"title":"Mapreduce and Primary-Backup Key-Value Service","text":"今天写完了分布式的作业2，正好总结一下作业1-Mapreduce和作业2-Primary-Backup Key-Value Service。 Assignment 1: MapReduceDue: Sunday Sep 22, 11:59:59pmIntroductionIn this assignment you’ll build a MapReduce library as a way to learn the Goprogramming language and as a way to learn about fault tolerance indistributed systems. In the first part you will write a simpleMapReduce program. In the second part you will write a Master thathands out jobs to workers, and handles failures of workers. Theinterface to the library and the approach to fault tolerance issimilar to the one described in the originalMapReduce paper. Collaboration PolicyPlease refer to Assignment 0. SoftwareYou’ll implement this assignment (and all the assignments) in Go 1.2 orlater. The Go web site contains lots oftutorial information which you may want to look at. We supply you witha non-distributed MapReduce implementation, and a partialimplementation of a distributed implementation (just the boring bits). It’s your responsibility to install Go in your developmentenvironment. We recommend using your distribution’s package manager. On OS X with homebrew: 1$ brew install go On Ubuntu/Debian: 1$ sudo apt-get install golang On Arch: 1$ sudo pacman -S go Getting started There is an input file kjv12.txt in src/main, which wasdownloaded from here.Compile the initial software we provide you with and run it with the downloaded inputfile: 123456$ export GOPATH=$HOME/4113$ cd ~/4113/src/main$ go run wc.go master kjv12.txt sequential# command-line-arguments./wc.go:11: missing return at end of function./wc.go:15: missing return at end of function The compiler produces two errors, because the implementation of theMap and Reduce functions is incomplete. Part I: Word countModify Map and Reduce so that wc.go reports thenumber of occurrences of each word in alphabetical order. 1234567891011121314151617181920212223242526$ go run wc.go master kjv12.txt sequentialSplit kjv12.txtSplit read 4834757DoMap: read split mrtmp.kjv12.txt-0 966954DoMap: read split mrtmp.kjv12.txt-1 966953DoMap: read split mrtmp.kjv12.txt-2 966951DoMap: read split mrtmp.kjv12.txt-3 966955DoMap: read split mrtmp.kjv12.txt-4 966944DoReduce: read mrtmp.kjv12.txt-0-0DoReduce: read mrtmp.kjv12.txt-1-0DoReduce: read mrtmp.kjv12.txt-2-0DoReduce: read mrtmp.kjv12.txt-3-0DoReduce: read mrtmp.kjv12.txt-4-0DoReduce: read mrtmp.kjv12.txt-0-1DoReduce: read mrtmp.kjv12.txt-1-1DoReduce: read mrtmp.kjv12.txt-2-1DoReduce: read mrtmp.kjv12.txt-3-1DoReduce: read mrtmp.kjv12.txt-4-1DoReduce: read mrtmp.kjv12.txt-0-2DoReduce: read mrtmp.kjv12.txt-1-2DoReduce: read mrtmp.kjv12.txt-2-2DoReduce: read mrtmp.kjv12.txt-3-2DoReduce: read mrtmp.kjv12.txt-4-2Merge phaseMerge: read mrtmp.kjv12.txt-res-0Merge: read mrtmp.kjv12.txt-res-1Merge: read mrtmp.kjv12.txt-res-2 The output will be in the file “mrtmp.kjv12.txt”. Your implementation iscorrect if the following command produces the following top 10 words: 1234567891011$ sort -n -k2 mrtmp.kjv12.txt | tail -10unto: 8940he: 9666shall: 9760in: 12334that: 12577And: 12846to: 13384of: 34434and: 38850the: 62075 To make testing easy for you, run: 1$ ./test-wc.sh and it will report if your solution is correct or not. Before you start coding reread Section 2 of the MapReducepaper and our code for MapReduce, which is in mapreduce.go inpackage mapreduce. In particular, you want to read the code of thefunction RunSingle and the functions it calls. This will help youunderstand what MapReduce does and learn Go by example. Once you understand this code, implement Map and Reduce inwc.go. Hint: you can usestrings.FieldsFuncto split a string into components. Hint: for the purposes of this exercise, you can consider a word to beany contiguous sequence of letters, as determined byunicode.IsLetter.A good read on what strings are in Go is the Go Blog on strings. Hint: the strconv package (http://golang.org/pkg/strconv/) is handy toconvert strings to integers, etc. You can remove the output file and all intermediate files with: 1$ rm mrtmp.* 12345$ git commit -am &quot;[you fill me in]&quot;$ git tag -a -m &quot;i finished assignment 1 part 1&quot; a1p1$ git push origin master$ git push origin a1p1$ Part II: Distributing MapReduce jobsIn this part you will design and implement a master who distributesjobs to a set of workers. We give you the code for the RPC messages(see common.go in the mapreduce package) and the codefor a worker (see worker.go in the mapreduce package). Your job is to complete master.go in the mapreducepackage. In particular, the RunMaster() function inmaster.go should return only when all of the map and reduce taskshave been executed. This function will be invoked from the Run()function in mapreduce.go. The code in mapreduce.go already implements theMapReduce.Register RPC function for you, and passes the newworker’s information to mr.registerChannel. You should processnew worker registrations by reading from this channel. Information about the MapReduce job is in the MapReduce struct,defined in mapreduce.go. Modify the MapReduce struct tokeep track of any additional state (e.g., the set of available workers),and initialize this additional state in the InitMapReduce()function. The master does not need to know which Map or Reduce functionsare being used for the job; the workers will take care of executing theright code for Map or Reduce. In Part II, you don’t have to worry about the failures of the workers. You aredone with Part II when your implementation passes the first test set intest_test.go in the mapreduce package. test_test.go uses Go’s unit testing. From now on all exercises(including subsequent assignments) will use it, but you can always run the actualprograms from the main directory. You run unit tests in a packagedirectory as follows: 1$ go test The master should send RPCs to the workers in parallel so that the workerscan work on jobs concurrently. You will find the go statement usefulfor this purpose, and so is the Go RPC documentation. The master may have to wait for a worker to finish before it can hand outmore jobs. You may find channels useful to synchronize the threads that are waitingfor reply with the master once the reply arrives. Channels are explained in thedocument on Concurrency in Go. We’ve given you code that sends RPCs via “UNIX-domain sockets”.This means that RPCs only work between processes on the same machine.It would be easy to convert the code to use TCP/IP-basedRPC instead, so that it would communicate between machines;you’d have to change the first argument to calls to Listen() and Dial() to“tcp” instead of “unix”, and the second argument to a port numberlike “:5100”. You will need a shared distributed file system. The easiest way to track down bugs is to insert log.Printf()statements, collect the output in a file with go test &gt;out, and then think about whether the output matches yourunderstanding of how your code should behave. The last step is most important. Please let us know that you’ve gotten this far in the assignment, bypushing a tag to github. 1234$ git commit -am &quot;[you fill me in]&quot;$ git tag -a -m &quot;i finished assignment 1 part 2&quot; a1p2$ git push origin master$ git push origin a1p2 Part III: Handling worker failuresIn this part you will make the master handle worker failures. InMapReduce handling failures of workers is relatively straightforward,because the workers don’t have persistent state. If the worker fails,any RPCs that the master issued to that worker will fail (e.g., due toa timeout). Thus, if the master’s RPC to the worker fails, the mastershould re-assign the job given to the failed worker to another worker. An RPC failure doesn’t necessarily mean that the worker failed; the workermay just be unreachable but still computing. Thus, it may happen that twoworkers receive the same job and compute it. However, because jobs areidempotent, it doesn’t matter if the same job is computed twice - both times itwill generate the same output. So, you don’t have to do anything special for thiscase. (Our tests never fail workers in the middle of job, so you don’t even haveto worry about several workers writing to the same output file.) You don’t have to handle failures of the master; we will assume itwon’t fail. Making the master fault tolerant is more difficult becauseit keeps persistent state that must be replicated in order to make the masterfault tolerant. Keeping replicated state consistent in the presence offailures is challenging. Much of the later assignments is devoted to thischallenge. Your implementation must pass two remaining test cases intest_test.go. The first case tests the failure of oneworker. The second test case tests handling of many failures ofworkers. Periodically, the test cases start new workers that themaster can use to make progress, but these workers fail afterhandling a few jobs. Handin procedureYou hand in your assignment exactly as you’ve been letting us knowyour progress: 1234$ git commit -am &quot;[you fill me in]&quot;$ git tag -a -m &quot;i finished assignment 1&quot; a1handin$ git push origin master$ git push origin a1handin You should verify that you are able to see your final commit and youra1handin tag on the Github page in your repository for thisassignment. You will receive full credit if your software passes thetest_test.go tests when we run your software on our machines.We will use the timestamp of your last a1handin tag for thepurpose of calculating late days, and we will only grade that version of thecode. (We’ll also know if you backdate the tag, don’t do that.) QuestionsPlease post questions on Piazza. 作业1：作业主要是重现了著名的Mapreduce方法。Mapreduce的思路并不复杂，由名字可以知道最重要的两个步骤map和reduce，在分布式中还partition和merge两部，也就是：先将任务partition成多个部分-&gt;对每个部分分别进行map和reduce，工作可以由不同的worker同时分布进行-&gt;将结果merge在一起。\b举最常见的word count作为例子，先将文章partition成多个部分，然后对每一部分进行map，map的作用是将文章中的每个字转化成{word : 1}的模式；然后reduce将所有相同的key的value加在一起得到每部分的最终结果，然后各个部分再merge到一起得到结果。本身Mapreduce并不是很高深的方法，但它的优势在于很适合分布式系统，所以在作业中我们实现了master+worker的模式。 我在作业中的思路是：先进行map操作，有多少个map任务(partition)，master就开多少个线程，这些线程不干别的，只是一直在等待可以空闲的worker，一有空闲的worker他们就去占用然后进行map操作，操作完再释放这个worker，所以这里我们使用一个workChannel去出栈入栈现在空闲的worker。每个线程的map操作完成后向master发送一个完成的信号(通过workDoneChannel)，master统计发现所有开的线程的任务都完成后在进行reduce，思路相同。 Assignment 2: Primary/Backup Key/Value ServicePart A Due: Saturday Oct 5, 11:59:59pmPart B Due: Saturday Oct 12, 11:59:59pmIntroductionIn the MapReduce assignment handling failures is relatively easybecause the workers don’t maintain state. The master does maintainstate, but you didn’t have to make the master fault tolerant. Thisassignment is a first step towards making stateful servers fault tolerant. Road map for Assignment 2-4In the next 3 assignments you will build several key/valueservices. The service supports three RPCs: Put(key, value),PutHash(key, value), and Get(key). The service maintains a simpledatabase of key/value pairs. Put() updates the value for a particularkey in the database. PutHash chains all values for a key together,which is useful for testing purposes; PutHash stores the hash(oldvalue of the key in database, new supplied value) into database, andreturns the old value. Get() fetches the current value for a key. These 3 assignments differ in the degree of fault tolerance,performance, and scalability they provide for the key/value service: In all three assignments you will have to do substantial design. Wegive you a sketch of the overall design (and code for the boringpieces), but you will have to flesh it out and nail down a completeprotocol. The test cases test failure scenarios to see if yourprotocol is correct for that scenario. It is likely that some of thetest cases will point out a flaw in your design and protocol, and youmay have to redesign your implementation and protocol. Thinkcarefully before you start coding so that you can avoid manyiterations. We don’t give you a description of the test cases (otherthan the Go code); in the real world, you would have to come up withthem yourself. Overview of Assignment 2In this assignment you’ll make a key/value service fault-tolerantusing a form of primary/backup replication. In order to ensure thatall parties (clients and servers) agree on which server is theprimary, and which is the backup, we’ll introduce a kind of masterserver, called the viewservice. The viewservice monitors whether eachavailable server is alive or dead. If the current primary or backupbecomes dead, the viewservice selects a server to replace it. A clientchecks with the viewservice to find the current primary. The serverscooperate with the viewservice to ensure that at most one primary isactive at a time. Your key/value service will allow replacement of failed servers. Ifthe primary fails, the viewservice will promote the backup to beprimary. If the backup fails, or is promoted, and there is an idleserver available, the viewservice will cause it to be the backup.The primary will send its complete database to the new backup,and then send subsequent Puts to the backup to ensure that thebackup’s key/value database remains identical to the primary’s. It turns out that the primary must send Gets as well as Puts to the backup(if there is one), and must wait for the backup to reply beforeresponding to the client. This helps prevent two servers from actingas primary (a “split brain”). An example: S1 is the primary and S2 isthe backup. The viewservice decides (incorrectly) that S1 is dead,and promotes S2 to be primary. If a client thinks that S1 is still theprimary and sends it an operation, S1 will forward the operation toS2, and S2 will reply with an error indicating that it is no longerthe backup (assuming S2 obtained the new view from the viewservice).S1 can then return an error to the client indicating that S1 might nolonger be the primary (reasoning that, since S2 rejected theoperation, a new view must have been formed); the client can then askthe viewservice for the correct primary (S2) and send it theoperation. A failed key/value server may restart, but it will do so without acopy of the replicated data (i.e. the keys and values). That is, yourkey/value server will keep the data in memory, not on disk. Oneconsequence of keeping data only in memory is that if there’s nobackup, and the primary fails, and then restarts, it cannot then actas primary. Only RPC may be used for interaction between clients and servers,between different servers, and between different clients. For example,different instances of your server are not allowed to share Govariables or files. The design outlined in the assignment has some fault-tolerance andperformance limitations: We will address these limitations in later assignments by using betterdesigns and protocols. This assignment will make you understand whatthe tricky issues are so that you can design better design/protocols.Also, parts of this assignment’s design (e.g., a separate viewservice) are uncommon in practice. The primary/backup scheme in this assignment is not based on anypublished protocol. In fact, this assignment doesn’t specify acomplete protocol; you must flesh out the protocol. The protocol hassimilarities with Flat Datacenter Storage (the viewservice is likeFDS’s metadata server, and the primary/backup servers are like FDS’stractservers), though FDS pays far more attention to performance.It’s also a bit like a MongoDB replica set (though MongoDB selects theleader with a Paxos-like election). For a detailed description of a(different) primary-backup-like protocol, see ChainReplication.Chain Replication has higher performance than this assignment’sdesign, though it assumes that the viewservice never declares aserver dead when it is merely partitioned. See Harp and ViewstampedReplication for a detailed treatment of high-performanceprimary/backup and reconstruction of system state after various kindsof failures. Collaboration PolicyPlease refer to Assignment 0. SoftwareDo a git pull to get the latest assignment software. We supply youwith new skeleton code and new tests in src/viewservice andsrc/pbservice. 1234567891011$ cd ~/4113$ git pull...$ cd src/viewservice$ go test2012/12/28 14:51:47 method Kill has wrong number of ins: 1First primary: --- FAIL: Test1 (1.02 seconds) test_test.go:13: wanted primary /var/tmp/viewserver-35913-1, got FAILexit status 1FAIL _/afs/athena.mit.edu/user/r/t/rtm/4113/src/viewservice 1.041s Ignore the method Kill error message now and in the future.Our test code fails because viewservice/server.go has emptyRPC handlers. You can run your code as stand-alone programs using the source inmain/viewd.go,main/pbd.go, andmain/pbc.go.See the comments in pbc.go. Part A: The ViewserviceFirst you’ll implement a viewservice and make sure it passes our tests; inPart B you’ll build the key/value service. Your viewservice won’t itself bereplicated, so it will be relatively straightforward. Part B is much harder thanpart A, because the K/V service is replicated and you have to flesh out thereplication protocol. The viewservice goes through a sequence of numberedviews, each with a primary and (if possible) a backup.A view consists of a view number and the identity (network port name) ofthe view’s primary and backup servers. The primary in a view must always be either the primaryor the backup of the previous view. This helps ensurethat the key/value service’s state is preserved.An exception: when the viewservice first starts, it shouldaccept any server at all as the first primary.The backup in a view can be any server (other than the primary),or can be altogether missing if no server is available(represented by an empty string, “”). Each key/value server should send a Ping RPC once perPingInterval(see viewservice/common.go).The viewservice replies to the Ping with a description of the currentview. A Ping lets the viewservice know that the key/valueserver is alive; informs the key/value server of the currentview; and informs the viewservice of the most recent viewthat the key/value server knows about.If the viewservice doesn’t receive a Ping from a serverfor DeadPings PingIntervals, theviewservice should consider the server to be dead.When a server re-starts after a crash, it should sendone or more Pings with an argument of zero to informthe viewservice that it has crashed (of course, duplicatePing(0) calls will be interpreted as repeatedcrashes). The viewservice proceeds to a new view when either it hasn’treceived a Ping from the primary or backup for DeadPingsPingIntervals, orif the primary or backup crashed and restarted, orif there is no backup and there’s an idle server(a server that’s been Pinging but isneither the primary nor the backup).But the viewservice must not change views (i.e., returna different view to callers) untilthe primary from the current view acknowledgesthat it is operating in the current view (by sendinga Ping with the current view number). If the viewservice has not yetreceived an acknowledgment for the current view from the primary ofthe current view, the viewservice should not change views even if itthinks that the primary or backup has died. The acknowledgment rule prevents the viewservice from getting more than oneview ahead of the key/value servers. If the viewservice could get arbitrarilyfar ahead, then it would need a more complex design in which it kept a historyof views, allowed key/value servers to ask about old views, andgarbage-collected information about old views when appropriate. The downside ofthe acknowledgement rule is that if the primary fails before it acknowledges theview in which it is primary, then the viewservice cannot change views, spinsforever, and cannot make forward progress. An example sequence of view changes: The above example is overspecified; for example, when the view servergets Ping(1) from S1 for the first time, it is also OK for itto return view 1, as long as it eventually switches to view 2 (whichincludes S2). We provide you with a complete client.go andappropriate RPC definitions in common.go.Your job is to supply the needed code in server.go.When you’re done, you should pass all the viewservicetests: 1234567891011121314151617181920$ cd ~/4113/src/viewservice$ go testTest: First primary ... ... PassedTest: First backup ... ... PassedTest: Backup takes over if primary fails ... ... PassedTest: Restarted server becomes backup ... ... PassedTest: Idle third server becomes backup if primary fails ... ... PassedTest: Restarted primary treated as dead ... ... PassedTest: Viewserver waits for primary to ack view ... ... PassedTest: Uninitialized server can't become primary ... ... PassedPASSok viewservice 7.457s The above output omits some benign Go RPC errors. Hint: you’ll want to add field(s) to ViewServer inserver.go in order to keep track of the most recenttime at which the viewservice has heard a Ping from eachserver. Perhaps a map from server names totime.Time. You can find the current time with time.Now(). Hint: add field(s) to ViewServer to keep track of thecurrent view. Hint: you’ll need to keep track of whether the primary for thecurrent view has acknowledged it (in PingArgs.Viewnum). Hint: your viewservice needs to make periodic decisions, forexample to promote the backup if the viewservice has missed DeadPingspings from the primary. Add this code to the tick()function, which is called once per PingInterval. Hint: there may be more than two servers sending Pings. Theextra ones (beyond primary and backup) are volunteeringto be backup if needed. Hint: the viewservice needs a way to detect that a primaryor backup has failed and re-started. For example, the primarymay crash and quickly restart without missing sending asingle Ping. Hint: study the test cases before you start programming. If you fail atest, you may have to look at the test code in test_test.go to figureout what the failure scenario is. The easiest way to track down bugs is to insert log.Printf()statements, collect the output in a file with go test &gt;out, and then think about whether the output matches yourunderstanding of how your code should behave. The last step is most important. Remember that the Go RPC server framework starts a new thread for eachreceived RPC request. Thus if multiple RPCs arrive at the same time(from multiple clients), there may be multiple threads runningconcurrently in the server. The tests kills a server by setting its dead flag. You mustmake sure that your server terminates correctly when that flag is set, otherwiseyou may fail to complete the test cases. Part B: The primary/backup key/value serviceYour key/value service should continue operating correctly as long asthere has never been a time at which no server was alive. It shouldalso operate correctly with partitions: a server that suffers fromtemporary network failure without crashing, or can talk to somecomputers but not others. If your service is operating with just oneserver, it should be able to incorporate a recovered or idle server(as backup), so that it can then tolerate another server failure. Correct operation means that calls to Clerk.Get(k) return the latestvalue set by a successful call to Clerk.Put(k,v) orClerk.PutHash(k,v), or an empty string if the key has never beenPut()’ed. All operations should provide at-most-once semantic. You should assume that the viewservice never halts or crashes. Your clients and servers may only communicate using RPC, and bothclients and servers mustsend RPCs with the call() function in client.go. It’s crucial that only one primary be active at any given time. Youshould have a clear story worked out for why that’s the case for yourdesign. A danger: suppose in some view S1 is the primary; the viewservice changesviews so that S2 is the primary; but S1 hasn’t yet heard about the newview and thinks it is still primary. Then some clients might talk toS1, and others talk to S2, and not see each other’s Put()s. A server that isn’t the active primary should either not respond toclients, or respond with an error: it should set GetReply.Err orPutReply.Err to something other than OK. Clerk.Get(), Clerk.Put(), and Clerk.PutHash() should only return when theyhave completed the operation. That is, Puts should keep trying until it hasupdated the key/value database, and Clerk.Get() should keep trying until it hasretrieved the current value for the key (if any). Your server must filter outthe duplicate RPCs that these client re-tries will generate to ensureat-most-once semantics for operations. You can assume that each clerk has onlyone outstanding Put or Get. Think carefully about what the commit point is fora Put. A server should not talk to the viewservice for every Put/Getit receives, since that would put the viewservice on the critical pathfor performance and fault-tolerance. Instead servers shouldPing the viewservice periodically(in pbservice/server.go‘s tick())to learn about new views. Part of your one-primary-at-a-time strategy should rely on theviewservice only promoting the backup from view ito be primary in view i+1. If the old primary fromview i tries to handle a client request, it willforward it to its backup. If that backup hasn’t heard aboutview i+1, then it’s not acting as primary yet, sono harm done. If the backup has heard about view i+1and is acting as primary, it knows enough to reject the oldprimary’s forwarded client requests. You’ll need to ensure that the backup sees every update to thekey/value database, by a combination of the primary initializing it withthe complete key/value database and forwarding subsequentclient Puts. The skeleton code for the key/value servers is in src/pbservice.It uses your viewservice, so you’ll have to set upyour GOPATH as follows: 12345678910111213$ export GOPATH=$HOME/4113$ cd ~/4113/src/pbservice$ go test -i$ go testSingle primary, no backup: --- FAIL: TestBasicFail (2.00 seconds) test_test.go:50: first primary never formed view--- FAIL: TestFailPut (5.55 seconds) test_test.go:165: wrong primary or backupConcurrent Put()s to the same key: --- FAIL: TestConcurrentSame (8.51 seconds)...Partition an old primary: --- FAIL: TestPartition (3.52 seconds) test_test.go:354: wrong primary or backup... Here’s a recommended plan of attack: You’re done if you can pass all the pbservice tests: 1234567891011121314151617181920212223242526272829303132$ cd ~/4113/src/pbservice$ go testTest: Single primary, no backup ... ... PassedTest: Add a backup ... ... PassedTest: Primary failure ... ... PassedTest: Kill last server, new one should not be active ... ... PassedTest: at-most-once Put; unreliable ... ... PassedTest: Put() immediately after backup failure ... ... PassedTest: Put() immediately after primary failure ... ... PassedTest: Concurrent Put()s to the same key ... ... PassedTest: Concurrent Put()s to the same key; unreliable ... ... PassedTest: Repeated failures/restarts ... ... Put/Gets done ... ... PassedTest: Repeated failures/restarts; unreliable ... ... Put/Gets done ... ... PassedTest: Old primary does not serve Gets ... ... PassedTest: Partitioned old primary does not complete Gets ... ... PassedPASSok pbservice 113.352s You’ll see some “method Kill has wrong number of ins” complaintsand lots of “rpc: client protocol error” and “rpc: writing response”complaints; ignore them. Hint: you’ll probably need to create new RPCs to forward clientrequests from primary to backup, since the backup should rejecta direct client request but should accept a forwarded request. Hint: you’ll probably need to create new RPCs to handle the transferof the complete key/value database from the primary to a new backup.You can send the whole database in one RPC (for example,include a map[string]string in the RPC arguments). Hint: the state to filter duplicates must be replicated along with the key/valuestate. Hint: the tester arranges for RPC replies to be lost in tests whosedescription includes “unreliable”. This will cause RPCs to be executedby the receiver, but since the sender sees no reply, it cannottell whether the server executed the RPC. You may find you want to generate numbers that havea high probability of being unique. Try this: 12345678import &quot;crypto/rand&quot;import &quot;math/big&quot;func nrand() int64 { max := big.NewInt(int64(1) &lt;&lt; 62) bigx, _ := rand.Int(rand.Reader, max) x := bigx.Int64() return x} The tests kills a server by setting its dead flag. You mustmake sure that your server terminates correctly when that flag is set, otherwiseyou may fail to complete the test cases. Hint: even if your viewserver passed all the tests in Part A, itmay still have bugs that cause failures in Part B. Hint: study the test cases before you start programming Handin procedureYou hand in your assignment as before. For Part A: 1234$ git commit -am &quot;[you fill me in]&quot;$ git tag -a -m &quot;i finished assignment 2a&quot; a2ahandin$ git push origin master$ git push origin a2ahandin For Part B: 1234$ git commit -am &quot;[you fill me in]&quot;$ git tag -a -m &quot;i finished assignment 2b&quot; a2bhandin$ git push origin master$ git push origin a2bhandin You should verify that you are able to see your final commit and tagson the Github page of your repository for this assignment. You will receive full credit if your software passes thetest_test.go tests when we run your software on our machines.We will use the timestamp of your last handin tag for the purposeof calculating late days and we will only grade that version of the code.(We’ll also know if you backdate the tag, don’t do that.) QuestionsPlease post questions on Piazza. 作业2：作业1中的wordCount由于是stateless，所以面对fault-tolerant处理方法很简单，但是大多数生活中的系统都是stateless的，所以我们后面三个作业逐步深入解决这个问题。作业2中我们需要实现的是一个key/value数据库，他并不是stateless的，所以我们需要replication。因此这里我们采用Primary+Backup的组合，Primary是现在存储数据的数据库，Backup是后备且与Primary有完全一样数据的备份。那么问题来了：我们的client如何知道哪个数据库server是Primary哪个是Backup，我们不可能不同的client向两个数据库随便传数据，肯定是数据交互都是与Primary进行，Primary死掉Backup才会上位，这个作业我们采用的方式是假设有一个不会死掉的viewServer一直监视着Primary和Backup，client想要发数据前先去viewServer那里得到最新的Primary地址，然后进行数据交互PartA：PartA部分比较简单，主要就是实现一个viewServer，我们假设viewServer不会死掉，它的功能就是自身存储viewNumber+Primary+Backup，同时每隔固定的时间去Ping Primary和Backup当前viewNumber，这种时候Primary和Backup有两种情况：如果正常则回传viewNumber，死掉则无法回传，我们的viewServer在检测到Primary传回相同的viewNumber后得知Primary进行了ACK，如果viewServer已知Primary已经传回了ACK，同时长时间收不到Primary/backup的信号，那么认为他们死掉了，随即采取相应的解决措施，并改变viewNumber。作业里面有解释为什么一定要等Primary ACK后才可以改变viewNumber。PartB：PartB部分比起PartA就要复杂的多了，主要原因是这里我们的Primary和Backup会经常死掉，而PartA的viewServer我们假设它不会死掉，所以其实PartB的关键就是要保证时时刻刻Primary与BackUp的数据是一致的。所以我么需要有一个机制去不停地将Primary的数据共享给我们的备份以确保Primary死掉以后Backup存储的数据是正确的，所以作业中我用了两个RPC，分别是当我的Primary检测到有新的Backup启动的时候，我把自己的数据发给他；另一个是每当client向Priamry put的时候，我都会发给Backup同时必须是先发给backup并确认backup接受这个数据没问题以后才更新我的Primary，否则如果Backup接受失败而Primary却更新了，那么系统就会出现问题另一个难点在于我们的系统会有网络故障的情况，也就是Primary与Backup之间可能会出现unreliable的通信问题。那么解决办法是我们实现at-most once的机制，client的put和get请求都有一个uniqueID，同时client的请求机制是如果没得到结果就一直不同的去请求，我们的Primary和Backup如果对于某个put执行完全成功了，我们把结果记录在{UniqueID：result}的map中，当下次client发来同样的ID的时候，我们直接返回，不再进行其他操作。这里就遇到了一个很严重的bug：对于多个client同时发来的请求put1(1, 1)和put2(1, 2)，put1进入Primary后传给Backup，Backup执行成功返回Primary，但这时返回丢失，Primary返回给client失败(此时Backup{1, 1})，在client再次请求put1之前，put2进来了并且一切正常(此时Primary{1, 2}，Backup{1, 2})，之后client1再次发送有uniqueID的请求put1，由于Backup此前已经存有了这个UniqueID，那么不会更新结果，但Primary没有这个UniqueID，会更新为{1, 1}，这时就导致了Primary和Backup的不一样。详见testcase：TestConcurrentSameUnreliable。","link":"/2019/10/12/Basics/Mapreduce%20and%20Primary-Backup%20Key-Value%20Service/"},{"title":"Master Theorem","text":"Master Theorem(主定理)主定理用于在divide&amp;conquer问题中求时间复杂度，以前总是记不住，今天总结了一下，方便记忆。 Example: merge sort: T(n) = 2*T(n/2)+O(n) a = 2, b =2, n^logba == n, 所以符合2.1, 所以结果是O(nlogn)","link":"/2019/10/03/Basics/Master%20Theorem/"},{"title":"Package, classpath and jar","text":"Package, classpath and jarhttps://www.liaoxuefeng.com/wiki/1252599548343744/1260467032946976https://www.liaoxuefeng.com/wiki/1252599548343744/1260466914339296","link":"/2020/03/27/Basics/Package,%20classpath%20and%20jar/"},{"title":"Paxos-based Key&#x2F;Value Service","text":"分布式的第三次作业，作业的内容是实现基于Paxos的Key/Value pair数据库 Assignment 3: Paxos-based Key/Value ServicePart A Due: Saturday Nov 2, 11:59:59pmPart B Due: Saturday Nov 9, 11:59:59pmIntroductionYour Assignment 2 depends on a single master view server to pick the primary.If the view server is not available (crashes or has network problems),then your key/value service won’t work, even if both primary andbackup are available. It also has the less critical defect that itcopes with a server (primary or backup) that’s briefly unavailable(e.g. due to a lost packet) by either blocking or declaring it dead;the latter is very expensive because it requires a complete key/valuedatabase transfer. In this assignment you’ll fix above problems by using Paxos to manage thereplication of a key/value store. You won’t have anythingcorresponding to a master view server. Instead, a set of replicas willprocess all client requests in the same order, using Paxos to agree onthe order. Paxos will get the agreement right even if some of thereplicas are unavailable, or have unreliable network connections, oreven if subsets of the replicas are isolated in their own networkpartitions. As long as Paxos can assemble a majority of replicas, itcan process client operations. Replicas that were not in the majoritycan catch up later by asking Paxos for operations that they missed. Your system will consist of the following players: clients, kvpaxos servers,and Paxos peers. Clients send Put(), PutHash(), and Get() RPCs to key/valueservers (called kvpaxos servers). A client can send an RPC to any of the kvpaxosservers, and should retry by sending to a different server if there’s afailure. Each kvpaxos server contains a replica of the key/value database;handlers for client Get() and Put() RPCs; and a Paxos peer. Paxos takes the formof a library that is included in each kvpaxos server. A kvpaxos server talks toits local Paxos peer (via method calls). The different Paxos peers talk to eachother via RPCs to achieve agreement on each operation. Your Paxos library’s interface supports an indefinite sequence ofagreement “instances”. The instances are numbered with sequence numbers. Eachinstance is either “decided” or not yet decided. A decided instancehas a value. If an instance is decided, then all the Paxos peers thatare aware that it is decided will agree on the same value for thatinstance. The Paxos library interface allows kvpaxos to suggest avalue for an instance, and to find out whether an instance has beendecided and (if so) what that instance’s value is. Your kvpaxos servers will use Paxos to agree on the order in whichclient Put()s and Get()s execute. Each time a kvpaxos server receivesa Put() or Get() RPC, it will use Paxos to cause some Paxos instance’svalue to be a description of that Put() or Get(). That instance’ssequence number determines when the Put() or Get() executes relativeto other Put()s and Get()s. In order to find the value to be returnedby a Get(), kvpaxos should first apply all Put()s that are orderedbefore the Get() to its key/value database. You should think of kvpaxos as using Paxos to implement a “log” ofPut/Get operations. That is, each Paxos instance is a log element, andthe order of operations in the log is the order in which all kvpaxosservers will apply the operations to their key/value databases. Paxoswill ensure that the kvpaxos servers agree on this order. Only RPC may be used for interaction between clients and servers,between different servers, and between different clients. For example,different instances of your server are not allowed to share Govariables or files. Your Paxos-based key/value storage system will have some limitationsthat would need to be fixed in order for it to be a serious system. Itwon’t cope with crashes, since it stores neither the key/valuedatabase nor the Paxos state on disk. It requires the set of servers to befixed, so one cannot replace old servers. Finally, it is slow: manyPaxos messages are exchanged for each Put() and Get(). All of theseproblems can be fixed. You should consult the Paxos lecture notes and the Paxos assignedreading. For a wider perspective, take a look at Chubby, Paxos Made Live,Spanner, Zookeeper, Harp, Viewstamped Replication,and Gaios Collaboration PolicyPlease refer to Assignment 0. SoftwareDo a git pull to get the latest assignment software. We supply youwith new skeleton code and new tests in src/paxos andsrc/kvpaxos. 12345678910$ cd ~/4113$ git pull...$ cd src/paxos$ go testSingle proposer: --- FAIL: TestBasic (5.02 seconds) test_test.go:48: too few decided; seq=0 ndecided=0 wanted=3Forgetting: --- FAIL: TestForget (5.03 seconds) test_test.go:48: too few decided; seq=0 ndecided=0 wanted=6... Ignore the huge number of “has wrong number of ins” and “type Paxoshas no exported methods” errors. Part A: PaxosFirst you’ll implement a Paxos library.paxos.go contains descriptions of the methods you mustimplement. When you’re done, you should pass all the tests in thepaxos directory (after ignoring Go’s many complaints): 1234567891011121314151617181920212223242526272829303132333435363738$ cd ~/4113/src/paxos$ go testTest: Single proposer ... ... PassedTest: Many proposers, same value ... ... PassedTest: Many proposers, different values ... ... PassedTest: Out-of-order instances ... ... PassedTest: Deaf proposer ... ... PassedTest: Forgetting ... ... PassedTest: Lots of forgetting ... ... PassedTest: Paxos frees forgotten instance memory ... ... PassedTest: Many instances ... ... PassedTest: Minority proposal ignored ... ... PassedTest: Many instances, unreliable RPC ... ... PassedTest: No decision if partitioned ... ... PassedTest: Decision in majority partition ... ... PassedTest: All agree after full heal ... ... PassedTest: One peer switches partitions ... ... PassedTest: One peer switches partitions, unreliable ... ... PassedTest: Many requests, changing partitions ... ... PassedPASSok paxos 59.523s Your implementation must support this interface: 123456px = paxos.Make(peers []string, me int)px.Start(seq int, v interface{}) // start agreement on new instancepx.Status(seq int) (decided bool, v interface{}) // get info about an instancepx.Done(seq int) // ok to forget all instances &lt;= seqpx.Max() int // highest instance seq known, or -1px.Min() int // instances before this have been forgotten An application calls Make(peers,me) to create a Paxos peer. The peersargument contains the ports of all the peers (including this one), andthe me argument is the index of this peer in the peers array.Start(seq,v) asks Paxos to start agreement on instance seq, withproposed value v; Start() should return immediately, without waitingfor agreement to complete. The application calls Status(seq) to findout whether the Paxos peer thinks the instance has reached agreement,and if so what the agreed value is.Status() should consult the local Paxos peer’s state and returnimmediately; it should not communicate with other peers.The application may call Status()for old instances (but see the discussion of Done() below). Your implementation should be able to make progress on agreement formultiple instances at the same time. That is, if application peerscall Start() with different sequence numbers at about the same time,your implementation should run the Paxos protocol concurrently for allof them. You should not wait for agreement to complete forinstance i before starting the protocol for instance i+1. Each instanceshould have its own separate execution of the Paxos protocol. A long-running Paxos-based server must forget aboutinstances that are no longer needed, and free the memorystoring information about those instances.An instance is needed if theapplication still wants to be able to call Status() for that instance,or if another Paxos peer may not yet have reached agreement on thatinstance. Your Paxos should implement freeing of instances in thefollowing way. When a particular peer application will no longer needto call Status() for any instance &lt;= x, it should call Done(x). ThatPaxos peer can’t yet discard the instances, since some other Paxospeer might not yet have agreed to the instance. So each Paxos peershould tell each other peer the highest Done argument supplied by itslocal application. Each Paxos peer will then have a Done valuefrom each other peer. It should find the minimum, and discard allinstances with sequence numbers &lt;= that minimum. The Min() methodreturns this minimum sequence number plus one. It’s OK for your Paxos to piggyback the Done value in the agreementprotocol packets; that is, it’s OK for peer P1 to only learn P2’slatest Done value the next time that P2 sends an agreement message toP1. If Start() is called with a sequence number less than Min(),the Start() call should be ignored. If Status() is called with asequence number less than Min(), Status() should return false(indicating no agreement). Here is Paxos pseudocode (for a single instance): 123456789101112131415161718192021222324252627282930proposer(v): while not decided: choose n, unique and higher than any n seen so far send prepare(n) to all servers including self if prepare_ok(n_a, v_a) from majority: v' = v_a with highest n_a; choose own v otherwise send accept(n, v') to all if accept_ok(n) from majority: send decided(v') to allacceptor's state: n_p (highest prepare seen) n_a, v_a (highest accept seen)acceptor's prepare(n) handler: if n &gt; n_p n_p = n reply prepare_ok(n_a, v_a) else reply prepare_rejectacceptor's accept(n, v) handler: if n &gt;= n_p n_p = n n_a = n v_a = v reply accept_ok(n) else reply accept_reject Here’s a reasonable plan of attack: Add elements to the Paxos struct in paxos.go to hold the state you’ll need,according to the lecture pseudocode. You’ll need to define a struct to holdinformation about each agreement instance. Define RPC argument/reply type(s) for Paxos protocol messages, based on thelecture pseudocode. The RPCs must include the sequence number for the agreementinstance to which they refer. Remember the field names in the RPC structures muststart with capital letters. Write a proposer function that drives the Paxos protocol for an instance, andRPC handlers that implement acceptors. Start a proposer function in its own threadfor each instance, as needed (e.g. in Start()). At this point you should be able to pass the first few tests. Now implement forgetting. Hint: more than one Paxos instance may be executing at a given time,and they may be Start()’ed and/or decided out of order (e.g. seq 10 maybe decided before seq 5). Hint: in order to pass tests assuming unreliable network, your paxosshould call the local acceptor through a function call rather than RPC. Hint: remember that multiple application peers may call Start() on thesame instance, perhaps with different proposed values. An applicationmay even call Start() for an instance that has already been decided. Hint: think about how your paxos will forget (discard) information aboutold instances before you start writing code. Each Paxos peer will need tostore instance information in some data structure that allowsindividual instance records to be deleted (so that the Go garbagecollector can free / re-use the memory). Hint: you do not need to write code to handle the situation wherea Paxos peer needs to re-start after a crash. If one of yourPaxos peers crashes, it will never be re-started. Hint: have each Paxos peer start a thread per un-decided instancewhose job is to eventually drive the instance to agreement, byacting as a proposer. Hint: a single Paxos peer may be acting simultaneously as acceptor andproposer for the same instance. Keep these two activities as separateas possible. Hint: a proposer needs a way to choose a higher proposal number thanany seen so far. This is a reasonable exception to the rule thatproposer and acceptor should be separate. It may also be useful for thepropose RPC handler to return the highest known proposal number if itrejects an RPC, to help the caller pick a higher one next time.The px.me value will be different in each Paxos peer,so you can use px.me to help ensure that proposal numbersare unique. Hint: figure out the minimum number of messages Paxos should use whenreaching agreement in non-failure cases and make your implementationuse that minimum. Hint: the tester calls Kill() when it wants your Paxos to shut down;Kill() sets px.dead. You should check px.dead in any loops you havethat might run for a while, and break out of the loop if px.dead istrue. It’s particularly important to do this in any long-runningthreads you create. Part B: Paxos-based Key/Value ServerNow you’ll build kvpaxos, a fault-tolerant key/value storage system.You’ll modify kvpaxos/client.go,kvpaxos/common.go, and kvpaxos/server.go. Your kvpaxos replicas should stay identical; the only exceptionis that some replicas may lag others if they are notreachable. If a replica isn’t reachable for a while, but then startsbeing reachable, it should eventually catch up (learn about operationsthat it missed). Your kvpaxos client code should try different replicas it knows aboutuntil one responds. A kvpaxosreplica that is part of a majority of replicas that can all reach eachother should be able to serve client requests. Your storage system must provide sequential consistency to applications thatuse its client interface. That is, completed application calls to theClerk.Get(), Clerk.Put(), and Clerk.PutHash() methods inkvpaxos/client.go must appear to have affected all replicas in the sameorder and have at-most-once semantics. A Clerk.Get() should see the valuewritten by the most recent Clerk.Put() (in that order) to the same key. Oneconsequence of this is that you must ensure that each application call toClerk.Put() must appear in that order just once (i.e., write the key/valuedatabase just once), even though internally your client.go may have tosend Put() and PutHash() RPCs multiple times until it finds a kvpaxos serverreplica that replies. Here’s a reasonable plan: Fill in the Op struct in server.go with the “value” information that kvpaxos willuse Paxos to agree on, for each client request. Op field names must start with capitalletters. You should use Op structs as the agreed-on values – for example, you shouldpass Op structs to Paxos Start(). Go’s RPC can marshall/unmarshall Op structs; thecall to gob.Register() in StartServer() teaches it how. Implement the Put() handler in server.go. It should enter a Put Op in the Paxos log(i.e., use Paxos to allocate a Paxos instance, whose value includes the key and value(so that other kvpaxoses know about the Put())). Implement a Get() handler. It should enter a Get Op in the Paxos log, and then“interpret” the the log before that point to make sure its key/value database reflectsall recent Put()s. Add code to cope with duplicate client Put()s – i.e. situations in which Put() inclient.go sends the same request to multiple kvpaxos replicas. The Put()/PutHash()should execute just once. Hint: your server should try to assign the next available Paxosinstance (sequence number) to each incoming client RPC. However, someother kvpaxos replica may also be trying to use that instance for adifferent client’s operation. So the kvpaxos server has to be preparedto try different instances. Hint: your kvpaxos servers should not directly communicate; theyshould only interact with each other through the Paxos log. Hint: as in Assignment 2, you will need to uniquely identify clientoperations to ensure that they execute just once.Also as in Assignment 2, you can assume that each clerk has only oneoutstanding Put or Get. Hint: a kvpaxos server should not complete a Get() RPC if it is notpart of a majority (so that it does not serve stale data). This meansthat each Get() (as well as each Put()) must involve Paxosagreement. Hint: don’t forget to call the Paxos Done() method when a kvpaxoshas processed an instance and will no longer need it or anyprevious instance. Hint: your code will need to wait for Paxos instances to completeagreement. The only way to do this is to periodically call Status(),sleeping between calls. How long to sleep? A good plan is to checkquickly at first, and then more slowly: 123456789101112to := 10 * time.Millisecondfor { decided, _ := kv.px.Status(seq) if decided { ... return } time.Sleep(to) if to &lt; 10 * time.Second { to *= 2 }} Hint: if one of your kvpaxos servers falls behind (i.e. did notparticipate in the agreement for some instance), it will later need tofind out what (if anything) was agreed to. A reasonable way to to thisis to call Start(), which will either discover the previouslyagreed-to value, or cause agreement to happen. Think about what valuewould be reasonable to pass to Start() in this situation. Hint: When the test fails, check for gob error (e.g. “rpc: writingresponse: gob: type not registered for interface …”) in the log because godoesn’t consider the error fatal, although it is fatal for the assignment. Handin procedureYou hand in your assignment as before. For Part A: 1234$ git commit -am &quot;[you fill me in]&quot;$ git tag -a -m &quot;i finished assignment 3a&quot; a3ahandin$ git push origin master$ git push origin a3ahandin For Part B: 1234$ git commit -am &quot;[you fill me in]&quot;$ git tag -a -m &quot;i finished assignment 3b&quot; a3bhandin$ git push origin master$ git push origin a3bhandin You should verify that you are able to see your final commit and tagson the Github page of your repository for this assignment. You will receive full credit if your software passes thetest_test.go tests when we run your software on our machines.We will use the timestamp of your last handin tag for the purposeof calculating late days and we will only grade that version of the code.(We’ll also know if you backdate the tag, don’t do that.) QuestionsPlease post questions on Piazza. Part A 部分主要是基于Paxos协议的三个阶段进行编写：prepare, accecpt and decide。由于我们的系统是可以同时处理多个请求的，所以对于不同的请求我们用instance进行代表，每一个instance可以有decided或者undecided的状态，我们的paxos协议会使每一个instance最后变成decided状态，每一个instance都储存着操作的结果。PartB使用我们之前写好的Paxos Library实现Key/Value存储，与作业2相似，我们仍旧需要实现at most once semantic，所以仍现需要每次发出get或者put的时候都一起发出一个sequence unique ID。由于我们的instances中存着操作的结果，所以我们每进行put或者get，都从instance number 0开始进行检查：从0开始检查每一个instanceSeqNum，如果decided(已经有别的操作占用这个instance)，那么将这个操作的结果写入自己的数据库中；如果没有decided，那么将这次的操作占用这个instance并等待所有pvserver同步完成(同步完成也就是decided)。所以本质上paxos协议(partA)是可以使所有的partition储存相同的信息，partB因为我们要建立有PUT和GET操作的数据库，所以相当于我们存储的相同的信息是这些操作的LOG集合","link":"/2019/11/26/Basics/Paxos-based%20Key-Value%20Service/"},{"title":"Thinking in Java阅读笔记","text":"Initialization &amp; Clean upStatic data initialization 当新建一个类或者直接使用这个类里的static变量的时候，这个类里所有的static变量就会被初始化，static变量先于non-static变量进行初始化，并且整个程序中只有一份static变量的instance（即被所有对象共享） static block: 跟static变量一样，随着类的加载而执行，只执行一次，并优先于主函数，可用于给类进行初始化 Access controlpublic&gt;protected&gt;package(default)&gt;private public所有人都有access protected当前package或者继承类有access package(default)只有当前package的其他class有access。需要注意的是，liushiy.package1和liushiy.package2是两个不同的package，即使某个variable在liushiy.package1是package access，我们在liushiy.package2是不能使用的 private只有当前这个class可以使用 Reusing ClassesComposition Composition(组合)是最常见的复用类的方法，当我们创建一个新类的时候，里面包含旧类的对象 组合是一种HAS-A的关系，新类中有旧类 Inheritance Inheritance(继承)是IS-A的关系，子类是一种父类 继承的关键字是extends，子类自动继承父类所有的属性(fields)和方法(methods） 子类并不局限于使用父类的fields和methods，可以创建自己的fields和methods 子类可以重写(override)父类已有的methods。重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。即外壳不变，核心重写！重载(overloading)是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。每个重载的方法(或者构造函数)都必须有一个独一无二的参数类型列表。子类进行重写的时候，可以在重写的方法上加上@override注解。@override注解不是必须的，加上的好处是编译器会确认注解后面的方法确实是在重写。可以避免诸如方法名写错(编译器会认为这是子类的新方法，而不是在重写父类的旧方法)，或者想要重写但不小心写成了重载 如果子类重写了父类的某个方法, 但是又想使用父类的这个方法，那么我们可以用super关键字去call父类的方法。下面这个例子的输出是： Fake Miao 12345public class Animal { public void call(){ System.out.println(&quot;Fake&quot;); }} 123456789101112public class Cat extends Animal{ @Override public void call(){ super.call(); System.out.println(&quot;Miao&quot;); } public static void main(String[] args) { Animal animal = new Cat(); animal.call(); }} 子类在初始化的时候，会先自动调用父类的default构造器(constructor)去初始化父类的属性。如果父类没有默认constructor， 那么子类必须使用父类其他的constructor去初始化属性，即我们需要在子类中使用super关键词去call父类的constructor，并且super关键词必须在子类constructor的第一句。 如果父类既没有默认构造器，我们又不在子类调用某个父类的构造器，那么编译器会报错: There is no default constructor avaliable 123456789public class Animal { private String name; public Animal(String name){ this.name = name; } public void call(){ System.out.println(name); }} 12345678910111213141516public class Cat extends Animal{ public Cat(){ super(&quot;Fake&quot;); } @Override public void call(){ super.call(); System.out.println(&quot;Miao&quot;); } public static void main(String[] args) { Animal animal = new Cat(); animal.call(); }} 关于第六条，我们可以理解为初始化子类对象的时候，会同时在其中创建一个父类的subobject，本质上的理解：https://www.zhihu.com/question/51920553 继承类的初始化顺序：父类static initialization-&gt;子类static initialization-&gt;父类fields被设置成默认值-&gt;子类fields被设置成默认值-&gt;父类constructor-&gt;子类constructor The Final keywordFinal keyword means ‘This can not be changed’ in general. You might want to prevent cahges for two reasons: design or effciency. Final dataFinal data分为两种，一种是final primitives，一种是final object reference。Final primitives代表着这个field的value就是不可变的，final object reference代表这个field的reference不可以再变了，但是它的value是可以变的定义为final的fields是可以没有被初始化的，但是在使用这个field之前一定要完成初始化 Final argumentsFinal arguments means that inside the method you cannot change what the argument reference points Final methodsFinal methods的作用是防止子类override Final and Privateprivate method in a class are implicitly final. 因为private method只有自己的类中能看到，即使是子类也看到父类的private method，更不能够override它 Final classesFinal class不能被继承，并且final class里的methods自动是final的(因为不能继承，也就谈不上override了) Polymorphism(dynamic binding/late binding/run-time binding)Upcast: 从子类转成父类，总是安全的； downcase：从父类转成子类，需要加括号并确认要转的确实是这个子类 Method-call bindingEarly-binding: 在compile time，编译器只会根据某个对象的表面上写的是什么class从而判断他能不能call某个方法，如果不能的话会报compile-errorLate-binding：在run time，编译器会真的决定这个对象到底是什么class(而不是根据他表面上是什么class)，并使用它真正的class里的那个method去call比如Shape s = new Circle(); s.draw();，compile time，编译器只会检查Shape类有没有draw这个方法，没有的话报错，run time，当我们想要使用s对象的draw method的时候，编译期才会真正去查看s对象真是的类，虽然他被定义为Shape类，但真实的类是Circle，所以最终会调用Circle类里的draw方法总结来说，compile time看等号左边，run time看等号右边 几个不支持多态(dynamic binding)的例子 overriding private method fields：fields不存在override也就没有多态，不会使用dynamic binding，会使用等号左边的class里的field。子类和父类是可以有相同名字的field的，子类默认使用本身类的field，如果想使用父类的field，需要加上super static methods： static method是和class绑定的，不会使用dynamic binding，会使用等号左边的class里的static method InterfaceAbstract classes and methods 抽象方法指的是一个方法没有具体的实现，比如abstract void f()。 一个类中如果有一个或多个抽象方法，那么这个类我们必须声明成抽象类abstract class test(){} 抽象类不可以声明相应的对象，抽象类是为了继承使用的。当我们继承一个抽象类的时候，子类可以override抽象类中的抽象方法，也可以继续不实现这个抽象方法，而是继续声明成抽象方法，留给这个子类的子类去实现 抽象类可以一个抽象方法都没有，即都是实现好的方法，这个时候使用抽象类的目的就是不让这个类可以声明对象 Interfaces The interface keyword produces a completely abstract class, ont that provides no implementation at all. it allows the creator to determine method names, argument lists and return types, but no method bodies We can define fileds in interface, but these are implicitly static and final Interface里定义的methods即使我们不定义为public，也都自动都是public java中一个类只可以有一个父类，但是可以有多个interface，这就使得多态的用法更加的灵活。一个类可以继承多个interface(An x is an a and a b and a c)，当他需要变成哪个interface类型的时候，他就可以成为那个interface类型 Inner class If you want to make an object of inner class anywhere except from whin a non-static method of the outer class, you must specify the type of that object as OuterClassName.InnerClassName Inner class在声明对象时，ourter class的对象必须已经存在，我们不可以用OuterClassName.InnerClassName test = new OuterClassName.InnerClassName()来单独声明Inner class的对象，inner class’寄生于’outer class中，只有outer class有了对象，inner class才能有对象 当我们想要在inner class使用outer class对象的reference的时候，我们可以使用OuterClassName.this来指代 当我们已经有了outer class的对象，想要声明inner class的对象的时候，我们可以用OuterClassName outerClass = new OuterClassName(); OuterClassName.InnerClassName innerClass = outerClass.new InnerClassName();来声明 Inner class and upcasting使用inner class和upcasting，可以起到很好的封装效果，下面的例子对于Cat类，我们想要有一个比较器并且这个比较器只存在于Cat类中并且不能被别人修改，这种情况下我们可以定义一个private inner class 123456789101112131415161718import java.util.Comparator;public class Cat { private int age; public Cat(int age){ this.age = age; } private class CatComparator implements Comparator&lt;Cat&gt; { @Override public int compare(Cat cat1, Cat cat2){ return cat1.age - cat2.age; } } public Comparator getCatComparator() { return new CatComparator(); }} 1234567891011import java.util.Comparator;public class Main { public static void main(String[] args) { Cat cat1 = new Cat(10); Cat cat2 = new Cat(12); Comparator comparator = cat1.getCatComparator(); int res = comparator.compare(cat1, cat2); System.out.println(res); }} 值得注意的是，这里的我定义的inner class CatComparator是private，但是在implement comparator后，它override了一个public的方法，所以出现了在private类里面存在一个public方法：这是合情合理的，类的visibility和方法的visibility没有任何关系，两者是完全独立的。这里我们不想让别人修改我们的CatComparator类的定义，所以定义为private，同时我们也需要使用compare方法去比较猫的年龄，所以compare方法定义为public也是合理的 Anonymous Inner class匿名内部类就是在类中创建匿名的内部类，语法是当我们new一个对象的时候，我们说等等，我想要继承这个对象的类，并且new这个新生成的匿名内部继承类。这样做的好处是这个匿名内部类只被我们使用一次，不会被client engineer误用。所以上面的例子我们可以用匿名内部类简化成下面这样子： 123456789101112131415161718192021222324import java.util.Comparator;public class Cat { private int age; public Cat(int age){ this.age = age; } public Comparator getCatComparator() { return new Comparator&lt;Cat&gt; () { @Override public int compare(Cat cat1, Cat cat2){ return cat1.age - cat2.age; } }; }}````上面我们创建匿名内部类用的是默认的构造器，如果我们想要继承的父类没有默认构造器，只有含参构造器该怎么办呢？我们可以使用下面这个离子的办法：```JAVApublic class Wrapping { private int i; public Wrapping(int x) {i=x;} public int value() {return i;}} 1234567891011public class Test { public Wrapping wrapping(int x) { //Base constructor call: return new Wrapping(x) { @Override public int value(){ return super.value() * 47; } }; }} 如果我们不只是想单单call父类的构造器，我们还想要写子类自己新的构造器，这个时候我们可以使用instance initialization： 123456789101112131415161718192021222324252627public class Wrapping { private int i; public Wrapping(int x) {i=x;} public int value() {return i;}}```````javapublic class Test { public Wrapping wrapping(int x) { //Base constructor call: return new Wrapping(x) { private int cost; { cost = x * 10; } @Override public int value(){ return cost; } }; } public static void main(String[] args){ Test test = new Test(); System.out.println(test.wrapping(10).value()); }} 在java8以前没有effective final概念之前，如果我们要在匿名类里面用到外面的参数，那个参数必须声明为final： https://www.zhihu.com/question/21395848但是在java8以后就不需要了，所以我们上面例子里不用定义成final int x，编译器也不会报错 Nested ClassNested Class是一种特殊的inner class，即我们把inner class声明为static。之前在inner class部分我们提到过，要声明inner class，我们必须先声明它的outer class对象(即inner class是寄生于outer class的)。但是对于Nested Class(Static Inner Class)，就没有这样的要求，我们可以直接声明inner class的对象。A nested class means： 1. You don’t need an outer-class object in order to create an object of a nested class2.You can’t access a non-static outer-class object from an object of a nested class. Classes inside interface正常来说，我们不能在interface里面放一个class(因为interface本来就是用来做抽象的)，但是我们可以把nested class放到interface里去。对于interface来说，它内部的东西默认必须是static final的，而我们的nested class是满足这个条件的。It’s convenient to nest a class inside an interface when you want to create some common doe to be used with all different implmentations of that interface Why inner classes?The most compelling reason for inner classes is :Each inner class can independently inherit from an implementation. Thus, the inner class is not limited by whether the outer class is already inheriting from an implementation.所以inner class给予了我们继承多个class的能力,同时还能方便的使用outer class的fields和methods Holding your objectCollection Arrays.asList生成的List可以改变其中的元素，但不能向里面增加元素，因为本质上它是由Array生成的。如果又想使用这个方法又想增加新的元素，那么需要声明一个新的ListList&lt;Integer&gt; test = new ArrayList&lt;&gt;(Arrays.asList(1, 2, 3, 4, 5)) Collection包括List, Set, Queue, Stack, PriorityQueue Iterator 所有的Collection都有一个iterator() method，生成一个Iterator对象，这个对象有hasNext(), next(), remove()三个方法，我们可以使用这三个方法对Collection进行遍历。1234567Collection&lt;Integer&gt; c = new LinkedList&lt;&gt;();Iterator it = c.iterator();while(it.hasNext()){ Interger i = it.next(); System.out.print(i); it.remove();} Collection有iterator() method是因为所有Collection都实现了Iteratable接口 实现了Iteratable接口的类就可以使用foreach循环了，所以本质上foreach循环的底层是调用Iteratable.iterator()。这也解释了为什么Map不能用foreach，因为Map不是Collection，没有实现Iteratable，我们必须用for(Map.Entry&lt;Integer, integer&gt; entry:map.entrySet()) 拿到entry set以后才可以进行遍历。 Error Handling with ExceptionsBasic exceptions Exception对象的建立和普通java对象的建立完全一样：使用new，并且建立在堆(heap)上。当我们想要在某个地方抛出异常的时候，我们使用throw new Throwable();这样的语法结构。 Throwable\b对象是所有可以抛出的异常的源头父类。Throwable本身除了默认构造器外还有4个构造器，这五个构造器中的两个是所有JDK定义的标准异常都有的构造器：默认构造器和接收String的构造器。比如NullPointerException就只有这两个构造器： 1234NullPointerException()//Constructs a NullPointerException with no detail message.NullPointerException(String s)//Constructs a NullPointerException with the specified detail message. Catch an exception try-catch block123456789try { //Code that might generate exceptions} carch (Type1 id1) { //handle exception of Type 1} carch (Type2 id2) { //handle exception of Type 2} carch (Type3 id3) { //handle exception of Type 3} 当异常发生的时候，程序会去寻找第一个符合抛出异常类型的handler，并进入到那个catch块进行异常处理。这一要说明try-catch和switch有很大区别，switch必须要有个break告诉程序退出执行，否则switch会把每一个选择块都执行一遍。 Creating your own exceptions 如果在程序中的exception我们没有使用try-catch进行处理，或者我们自己在程序中抛出了某些异常，我们有义务告诉client programmer我们抛出了哪些异常，这样方便他们在使用我们的程序的时候去检查这些异常。所以Java引入了异常说明(Exception Specification)，也就是我们需要在方法外说明我们在这个方法里抛出了哪些异常：void f() throws TooBig, TooSmall, DivZero {} Throwable由两个子类继承： Error类和Exception类。Error类是一些程序运行中本身遇到的错误，比如线程死掉了；Exception类是我们需要处理的，它又分为Checked Exception和Unchecked Exception。 Checked Exception是那些我们写代码的时候必须处理的异常，我们必须使用try-catch处理这个异常或者使用异常说明告诉程序继续抛出这个异常，否则编译器会报错。Unchecked Exception是那些在Runtime可能发生的异常，属于我们不用主动处理的异常，Unchecked Exception是那些继承自RuntimeException(包括)的异常。 Catching any exception Throwable类本身有一些很有用的方法： 123456789//Gets the detailed exception messageString getMessage()string getLocalizedMessage()//Returns a short description of Throwable, including the detail message if there is oneString tostring()//Prints the Throwable and the Throwalbe's call stack tracevoid printStackTrace() getMessage()是tostring()的子集；tostring()是printStackTrace()的子集 处理异常一个非常常见的方式就是rethrow： 1234567891011121314151617181920212223242526272829303132public class Main { class RootException extends Exception{} class CausedException extends Exception{ } public static void main(String[] args) { Main main = new Main(); main.h(); } public void h(){ g(); } public void g(){ try { f(); } catch (CausedException e) { e.printStackTrace(); } } public void f() throws CausedException{ try{ throw new RootException(); } catch (RootException e) { CausedException causedException = new CausedException(); throw causedException; } }} 最后打印出来的异常是： 12345Main$CausedException at Main.f(Main.java:30) at Main.g(Main.java:19) at Main.h(Main.java:14) at Main.main(Main.java:10) Exception chaining: 当我们rethrow一个新的一场的时候，我们往往想要保留原异常的信息。比如上个例子中的CauseException是由RootException引起的，但是最后打印出来的异常信息中，我们完全找不到RootException了。这个时候我们就需要使用异常串。异常串的原理就是我们在抛出一个新的异常的同时，告诉它造成这个新异常的cause，这样程序就会知道是谁造成的这个新的异常。Throwable本身是有一个接受cause参数的构造器的Throwable(Throwable cause)。但是这个构造器只被Error，Exception和RuntimeException继承了，比如NullPointerException就没有这个构造器，那么如果我们想要NullPointerException知道它的cause，我们就需要使用initCause()这个方法。如果是我们自己定义的异常，我们可以选择重写Exception的带cause参数的构造器，那么样我们就可以直接使用了。 12345678910111213141516171819202122232425262728293031323334353637public class Main { class RootException extends Exception{} class CausedException extends Exception{ public CausedException() { } public CausedException(Throwable e) { super(e); } } public static void main(String[] args) { Main main = new Main(); main.h(); } public void h(){ g(); } public void g(){ try { f(); } catch (CausedException e) { e.printStackTrace(); } } public void f() throws CausedException{ try{ throw new RootException(); } catch (RootException e) { CausedException causedException = new CausedException(e); throw causedException; } }} 打印出来的结果是： 12345678Main$CausedException: Main$RootException at Main.f(Main.java:35) at Main.g(Main.java:24) at Main.h(Main.java:19) at Main.main(Main.java:15)Caused by: Main$RootException at Main.f(Main.java:33) ... 3 more Performing cleanup with finally finally块里的语句总是会执行，即使try块里有break，continue或者return finally总是执行的机制会导致一个坏处：lost exception。比如下面这个例子： 12345try { throw new ImportantException();} finally { throw new NotImportantException();} 或者 12345try { throw new ImportantException();} finally { return;} 上面两个例子都是导致我们丢失ImportantException Exception restrictions 当子类重写父类的方法时，子类重写的方法只能抛出父类方法已有的异常或已有异常的子异常。 这个是很好理解的，如果子类方法抛出了父类方法所没有的异常，那么如果我们使用多态(upcast)的时候，编译器认为父类方法没有抛出新增加的异常，但其实在runtime，子类抛出了该异常，这样程序就无法处理了。所以Java严格要求子类重写的方法只能抛出父类方法已有的异常或已有异常的子异常。 总结上面一条就是： 异常的继承只能变得更窄，而不能变得更宽。这正好和类的继承相反，类的继承只能变得更宽，因为父类的变量和方法子类默认已经继承，我们只能重写父类已有的方法或者增加新的方法。 所以子类重写的方法是可以不抛出异常的，即使父类抛出了某些异常(变窄了) 子类中新定义(非重写)的方法没有以上限制 构造器不用遵循上述的限制，即可以随便抛出不同于父类构造器的异常，但是子类所使用的父类构造器的异常一定要继承(这里强调所使用的父类构造器的原因是子类可以不调用默认构造器，但是无论如何子类必须调用一个父类的构造器，否则编译器会报错)。构造器不用遵循上述规则的原因也很简单，构造器不像方法有多态，构造器总是出现在等号的右边。 Exception matching Catch异常的时候不一定是完美符合，即子异常也会被父异常的catch语句抓到。所以我们总是在try-catchd的最后补上catch(Exception e)，而不能在最开始写。 StringsImmutable Strings String object都是不可更改的(immutable)，所有对于String的操作都是生成一个新的String，而非更改旧的 Overloading ‘+’ vs. StringBuilder Java编译器在处理String的加操作时，底层其实也是在使用StringBuilder的。但是在遇到循环的时候，编译器会生成多个StringBuilder在每一次循环的时候。 所以对于String和StringBuilder的使用：简单的加操作直接用String，涉及到循环的时候一定要用StringBuilder StringBuilder是java1.5引入的，之前使用的是StringBuffer，原理与StringBuilder基本相同，但是StringBuffer是线程安全的，而stringBuilder是线程不安全的，所以这就导致StringBuffer比StringBuilder效率要低 Formatting output Java中的format相关实现都是由java.util.formatter来完成的。常用的String.format()的内部实现也使用的formatter Formatter的使用见： https://docs.oracle.com/javase/7/docs/api/java/util/Formatter.html Regular expressions 在其他语言中，\\\\ 表示：我想要在正则表达式中插入一个普通的（字面上的）反斜杠，请不要给它任何特殊的意义。在 Java 中，\\\\ 表示：我要插入一个正则表达式的反斜线，所以其后的字符具有特殊的意义。所以，在其他的语言中（如 Perl），一个反斜杠 \\ 就足以具有转义的作用，而在 Java 中正则表达式中则需要有两个反斜杠才能被解析为其他语言中的转义作用。也可以简单的理解在 Java 的正则表达式中，两个 \\\\ 代表其他语言中的一个 \\，这也就是为什么表示一位数字的正则表达式是 \\\\d，而表示一个普通的反斜杠是 \\\\。 其他关于正则表达式的表达可以参考： https://www.liaoxuefeng.com/wiki/1016959663602400/1017639890281664 Java中关于正则表达式的内部实现都是由Pattern类和Matcher类完成的，这里有时间可以好好看一下 Type InformationRun time information(RTTI)分为两部分。传统的RTTI假定我们在编译时已经知道了所有的类型信息；另一种反射机制允许我们在运行时发现和使用类型信息。 The Class object 平时我们生成Java对象的时候都是直接用new，但new的背后其实隐藏了一些步骤。当我们写好一个新的类并进行编译时，JVM都会为这个新的类创建一个对应的Class对象，并将其存在.class的字节码中，这个Class对象会用来生成这个类的对象。 JVM一开始运行的时候，并不是所有的类都被直接装载进来，而是动态的逐渐的装载进来。JVM使用Java Class Loader来进行类的装载：每当程序第一次使用某个类的静态成员static member(包括静态常量，静态变量和静态方法)的时候，JVM就会将这个类加载进来(类的构造器默认是静态的，这也是为什么我们使用new就会装载这个类的原因) 当我们想要使用某个类的静态成员的时候，Java Class Loader会先检查这个类是否已经被加载了，如果没有的话就去寻找这个类的.class字节码并进行加载，这样这个类的Class对象也就同时被加载到了内存中，后面我们就可以使用这个Class对象来创建这个类的对象 如果我们想要得到Class对象的引用，我们可以使用Class test = Class.forName(FULL_QUALIFIED_NAME)。FULL_QUALIFIED_NAME的意思是要包括包名。这个时候有个疑问：有没有可能想要得到的Class对象还没有被加载进JVM呢？这个问题很好，答案是这个方法的一个“副作用”就是如果这个类还没有被加载，那么加载它。另一个方法去得到Class对象的引用是如果你已经有一个类的对象，可以使用getClass()方法。 之前说过Class对象是用来生成这个类的对象，这也就说明了Class对象存储了这个类几乎所有的信息。其中有一些常用的方法：getName()：返回类的全名(包括包名)getSimpleName()：返回类名getInterfaces()：返回一个数组，里面包括这个类的所有接口的Class对象的引用getSuperClass()：返回这个类的父类的Class对象的引用newInstance()：使用默认构造器创建这个类的一个对象。后面在反射部分会介绍怎么使用别的构造器创建对象 Class literals 第三种得到Class对象引用的方式是：Test.class。这种方式不仅效率更高，而且避免了forName()方法可能抛出的异常。 基本类也都有Class literals。比如int.class就和Integer.TYPE完全一样。 前面我们提到把字节码加载到JVM中，但这其实只是准备使用一个类的的第一步： 加载 加载是由Java Class Loader完成的，它的作用是把.class字节码加载到JVM中(Class对象也就被创建了，因为Class对象存在.class字节码中) 链接 链接会验证字节码；为静态域static field(静态变量+静态常量)分配存储空间；如果有必要的话，解析这个类创建的对其他类的引用 初始化 初始化父类；执行静态变量的初始化和静态代码块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.*;class Initable {static final int staticFinal = 47;static final int staticFinal2 = ClassInitialization.rand.nextInt(1000);static { System.out.println(&quot;Initializing Initable&quot;);}}class Initable2 {static int staticNonFinal = 147;static { System.out.println(&quot;Initializing Initable2&quot;);}}class Initable3 {static int staticNonFinal = 74;static { System.out.println(&quot;Initializing Initable3&quot;);}}public class ClassInitialization {public static Random rand = new Random(47);public static void main(String[] args) throws Exception { Class initable = Initable.class; System.out.println(&quot;After creating Initable ref&quot;); // Does not trigger initialization: System.out.println(Initable.staticFinal); // Does trigger initialization: System.out.println(Initable.staticFinal2); // Does trigger initialization: System.out.println(Initable2.staticNonFinal); Class initable3 = Class.forName(&quot;Initable3&quot;); System.out.println(&quot;After creating Initable3 ref&quot;); System.out.println(Initable3.staticNonFinal);}} /* Output:After creating Initable ref47Initializing Initable258Initializing Initable2147Initializing Initable3After creating Initable3 ref74*///:~ 由于类的初始化阶段会执行静态块，所以我们可以通过判断静态块是否执行来判断类是否初始化了。从这个例子中可以看出来： .class只触发了类的加载，并不会触发类的初始化，但是Class.forName()会触发类的加载 类似Initable.staticFinal这样的final静态常量，并不会触发初始化。这很合理，因为这种静态变量在编译阶段就已经写死了，并不需要进行初始化 类似Initable.staticFinal2这样的final静态变量，会触发初始化 如果一个静态域field不是final的，那么获取他总是需要链接和初始化的步骤的 Generic class references 我们可以使用泛型来使Class类对象更具体，这样的话编译器就会在编译阶段检查Class类对象所代表的类。123456789public class GenericClassReferences { public static void main(String[] args) { Class intClass = int.class; Class&lt;Integer&gt; genericIntClass = int.class; genericIntClass = Integer.class; // Same thing intClass = double.class; // genericIntClass = double.class; // Illegal }} ///:~ 那么如果我们要放松泛型的限制该怎么做呢，可能有人会想到Class&lt;Number&gt; genericNumberClass = int.class;，但是这样是不对的，因为虽然Number类是Integer类的父类，但是Number Class不是Integer Class的父类。这个后面在泛型会深入讲解 真正可以放松限制的是使用泛型通配符?，它代表着任何类型。我们使用的时候应该使用Class&lt;?&gt;而不是Class123456public class WildcardClassReferences { public static void main(String[] args) { Class&lt;?&gt; intClass = int.class; intClass = double.class; }} ///:~ 使用泛型的一个好处就是由于Class类对象的类型是确定的，当我们使用newInstance()的时候，返回的不会只是一个Object的对象，而是一个确定的类12345678910111213public class GenericNewInstance { public static void main(String[] args) { Class&lt;Test&gt; testClass = Test.class; try { Test test = testClass.newInstance(); System.out.println(test); } catch (Exception e) { e.printStackTrace(); } }} ///:~class Test {} Checking before a cast x instanceof Y可以用来进行类型检查，在进行类型转换的时候很有用，否则类型转换可能抛出ClassCastException Rgistered factories 注册工厂是一种设计模式，需要进行一下学习 instanceof vs. Class equicalence x instanceof Y的意思是判断x对象是不是Y类型的实例，所以x既可以是Y类型的对象，也可以Y类型子类的对象。所以derivedClassObject instanceof BaseClass返回true 当我们比较Class类对象的时候，子类与父类的Class对象是不同的，所以DrivedClass.class != BaseClass.class Reflection: runtime class information 反射是指我们在编译阶段不知道类的具体信息，相关信息只有在runtime才会被得到，这个时候我们使用反射。反射与普通的RTTI没什么区别，只是一个是在编译阶段知道Class类对象的信息(.class字节码编译阶段就已存在)，另一个是在runtime阶段才能够知道 java.lang.reflect包提供了Field，Method和Constructor类。我们可以使用Custructor类去创建新的对象；使用get()和set()去读或者改变一个Field对象；使用invoke()去call一个Method对象 Dynamic proxies 动态代理是反射一个很好的应用例子： https://www.zhihu.com/question/20794107 Genericshttps://www.cnblogs.com/wuqinglong/p/9456193.htmlhttps://segmentfault.com/a/1190000020497160 Simple Generics(Generic Types)https://docs.oracle.com/javase/tutorial/java/generics/types.html Raw TypeA raw type is the name of a generic class or interface without any type arguments. For example, given the generic Box class: 1234public class Box&lt;T&gt; { public void set(T t) { /* ... */ } // ...} To create a parameterized type of Box, you supply an actual type argument for the formal type parameter T:Box&lt;Integer&gt; intBox = new Box&lt;&gt;(); If the actual type argument is omitted, you create a raw type of Box:Box rawBox = new Box();Therefore, Box is the raw type of the generic type Box. However, a non-generic class or interface type is not a raw type. Raw types show up in legacy code because lots of API classes (such as the Collections classes) were not generic prior to JDK 5.0. When using raw types, you essentially get pre-generics behavior — a Box gives you Objects. For backward compatibility, assigning a parameterized type to its raw type is allowed: 1234567891011Box&lt;String&gt; stringBox = new Box&lt;&gt;();Box rawBox = stringBox; // OKBut if you assign a raw type to a parameterized type, you get a warning:Box rawBox = new Box(); // rawBox is a raw type of Box&lt;T&gt;Box&lt;Integer&gt; intBox = rawBox; // warning: unchecked conversionYou also get a warning if you use a raw type to invoke generic methods defined in the corresponding generic type:Box&lt;String&gt; stringBox = new Box&lt;&gt;();Box rawBox = stringBox;rawBox.set(8); // warning: unchecked invocation to set(T) The warning shows that raw types bypass generic type checks, deferring the catch of unsafe code to runtime. Therefore, you should avoid using raw types. The Type Erasure section has more information on how the Java compiler uses raw types. Raw Type的引用可以hold泛型对象，并且不会警告，这是为了兼容性；泛型的引用反之也可以hold Raw Type对象，但会报警告 由于有Raw Type的存在，泛型间的引用传递很危险，比如： 12List list = new ArrayList&lt;String&gt;();//no warningList&lt;Integer&gt; = list;//warning, but very bad result! 上面的例子只会报一个警告，但是是很危险的，因为我们把一个存有String的List对象被赋值给了一个List的引用 Unchecked Error MessagesAs mentioned previously, when mixing legacy code with generic code, you may encounter warning messages similar to the following: Note: Example.java uses unchecked or unsafe operations.Note: Recompile with -Xlint:unchecked for details.This can happen when using an older API that operates on raw types, as shown in the following example: 12345678910public class WarningDemo { public static void main(String[] args){ Box&lt;Integer&gt; bi; bi = createBox(); } static Box createBox(){ return new Box(); }} The term “unchecked” means that the compiler does not have enough type information to perform all type checks necessary to ensure type safety. The “unchecked” warning is disabled, by default, though the compiler gives a hint. To see all “unchecked” warnings, recompile with -Xlint:unchecked. Recompiling the previous example with -Xlint:unchecked reveals the following additional information: WarningDemo.java:4: warning: [unchecked] unchecked conversionfound : Boxrequired: Box&lt;java.lang.Integer&gt; bi = createBox(); ^1 warningTo completely disable unchecked warnings, use the -Xlint:-unchecked flag. The @SuppressWarnings(“unchecked”) annotation suppresses unchecked warnings. If you are unfamiliar with the @SuppressWarnings syntax, see Annotations. Generic methods前面我们已经展示了在类(或者接口，接口与类是类似的)上使用泛型的例子，我们也可以直接在方法上使用泛型，语法是：在返回值之前加上一个泛型参数列表(用&lt;和&gt;括起来) 123456public class Util { public static &lt;K, V&gt; boolean compare(Pair&lt;K, V&gt; p1, Pair&lt;K, V&gt; p2) { return p1.getKey().equals(p2.getKey()) &amp;&amp; p1.getValue().equals(p2.getValue()); }} Type Inference当我们使用声明好的泛型方法的时候，我们并不需要像泛型类那样显式的声明我们所要使用的类，而是可以借助Java自带的类型推断来知道我们需要使用的类。类型推断可以根据我们传入泛型方法的参数的并集来判断我们使用的类 123456class Test { static &lt;T&gt; T pick(T a1, T a2) { return a2; } public static void main(String[] args){ Serializable serializable = pick(&quot;test&quot;, new ArrayList&lt;String&gt;()); }} 这个例子中，我们两个泛型参数T分别被一个String和一个ArrayList表示，那么最终Java系统判断结果是String和ArrayList的并集也就是Serializable Explicit type specification 虽然Java系统可以自动帮我们判断泛型参数最后会使用什么类，我们也可以显式的声明它，语法是在使用函数的.的后面加上想使用的类型：`Serializable s = Test.pick(“d”, new ArrayList()); Generics, Inheritance, and Subtypeshttps://docs.oracle.com/javase/tutorial/java/generics/inheritance.htmla-&gt;b的意思是a是b的子类Integer-&gt;Number，但是List&lt;Number&gt;不是List&lt;Integer&gt;的父类，两者没有任何关系！List&lt;Number&gt;List&lt;Integer&gt; -&gt; ObjectArrayList&lt;Integer&gt; -&gt; List&lt;Integer&gt; -&gt; Collection&lt;Integer&gt; The mystery of erasure Java的泛型并不是在最开始就有的，而是在Java1.5才被加入的，所以Java泛型是由擦除实现的，也就是说关于泛型的信息在runtime是看不到的，所以List&lt;String&gt;和List&lt;Integer&gt;本质上在runtime是一种类型： 1234567891011import java.util.*;public class ErasedTypeEquivalence { public static void main(String[] args) { Class c1 = new ArrayList&lt;String&gt;().getClass(); Class c2 = new ArrayList&lt;Integer&gt;().getClass(); System.out.println(c1 == c2); }} /* Output:true*///:~ 擦除的作用效果是擦除到一个泛型的边界，如果一个泛型没有定义边界，那么它就会被擦除成Object类；如果一个泛型定义了边界&lt;T extends Integer&gt;，那么就会擦除到它的边界也就是这里的Integer。 123public class HasF {public void f() { System.out.println(&quot;HasF.f()&quot;); }} ///:~ 1234567class Manipulator&lt;T&gt; {private T obj;public Manipulator(T x) { obj = x; }// Error: cannot find symbol: method f():public void manipulate() { obj.f(); }} 这里由于T没有定义边界，被擦除成了Object，那么它不认为自己有f()方法 12345class Manipulator2&lt;T extends HasF&gt; {private T obj;public Manipulator2(T x) { obj = x; }public void manipulate() { obj.f(); }} ///:~ 这里由于T定义了边界，被擦除成了HasF，那么它知道自己有f()方法 先检查，再编译Q: 既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？ A: Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。 例如： 123456public static void main(String[] args) { ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;123&quot;); list.add(123);//编译错误 } 在上面的程序中，使用add方法添加一个整型，在IDE中，直接会报错，说明这就是在编译之前的检查，因为如果是在编译之后检查，类型擦除后，原始类型为Object，是应该允许任意引用类型添加的。可实际上却不是这样的，这恰恰说明了关于泛型变量的使用，是会在编译之前检查的。 那么，这个类型检查是针对谁的呢？我们先看看参数化类型和原始类型的兼容。以 ArrayList举例子，以前的写法:ArrayList list = new ArrayList(); 现在的写法:ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();如果是与以前的代码兼容，各种引用传值之间，必然会出现如下的情况：ArrayList list1 = new ArrayList(); //第一种 情况, 这样是没有错误的，不过会有个编译时警告。ArrayList list2 = new ArrayList(); //第二种 情况不过在第一种情况，可以实现与完全使用泛型参数一样的效果，第二种则没有效果。 因为类型检查就是编译时完成的，new ArrayList()只是在内存中开辟了一个存储空间，可以存储任何类型对象，而真正设计类型检查的是它的引用，因为我们是使用它引用list1来调用它的方法，比如说调用add方法，所以list1引用能完成泛型类型的检查。而引用list2没有使用泛型，所以不行。 举例子： 1234567891011121314151617181920public class Test { public static void main(String[] args) { ArrayList&lt;String&gt; list1 = new ArrayList(); list1.add(&quot;1&quot;); //编译通过 list1.add(1); //编译错误 String str1 = list1.get(0); //返回类型就是String ArrayList list2 = new ArrayList&lt;String&gt;(); list2.add(&quot;1&quot;); //编译通过 list2.add(1); //编译通过 Object object = list2.get(0); //返回类型就是Object new ArrayList&lt;String&gt;().add(&quot;11&quot;); //编译通过 new ArrayList&lt;String&gt;().add(22); //编译错误 String str2 = new ArrayList&lt;String&gt;().get(0); //返回类型就是String } } 通过上面的例子，我们可以明白，类型检查就是针对引用的，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。 自动类型转换因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。 既然都被替换为原始类型，那么为什么我们在获取的时候，不需要进行强制类型转换呢？ 看下ArrayList.get()方法： 12345public E get(int index) { RangeCheck(index); return (E) elementData[index]; } 可以看到，在return之前，会根据泛型变量进行强转。假设泛型类型变量为Date，虽然泛型信息会被擦除掉，但是会将(E) elementData[index]，编译为(Date)elementData[index]。所以我们不用自己进行强转。当存取一个泛型域时也会自动插入强制类型转换。假设Pair类的value域是public的，那么表达式：Date date = pair.value;也会自动地在结果字节码中插入强制类型转换 从以上两个小节我们得出结论：Java泛型的擦除使得代码在runtime是没有泛型信息的，泛型只作用于编译期间。编译期间，程序根据泛型信息检查输入是否符合标准，不符合会报出错误；同时根据泛型信息将输出自动进行类型转换 Compensating for erasure 由于擦除存在的原因，任何与runtime类型的操作泛型都不可以使用123456789public class Erased&lt;T&gt; { private final int SIZE = 100; public static void f(Object arg) { if(arg instanceof T) {} // Error T var = new T(); // Error T[] array = new T[SIZE]; // Error T[] array = (T)new Object[SIZE]; // Unchecked warning }} ///:~ Creating instances of types 既然我们不能进行new T()的操作，解决的办法之一是使用反射： 1234567891011121314151617181920212223242526272829303132import static net.mindview.util.Print.*;class ClassAsFactory&lt;T&gt; {T x;public ClassAsFactory(Class&lt;T&gt; kind) { try { x = kind.newInstance(); } catch(Exception e) { throw new RuntimeException(e); }}}class Employee {} public class InstantiateGenericType {public static void main(String[] args) { ClassAsFactory&lt;Employee&gt; fe = new ClassAsFactory&lt;Employee&gt;(Employee.class); print(&quot;ClassAsFactory&lt;Employee&gt; succeeded&quot;); try { ClassAsFactory&lt;Integer&gt; fi = new ClassAsFactory&lt;Integer&gt;(Integer.class); } catch(Exception e) { print(&quot;ClassAsFactory&lt;Integer&gt; failed&quot;); }}} /* Output:ClassAsFactory&lt;Employee&gt; succeededClassAsFactory&lt;Integer&gt; failed*///:~ 从上面的例子可以看出来，确实是可以使用反射来创建泛型类的实例，但是Integer的实例创建失败了，原因是Integer类没有默认的构造器 还可以使用工厂设计模式(Factory Pattern)或者模板设计模式(Template Method) WildcardsUpper Bounded Wildcards List&lt;? extends Number&gt;的意思是List可以包含任何Number或者Number的子类，所以以下几种表达都是合理的 List&lt;? extends Number&gt; list= new LinkedList&lt;Number&gt; List&lt;? extends Number&gt; list= new LinkedList&lt;Integer&gt; List&lt;? extends Number&gt; list= new LinkedList&lt;Double&gt; 所以这就导致了List&lt;? extends Number&gt;是不可写的(不能使用add)，因为如果写了一个Integer，但实际存储的是new LinkedList&lt;Double&gt;，就会出现错误 但是List&lt;? extends Number&gt;是可读的(可以使用get)，因为我们知道读出来的一定是Number或者Number的子类 Lower Bounded Wildcards List&lt;? super Integer&gt;的意思是List可以包含任何Integer或者Integer的父类，所以以下几种表达都是合理的 List&lt;? super Integer&gt; list= new LinkedList&lt;Integer&gt; List&lt;? super Integer&gt; list= new LinkedList&lt;Number&gt; List&lt;? super Integer&gt; list= new LinkedList&lt;Object&gt; 所以这就导致了List&lt;? super Integer&gt;只能读出Object类型 List&lt;? super Integer&gt;是可写的，但是只可以写Integer或者Integer的子类 所以总结来说，判断能否写是根据所有的可能性取一个交集，如果交集不存在就不能写；判断能否读是根据所有的可能性取一个并集，最差也能是Object，以为Object是所有类的父类 Unbounded Wildcards 根据上面的总结，List&lt;?&gt;不可写，只能读出Object There are two scenarios where an unbounded wildcard is a useful approach:If you are writing a method that can be implemented using functionality provided in the Object class. 对应第一条When the code is using methods in the generic class that don’t depend on the type parameter. For example, List.size or List.clear. In fact, Class&lt;?&gt; is so often used because most of the methods in Class do not depend on T. 因为第一条的限制，所以只能做与泛型读写无关的操作 Wildcards and Subtypinghttps://docs.oracle.com/javase/tutorial/java/generics/subtyping.htmlList&lt;Integer&gt; -&gt; List&lt;?&gt;List&lt;String&gt; -&gt; List&lt;?&gt;，但是List&lt;Integer&gt;和List&lt;String&gt;之间没有继承关系List&lt;Integer&gt; -&gt; List&lt;? extends Integer&gt; -&gt; List&lt;? extends Number&gt; -&gt; List&lt;?&gt;List&lt;Number&gt; -&gt; List&lt;? super Number&gt; -&gt; List&lt;? super Integer&gt; -&gt; List&lt;?&gt; 如何判断泛型之间的继承关系？通过比较泛型所能代表的类，如果一个泛型所能代表的类是另一个所能代表的类的子集，那他就是另一个类的子类比如? extends Integer可以代表的类有Integer以及所有继承Integer的类；? extends Number可以代表的类有Number以及所有继承Number的类，明显后面是前面的父集同理，? super Intege所能代表的类是? super Number的父集，所以List&lt;? super Integer&gt;是List&lt;? super Number&gt;的父类 12345List&lt;?&gt; list1 = new LinkedList&lt;String&gt;();List&lt;? extends String&gt; list2 = list1;//会报错，因为 ? extends String 不是 ？的父类，? extends String只能代表String及其子类，但 ？ 能代表所有类List&lt;? super String&gt; list3 = list1;//会报错，因为 ? super String 不是 ？的父类List&lt;? extends Object&gt; list4 = list1;//不会报错，因为 ? extends Object 其实就是所有类的意思，与 ? 是一样的List&lt;? super Object&gt; list5 = list1;//会报错，因为 ? super Object 不是 ？的父类 Java泛型通配符 ? 与 T 的区别https://segmentfault.com/a/1190000020497160这里解释的最好的一句就是?是一个实参，而T只是一个形参(占位符)，也就是说T只能存在于泛型的编写过程中，最终在使用的时候都会被一个实参替换掉，这个实参甚至有可能是？ 1234567891011121314import java.util.*;public class Test { public static &lt;T&gt; T test(List&lt;T&gt; input){ return input.get(0); } public static void main(String[] args){ List&lt;String&gt; list1 = new LinkedList&lt;&gt;(); list1.add(&quot;test&quot;); List&lt;?&gt; list2 = list1;//list2不能写只能读，所以这里先用list1写入一个数据 Object a = test(list2);//由于实参是？，根据type inference，任何类型的并集只能是object，所以我们返回的引用只能是Object， System.out.println(a); }} 也可以使用? extends String作为实参 1234567891011121314import java.util.*;public class Test { public static &lt;T&gt; T test(List&lt;T&gt; input){ return input.get(0); } public static void main(String[] args){ List&lt;String&gt; list1 = new LinkedList&lt;&gt;(); list1.add(&quot;test&quot;); List&lt;? extends String&gt; list2 = list1;//list2不能写只能读，所以这里先用list1写入一个数据 String a = test(list2);//由于实参是? extends String，我们知道其必是String或者String的子类，根据type inference，我们返回的引用就可以是String了 System.out.println(a); }} Self-bounded types泛型类的自限定 自限定的意思是一个类的对象只能与另一个这个类的对象进行作用。 泛型类的自限定是非常常见的，比如Integer类的声明public final class Integer implements Comparable&lt;Integer&gt;。它的含义是：Integer类实现了一个’使用Integer类的Comparable接口’。这样的好处是什么呢？Integer对象在使用Comparable的compareTo方法的时候只能和另一个Integer对象作用，也就不可能出现5.compareTo(&quot;6&quot;)的情况出现。这就是自限定的作用：强制Integer在使用compareTo的方法时使用另一个Integer 泛型声明的完全自限定 在上面Comparable的例子中，Comparable类本身的定义是没有任何限制的，就是public interface Comparable&lt;T&gt;，我们使用Comparable&lt;Integer&gt;的原因就是为了达到自限定，限定compareTo方法只能使用Integer。但是如果我们假设编写Java的人不小心把Integer类定义为public final class Integer implements Comparable&lt;String&gt;，那么这个时候我们compareTo方法只能使用String了，compareTo方法变得毫无意义，当然这个时候compareTo方法也就不叫自限定了。那么能不能把限制进一步，使得我们只要使用Comparable，就必须做到自限定，而不会出现public final class Integer implements Comparable&lt;String&gt;这种错误了呢？ 如果我们把Comparable定义成下面的形式，就做到了凡是实现Comparable的类，必须是自限定的，上面public final class Integer implements Comparable&lt;String&gt;的情况就会报错了。 1class Comparable&lt;T extends Comparable&lt;T&gt;&gt; 那么问题来了：为什么Java编写人员不把Comparable定义成上面这样的完全自限定呢？原因很简单，为了给予开发人员更多的灵活性。 那么有没有哪个Java类使用了上面这种完全自限定的定义呢？Enum就是一个很好的例子public abstract class Enum&lt;E extends Enum&lt;E&gt;&gt; implements Comparable&lt;E&gt;, Serializable { }。对于所有我们定义的Enum类，我们肯定都希望只能与相同的Enum类进行作用，肯定不希望月与年可以进行比较。 I/OThe File class File类的名字虽然是File，但其实传入的参数是文件路径。所以它可以表示一个真正的文件，也可能只是表示一个目录 File对象既可以表示文件，也可以表示目录。特别要注意的是，构造一个File对象，即使传入的文件或目录不存在，代码也不会出错，因为构造一个File对象，并不会导致任何磁盘操作。只有当我们调用File对象的某些方法的时候，才真正进行磁盘操作。例如，调用isFile()，判断该File对象是否是一个已存在的文件，调用isDirectory()，判断该File对象是否是一个已存在的目录： 如果我们确认一个File对象时目录，那么我们可以使用list()方法来列出这个目录下所有的File对象；也可以使用list(FileNameFilter)来筛选想要返回的File对象。FileNameFilter是一个接口，所以我们很自然的可以想到用匿名类来构造实现。 123456789101112131415161718192021222324252627282930//: io/DirList3.java// Building the anonymous inner class &quot;in-place.&quot;// {Args: &quot;D.*\\.java&quot;}import java.util.regex.*;import java.io.*;import java.util.*;public class DirList3 {public static void main(final String[] args) { File path = new File(&quot;.&quot;); String[] list; if(args.length == 0) list = path.list(); else list = path.list(new FilenameFilter() { private Pattern pattern = Pattern.compile(args[0]); public boolean accept(File dir, String name) { return pattern.matcher(name).matches(); } }); Arrays.sort(list, String.CASE_INSENSITIVE_ORDER); for(String dirItem : list) System.out.println(dirItem);}} /* Output:DirectoryDemo.javaDirList.javaDirList2.javaDirList3.java*///:~ 注意到这里我们使用了内部类外面的变量args，所以需要把它定义成final。 File类不止可以判断是否是文件还是目录，我们还可以使用它创建或者删除文件，查看文件的属性等。 InputStream/OutputStreamInputStream InputStream就是Java标准库提供的最基本的输入流。它位于java.io这个包里。java.io包提供了所有同步IO的功能。 要特别注意的一点是，InputStream并不是一个接口，而是一个抽象类，它是所有输入流的超类。这个抽象类定义的一个最重要的方法就是int read()，签名如下：public abstract int read() throws IOException;。这个方法会读取输入流的下一个字节，并返回字节表示的int值（0~255）。如果已读到末尾，返回-1表示不能继续读取了。 FileInputStream是InputStream的一个子类。顾名思义，FileInputStream就是从文件流中读取数据。下面的代码演示了如何完整地读取一个FileInputStream的所有字节： 123456789101112public void readFile() throws IOException { // 创建一个FileInputStream对象: InputStream input = new FileInputStream(&quot;src/readme.txt&quot;); for (;;) { int n = input.read(); // 反复调用read()方法，直到返回-1 if (n == -1) { break; } System.out.println(n); // 打印byte的值 } input.close(); // 关闭流} 在读取流的时候，一次读取一个字节并不是最高效的方法。很多流支持一次性读取多个字节到缓冲区，对于文件和网络流来说，利用缓冲区一次性读取多个字节效率往往要高很多。InputStream提供了两个重载方法来支持读取多个字节： int read(byte[] b)：读取若干字节并填充到byte[]数组，返回读取的字节数 int read(byte[] b, int off, int len)：指定byte[]数组的偏移量和最大填充数 利用上述方法一次读取多个字节时，需要先定义一个byte[]数组作为缓冲区，read()方法会尽可能多地读取字节到缓冲区， 但不会超过缓冲区的大小。read()方法的返回值不再是字节的int值，而是返回实际读取了多少个字节。如果返回-1，表示没有更多的数据了。 利用缓冲区一次读取多个字节的代码如下： 12345678910public void readFile() throws IOException { try (InputStream input = new FileInputStream(&quot;src/readme.txt&quot;)) { // 定义1000个字节大小的缓冲区: byte[] buffer = new byte[1000]; int n; while ((n = input.read(buffer)) != -1) { // 读取到缓冲区 System.out.println(&quot;read &quot; + n + &quot; bytes.&quot;); } }} FilterInputStream Java的IO标准库提供的InputStream根据来源可以包括： FileInputStream：从文件读取数据，是最终数据源； ServletInputStream：从HTTP请求读取数据，是最终数据源； Socket.getInputStream()：从TCP连接读取数据，是最终数据源； 等等 如果我们要给FileInputStream添加缓冲功能，则可以从FileInputStream派生一个类： BufferedFileInputStream extends FileInputStream 如果要给FileInputStream添加计算签名的功能，类似的，也可以从FileInputStream派生一个类： DigestFileInputStream extends FileInputStream 如果要给FileInputStream添加加密/解密功能，还是可以从FileInputStream派生一个类： CipherFileInputStream extends FileInputStream 如果要给FileInputStream添加缓冲和签名的功能，那么我们还需要派生BufferedDigestFileInputStream。如果要给FileInputStream添加缓冲和加解密的功能，则需要派生BufferedCipherFileInputStream。 我们发现，给FileInputStream添加3种功能，至少需要3个子类。这3种功能的组合，又需要更多的子类。 为了解决这种问题，Java采用装饰器(decorator)模式设计输入输出流。比如输入流可以分为两大类： 一类是直接提供数据的基础InputStream，例如： FileInputStream ByteArrayInputStream ServletInputStream 等等 一类是提供额外附加功能的InputStream，他们都继承自抽象类FilterInputStream。例如： BufferedInputStream DigestInputStream CipherInputStream 等等 当我们想要真正使用输入流的时候，需要先定义直接提供数据的基础的InputStream，再在外面套上各种FilterInputStream，但无论如何，最终得出的都是一个InputStream，他都有int read()方法: 123InputStream file = new FileInputStream(&quot;test.gz&quot;);InputStream buffered = new BufferedInputStream(file);InputStream gzip = new GZIPInputStream(buffered); 我们可以边写自己需要的FilterInputStream： 12345678910111213141516171819202122232425262728293031323334353637383940public class Main { public static void main(String[] args) throws IOException { byte[] data = &quot;hello, world!&quot;.getBytes(&quot;UTF-8&quot;); try (CountInputStream input = new CountInputStream(new ByteArrayInputStream(data))) { int n; while ((n = input.read()) != -1) { System.out.println((char)n); } System.out.println(&quot;Total read &quot; + input.getBytesRead() + &quot; bytes&quot;); } }}class CountInputStream extends FilterInputStream { private int count = 0; CountInputStream(InputStream in) { super(in); } public int getBytesRead() { return this.count; } public int read() throws IOException { int n = in.read(); if (n != -1) { this.count ++; } return n; } public int read(byte[] b, int off, int len) throws IOException { int n = in.read(b, off, len); if (n != -1) { this.count += n; } return n; }} Reader/Writer 上一节我们提到的InputStream和OutputStream，读入和写出的都是字节流，如果我们读取或者写入的是文本文件，那么我们还需要在进行编解码。为了解决这一痛点，Java引入了新的Reader和Writer类。本质上Reader/Writer与InputStream/OutputStream没有区别，只是Reader/Writer会根据操作系统默认的编解码配置进行编解码，所以操作的是字符流. Java内部将char存成BMP unicode，但是由于char只有两个字节，所以对于两个字节以外的NON-BMP unicode，是无法用char表示的。如果我们不想要使用系统自带的编解码，比如有的时候中文使用默认编解码就会乱码，可以如下定义：Reader reader = new FileReader(&quot;src/readme.txt&quot;, StandardCharsets.UTF_8);。关于Unicode和UTF-8(http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html) Reader和InputStream有什么关系？ 除了特殊的CharArrayReader和StringReader，普通的Reader实际上是基于InputStream构造的，因为Reader需要从InputStream中读入字节流（byte），然后，根据编码设置，再转换为char就可以实现字符流。如果我们查看FileReader的源码，它在内部实际上持有一个FileInputStream。 既然Reader本质上是一个基于InputStream的byte到char的转换器，那么，如果我们已经有一个InputStream，想把它转换为Reader，是完全可行的。InputStreamReader就是这样一个转换器，它可以把任何InputStream转换为Reader。示例代码如下： 1234// 持有InputStream:InputStream input = new FileInputStream(&quot;src/readme.txt&quot;);// 变换为Reader:Reader reader = new InputStreamReader(input, &quot;UTF-8&quot;); Standard I/O PrintStream是一种FilterInputStream，在OutputStream的接口上，额外提供了一些写入各种数据类型的方法： 写入int：print(int) 写入boolean：print(boolean) 写入String：print(String) 写入Object：print(Object)，实际上相当于print(object.toString()) System.out是系统自带的一个PrintStream，用于标准输出 与System.out不同，System.in只是一个InputStream，所以如果要使用标准输入读入，我们还需要对System.in进行包装 12345678910111213import java.io.*;public class Echo { public static void main(String[] args) throws IOException { BufferedReader stdin = new BufferedReader( new InputStreamReader(System.in)); String s; while((s = stdin.readLine()) != null &amp;&amp; s.length()!= 0) System.out.println(s); // An empty line or Ctrl-Z terminates the program }} ///:~ New I/OJDK1.4介绍了java.nio包，它的目的是更快速的进行I/O读写。具体细节这里不赘述 Object Serialization 序列化是指把一个Java对象变成二进制内容，本质上就是一个byte[]数组。为什么要把Java对象序列化呢？因为序列化后可以把byte[]保存到文件中，或者把byte[]通过网络传输到远程，这样，就相当于把Java对象存储到文件或者通过网络传输出去了。有序列化，就有反序列化，即把一个二进制内容(也就是byte[]数组)变回Java对象。有了反序列化，保存到文件中的byte[]数组又可以“变回”Java对象，或者从网络上读取byte[]并把它“变回”Java对象。 实现了Serilizable接口的类都可以进行Java序列化与反序列化，类似Serializable这样的空接口被称为”标记接口”(Marker Interface)1234567891011121314public class Main { public static void main(String[] args) throws IOException { ByteArrayOutputStream buffer = new ByteArrayOutputStream(); try (ObjectOutputStream output = new ObjectOutputStream(buffer)) { // 写入int: output.writeInt(12345); // 写入String: output.writeUTF(&quot;Hello&quot;); // 写入Object: output.writeObject(Double.valueOf(123.456)); } System.out.println(Arrays.toString(buffer.toByteArray())); }} 序列化的本质就是将Java code转成字节码，反序列化的时候再转译回来，所以反序列化得到的对象不会调用构造函数 由transient关键字声明的field不会被序列化，比如我们有一个password的field，我们并不想将其序列化并保存，这个时候可以将其声明为private transient String password; 如果我们想要控制序列化与反序列化，比如调用构造函数，那么可以实现Externalizable接口 Java的序列化机制仅适用于Java，如果需要与其它语言交换数据，必须使用通用的序列化方法，例如JSON EnumBasic enum features123456789101112131415161718192021222324252627282930313233343536373839enum Shrubbery { GROUND, CRAWLING, HANGING }public class EnumClass { public static void main(String[] args) { for(Shrubbery s : Shrubbery.values()) { print(s + &quot; ordinal: &quot; + s.ordinal()); printnb(s.compareTo(Shrubbery.CRAWLING) + &quot; &quot;); printnb(s.equals(Shrubbery.CRAWLING) + &quot; &quot;); print(s == Shrubbery.CRAWLING); print(s.getDeclaringClass()); print(s.name()); print(&quot;----------------------&quot;); } // Produce an enum value from a string name: for(String s : &quot;HANGING CRAWLING GROUND&quot;.split(&quot; &quot;)) { Shrubbery shrub = Enum.valueOf(Shrubbery.class, s); print(shrub); } }} /* Output:GROUND ordinal: 0-1 false falseclass ShrubberyGROUND----------------------CRAWLING ordinal: 10 true trueclass ShrubberyCRAWLING----------------------HANGING ordinal: 21 false falseclass ShrubberyHANGING----------------------HANGINGCRAWLINGGROUND*///:~ EnumClass.values()返回一个枚举变量的数据，顺序为声明枚举的顺序 ordinal()按照枚举的顺序从0开始返回int name()返回枚举的名字 Adding methods to an enum 除了无法继承一个enum之外(因为enum被编译后会变成Class Example extends Enum&lt;Example&gt;，已经继承过，不能再继承了)，我们可以将enum当成普通的Java类 如果我们要为enum添加fields或者methods，那么enum的instances必须在类的开头声明，且最后需要加上;。1234567891011121314151617181920212223public enum OzWitch { // Instances must be defined first, before methods: WEST(&quot;Miss Gulch, aka the Wicked Witch of the West&quot;), NORTH(&quot;Glinda, the Good Witch of the North&quot;), EAST(&quot;Wicked Witch of the East, wearer of the Ruby &quot; + &quot;Slippers, crushed by Dorothy's house&quot;), SOUTH(&quot;Good by inference, but missing&quot;); private String description; // Constructor must be package or private access: private OzWitch(String description) { this.description = description; } public String getDescription() { return description; } public static void main(String[] args) { for(OzWitch witch : OzWitch.values()) print(witch + &quot;: &quot; + witch.getDescription()); }} /* Output:WEST: Miss Gulch, aka the Wicked Witch of the WestNORTH: Glinda, the Good Witch of the NorthEAST: Wicked Witch of the East, wearer of the Ruby Slippers, crushed by Dorothy's houseSOUTH: Good by inference, but missing*///:~ Enum的方法也很普通类的方法一样可以override The mystery of values() 如果我们查看Enum的Java文档，会发现并没有values()这个方法，原因是values()是一个由编译器在编译期间加入的静态方法。编译器还会加入一个valueOf()方法(这个valueOf和Enum类自带的不一样，一个只有一个参数，一个有两个参数) 由于values()是在编译期间加入的，所以说如果我们直接使用Enum类，是无法使用values()的，这个时候可以使用反射Enum en = OzWitch.WEST.getClass().getEnumConstants() Implements, not inherits Enum虽然不能继承父类，但是却可以实现接口12345678910111213141516171819202122232425import java.util.*;import net.mindview.util.*;enum CartoonCharacterimplements Generator&lt;CartoonCharacter&gt; { SLAPPY, SPANKY, PUNCHY, SILLY, BOUNCY, NUTTY, BOB; private Random rand = new Random(47); public CartoonCharacter next() { return values()[rand.nextInt(values().length)]; }}public class EnumImplementation { public static &lt;T&gt; void printNext(Generator&lt;T&gt; rg) { System.out.print(rg.next() + &quot;, &quot;); } public static void main(String[] args) { // Choose any instance: CartoonCharacter cc = CartoonCharacter.BOB; for(int i = 0; i &lt; 10; i++) printNext(cc); }} /* Output:BOB, PUNCHY, BOB, SPANKY, NUTTY, PUNCHY, SLAPPY, NUTTY, NUTTY, SLAPPY,*///:~ EnumSet and EnumMap使用Enum实现的Set和Map Constant-specfic methods Enum有一个特殊的功能，可以创建一个abstract method并且为每个Enum Instance进行不一样的实现 1234567891011121314151617181920212223242526import java.util.*;import java.text.*;public enum ConstantSpecificMethod {DATE_TIME { String getInfo() { return DateFormat.getDateInstance().format(new Date()); }},CLASSPATH { String getInfo() { return System.getenv(&quot;CLASSPATH&quot;); }},VERSION { String getInfo() { return System.getProperty(&quot;java.version&quot;); }};abstract String getInfo();public static void main(String[] args) { for(ConstantSpecificMethod csm : values()) System.out.println(csm.getInfo());}} 这让每个Enum Instance看起来像是一个独立的类，但要记住：这只是一种特殊的用法，他们并不能被当成独立的类使用，ConstantSpecificMethod才是一个类 AnnotationBasic syntaxDefining annotations12345678import java.lang.annotation.*;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface UseCase { public int id(); public String description() default &quot;no description&quot;;} ///:~ 注解的定义用@interface，我们使用元注解(例子中的@Target和@Retention)来声明注解的使用方法。@Target代表了我们的注解应该用在method还是field上；@Retention代表了注解存在于RUNTIME，SOURCE还是CLASS中。 注解中可以声明元素(elements，注解里我们不叫fields)，用来表明注解中拥有的值。这些元素在处理注解的时候会被用到。注解的元素和类的方法很相似，区别是元素没有大括号以及元素可以有默认值。 Meta-annotations @Target 注解能被用在什么地方：CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE(Class, interface or enum) @Retention 注解信息会保存多久：SOURCE(Annotations are discarded by the compiler), CLASS(Annotations are available in the class file by the compiler but can be discarded by the JVM), RUNTIME(Annotations are retained by hte JVM at run time, os they may be read reflectively) @Documented 把注解保存到javadocs Writing annotation processors 没有注解处理器，定义好的注解没有任何意义，编译器不会对其进行任何操作 我们可以使用反射来处理注解： 1234567891011121314import java.lang.reflect.*;import java.util.*;public class UseCaseTracker { public static void trackUseCases(Class&lt;?&gt; cl) { for(Method m : cl.getDeclaredMethods()) { UseCase uc = m.getAnnotation(UseCase.class); if(uc != null) { System.out.println(&quot;Found Use Case:&quot; + uc.id() + &quot; &quot; + uc.description()); } } }} Annotation elements 注解元素允许的类型： All primitives, String, Class, Enums, Annotations, Arrays of any of the above。因此我们知道，注解元素不能使用封装类，但是可以使用nested annotation Default value constrainsts 注解元素的默认值必须是确定的，所以对于空的String我们不能使用null，而应该使用&quot;&quot; Nested annotation123456789import java.lang.annotation.*;@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface Constraints { boolean primaryKey() default false; boolean allowNull() default true; boolean unique() default false;} 123456789import java.lang.annotation.*;@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface SQLString { int value() default 0; String name() default &quot;&quot;; Constraints constraints() default @Constraints;} 如果注解中定义了value元素，那么使用的时候可以不用写key-value pair，比如可以直接使用@SQLString(30)，那么编译器默认这里的30是赋给value元素的，其他元素的使用默认值 SQLString中的nested annotaion Constraints的默认值与@Constraints相同，我们也可以改变它的默认值 123public @interface Uniqueness { Constraints constraints() default @Constraints(unique=true);} 如何使用nested annotation： @SQLString(value = 30, constraints = @Constraints(primaryKey = true)) 如何处理nested annotation： 123456789101112131415import java.lang.reflect.*;import java.util.*;public class SQLStringTracker { public static void trackSQLString(Class&lt;?&gt; cl) { for(Field f : cl.getDeclaredFields()) { SQLString sqlString = f.getAnnotation(SQLString.class); if(sqlString != null) { Constraints con = sqlString.constraints(); System.out.println(&quot;Found sql string:&quot; + sqlString.value() + &quot; &quot; + con.primaryKey()); } } }} Using apt to process annotations除了使用反射(RUNTIME)处理annotations， 还有别的方式处理annotation，比如在SOURCE CODE或者CLASS阶段进行处理 Concurrency","link":"/2021/01/31/Basics/Thinking%20in%20Java%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"title":"java中final、finally和finalize的区别","text":"https://www.cnblogs.com/ktao/p/8586966.html","link":"/2019/09/24/Basics/java%E4%B8%ADfinal%E3%80%81finally%E5%92%8Cfinalize%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"java垃圾回收","text":"Garbage CollectionThe java virtual machine(JVM) that runs your program uses hideden data structures to manage memory. Roots and ReachabilityAn object your program mignt use again: live, opposite is garbage-objects your program cannot reference again Root: any reference your proram can access. Primitive variable are not roots. local variables on stack class variable(static variable) Object is live(i.e. reachable from root) if it is: referenced by a root referenced by another live root(ListNode in a live List) Garbage Collector run DFS from root to find live object.Every object has a “visited” tag, invisible to your program. Memory AddressesMemory is array of bytes with address.Declare local variable –&gt; naming a variable location.(Java picks the address) Memory address == Pointers Mark &amp; Sweep Garbarge Collection2 phase: Mark phase: Do a DFS from every root; marks all live objects Sweep phase: Pass over all objects in the memory. Garbage is reclaimed. Jvm data structrues keep track of free and allocated memory(最简单可以想象成LinkedList), 这种数据结构帮助我们allocate新的变量或者删除掉garbage变量。 Jvm运行一段时间会停下来进行Mark and Sweep。 问题: Fragmentation: tendency of free memory to get broken up into small pieces. Unable to allocate a large object despite lots of free memory解决方法: Compaction: A compacting garbage collector moves objects during sweep phase. Campaction会导致很多变量移动，也就是reference的移动，但其实java中由于reference的特殊设计，使得减少大量的操作。同时refernce的移动也会造成本身的fragmentation，但由于reference的大小都是一样的，所以并不会造成像变量一样插不进去的问题，所以是无所谓的。 Copying Garbage CollectionFaster than mark&amp;sweep because only one phase.Mwmory is divided into 2 spaces, old space and new space. Find live objects by DFS. When it encounter live object in old space, it immediately moves it to new space. Campaction included.Next time, new space is relabeled old space, old space is relabeled new space问题: 只能使用一般的memeory优点: 比mark&amp;sweep快 Generational Garbage CollectionMost objects have short lifetime; a few live very long.A generational collection has 2 or more generations. can be different sizes. can change size. Generational Garbage集合了以上两种GC的优点。 Example(Sun 1.3 JVM):Minor collections: frequent;only affect young generations.Major collections: Cover all objects.Special tables of references from old objects to young is added to the roots for minor collections.(由于在minor collection的时候，我们只检索年轻代，但可能会存在一些年轻代被年老代所reference，这个时候他们不应该回收，但我们没有对年老代进行DFS。解决方式是用一个table记录。) https://www.cnblogs.com/wangsr-suc/p/9241652.html","link":"/2019/09/24/Basics/java%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"Python字符编解码","text":"1. ASCII码我们知道，计算机内部，所有信息最终都是一个二进制值。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从00000000到11111111。 上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为 ASCII 码，一直沿用至今。 ASCII 码一共规定了128个字符的编码，比如空格SPACE是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的一位统一规定为0。 2. Unicode字符集ASCII码只能表示英文字符，然而无法表示世界上其他语言的字符，世界各国针对本国文字制定了各种不同的编码方式，但这样一个最大的问题就是使用不同的编解码方式会出现乱码，所以出现了unicode字符集。 Unicode标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。现在，捋一捋ASCII编码和Unicode编码的区别：ASCII编码是1个字节，而Unicode编码通常是2个字节。字母A用ASCII编码是十进制的65，二进制的01000001；字符0用ASCII编码是十进制的48，二进制的00110000，注意字符'0'和整数0是不同的；汉字中已经超出了ASCII编码的范围，用Unicode编码是十进制的20013，二进制的01001110 00101101。你可以猜测，如果把ASCII编码的A用Unicode编码，只需要在前面补0就可以，因此，A的Unicode编码是00000000 01000001。 3. Unicode的问题需要注意的是，Unicode 只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。 比如，汉字严的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。 这里就有两个严重的问题，第一个问题是，如何才能区别 Unicode 和 ASCII ？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果 Unicode 统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。 它们造成的结果是：1）出现了 Unicode 的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示 Unicode。2）Unicode 在很长一段时间内无法推广，直到互联网的出现。 4. UTF-8互联网的普及，强烈要求出现一种统一的编码方式。UTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。其他实现方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8 是 Unicode 的实现方式之一。 UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8 的编码规则很简单，只有二条： 1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。 2）对于n字节的符号（n &gt; 1），第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。 下表总结了编码规则，字母x表示可用编码的位。 Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）———————-+———————————————0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 下面，还是以汉字严为例，演示如何实现 UTF-8 编码。 严的 Unicode 是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800 - 0000 FFFF），因此严的 UTF-8 编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，严的 UTF-8 编码是11100100 10111000 10100101，转换成十六进制就是E4B8A5。======100 + 111000 + 100101====== 5. Python2与Python3的字符编解码Python诞生的时候还没有Unicode字符集，所以开始的时候Python的str类型都是其实本质上都是bytes类型，也就是从文件中读入bytes字节流然后经过ACII编码生成字符串。但由于Unicode的出现，Python2中后加入了Unicode类型，Unicode类型的含义是Unicode编码的字符串。Python2中如果想要文件按照’UTF-8’编码保存，需要在开头加入# -*- coding: utf-8 -*-。Python3中将Python2中的Unicode类型改为str类型，也就是新的str类型代表原来老的Unicode类型，并新加入了bytes类型用来表示字节。 encode()是将字符串转换为字节流。decode()是将字节流转换为字符串。","link":"/2019/04/29/Basics/python%E5%AD%97%E7%AC%A6%E7%BC%96%E8%A7%A3%E7%A0%81/"},{"title":"数据库索引","text":"https://www.jianshu.com/p/b72d3ab9e54a https://blog.csdn.net/whoamiyang/article/details/51926985 数据库索引是一种数据结构，用于加快查询表的速度 B Tree(Balanced Tree)是平衡多叉树，所以它的高度要远低于红黑树等平衡二叉树，也就是说他很扁，可以有效地提升查询的效率 B树的非叶子节点和叶子节点都是既有索引，也有数据。B+树的非叶子节点只保存索引,不保存实际的数据,数据都保存在叶子节点的有序链表中。","link":"/2019/09/24/Basics/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/"},{"title":"LoadBalancing","text":"负载均衡什么是负载均衡 Load balancing refers to efficiently distributing incoming network traffic across a group of backend servers, also known as a server farm or server pool. 通俗来说就是后端服务往往host在多个服务器中，当我们收到大量client发送来的请求时，我们使用load balancer来管理流量，使得请求可以均匀的发送给所有的服务器。我们经常说的反向代理服务器(也就是代理在服务器这一端)的一个很重要的功能就是负载均衡(当然还有其他功能比如缓存，安全保障)。 其实负载均衡一个最著名的用处就是DNS服务器，世界上所有的DNS服务器都会起到负载均衡的作用，但由于DNS服务器的更新可能很慢，所以往往DNS的负载均衡只作为负载均衡的第一步，后面我们还是会使用自己的负载均衡服务器 Layer 4 load balancer vs Layer 7 load balancer 负载均衡器一般分为两种，Layer 4 load balancer和Layer 7 load balancer。Layer 4指的是OSI模型的第四层传输层，也就是说负载均衡器根据TCP/UDP segment进行请求的转发；Layer 7指的是OSI模型的第七层应用层，也就是说负载均衡器根据HTTP/HTTPS message进行请求的转发。 Layer 4 load balancer见图： https://github.com/ShiyuLiuColumbia/diagram/blob/main/Layer4LoadBalancing.drawio.png 第四层的负载均衡器是通过转发TCP/UDP segment来达到分发请求的目的的，本质上是通过NAT改写IP datagram header的IP地址以及TCP/UDP segment header的destination port来达到目的的，其原理与我们家用路由器是类似的。由于负载均衡器只起到转发的作用，所以从client到server端我们只建立了一次TCP连接(图中红线)。 Layer 4负载均衡器的优点是：1.原理简单 2.高效，因为负载均衡器不会去解析应用层的信息，只需要根据TCP/IP的header进行转发就好了 3.安全，后面的Layer 7负载均衡器中会讲到，假设我们使用的是HTTPS协议，那么我们需要在负载均衡器中对HTTPS消息进行解密，一旦有中间人入侵我们的负载均衡器，那么消息就会被监听 4.Only one TCP connection 缺点是：1.No smart load balancing，由于我们不查看应用层的消息，我们不能根据消息本身对请求的转发进行抉择 2.Sticky per segment，某些HTTP请求可能很大，需要被分成很多的TCP segment，对于这样的请求，Layer 4负载均衡器必须有能力判断他们属于同一个请求，并且被发送到同一台主机上 3.No caching，对于Layer 7的负载均衡器，我们可以对请求进行缓存，比如处理过的HTTP请求缓存在负载均衡器中，当有客户再次请求的时候，直接返回即可，但是Layer 4无法做到这一点 Layer 7 load balancer见图：https://github.com/ShiyuLiuColumbia/diagram/blob/main/Layer7LoadBalancing.drawio.png 第七层的负载均衡器是通过转发HTTP/HTTPS message来达到分发请求的目的的，由于我们要检查HTTP/HTTPS请求的具体信息，我们需要建立两次TCP连接，一次是从client到负载均衡器的，一次是从负载均衡器到server的 Layer 7负载均衡器的优点是：1.Smart load balancing 2.Caching 3.Great for microservice 缺点是：1.Two TCP connection 2.Expensive(looks at data) 3.如果client使用的是HTTPS协议的话，那么我们需要进行解密(TLS termination)，我们的负载均衡器中需要存有可信任的证书 负载均衡算法 最常用的算法是轮训(round robin)和最小连接数(Least connections)。在亚麻内部，HTTP/HTTPS负载均衡器推荐使用最小连接数算法，因为这个最小连接数的判断是根据HTTP请求来的，每当有新的请求到来的时候，负载均衡求都会把它打到目前HTTP/HTTPS连接最少的服务器。但是对于TCP负载均衡器，使用最小连接数并不推荐，因为这里的连接不再是HTTP/HTTPS连接，而是TCP连接，一台服务器可能建立了大量TCP连接，但其中很多都是空闲的，所以亚麻并不推荐使用最小连接数算法，而是推荐使用轮训。 其他算法还包括诸如完全随机，加权轮训，加权最小连接数等 应用 公司中的实际应用见图：https://github.com/ShiyuLiuColumbia/diagram/blob/main/LoadBalancerInProject.drawio.png 可以看到，load balancer 1和load balancer 3都是用来处理HTTPS请求的，但是load balancer使用的协议是不一样的。load balancer 1使用的是Layer 7 load balancer并且使用TLS加密，所以请求是可以均匀的打到三台服务器上的(使用的算法是least connections)，但是公司不推荐这种做法，因为在load balancer中使用TLS存在很多的问题。load balancer 3使用的是Layer 4 load balancer + Reverse proxy的做法，请求在load balancer不作任何处理，只是进行转发，使用的算法也只是轮训，在Reverser proxy上进行TLS termination后发到Tomcat服务器监听的HTTP endpoint。这里我们在reverse proxy进行TLS termination，而不是把请求直接发到HTTPS endpoint的原因是：由于我们的load balancer使用TCP协议，存在sticky connection的问题，如果我们使用HTTPS endoint监听请求的话，可能出现server端同一时间被建立了大量的TCP连接，其中很多的连接可能都是无意义的idle的，所以是有必要进行TLS termination的。 现在我们分析使用loader balancer 1的HTTPS请求的建立过程：首先，由于请求是HTTPS协议，client端必须有亚马逊的根证书，用来验证load balancer端提供的证书是正确的；其次，load balancer 1中必须要有由亚马逊根证书(或中间证书)签发的证书，用来向client确认load balancer端的可信性，所以我们看到配置VIP HTTPS load balancer的时候，需要绑定redfort生成的由亚马逊根证书(或中间证书)签发的证书；另外在load balancer完成TLS termination，解析完请求并决定该请求应该打到哪个server后，load balancer与server之间也是使用的HTTPS协议，amazon这里的做法是server端提供自签名的证书，load balancer端不会验证证书的正确性，这就导致了可能存在中间人攻击，这也是为什么amazon不推荐使用Layer 7 load balancer+TLS加密这种做法。 现在我们分析使用loader balancer 3的HTTPS请求的建立过程：首先，client端必须有亚马逊的根证书，用来验证Reverse proxy端提供的证书是正确的；其次，Reverse proxy中必须要有由亚马逊根证书(或中间证书)签发的证书，用来向client确认load balancer端的可信性，所以我们看到配置JLBRelay的时候，需要从odin处获取redfort生成的由亚马逊根证书(或中间证书)签发的证书，odin在这里是负责储存并定时生成新证书的。","link":"/2021/10/12/Backend/LoadBalancing/"},{"title":"Maven学习笔记","text":"Maven简介Maven是基于项目对象模型(POM)，可以通过一小段描述信息来管理项目的构建，报告和文档的软件项目管理工具。Maven可以很好的管理项目中的第三方jar包，避免冲突，一键配置(关于jar包和classpath看另一篇博客)。 代码：https://github.com/ShiyuLiuColumbia/MavenStudy Maven的目录结构代码见maven01 -src -main -java -packages(这里存放程序的java源码) -test -java -packages(这里存放测试的java源码) resource-pom.xml pom.xml即存储了这个java项目的各种信息，包括所在的package名称，项目名称，所用到的依赖等等，maven根据pom.xml使用maven命令管理我们的java项目。 Maven基础知识 Maven主要命令mvn compile 编译maven项目中主程序的源码，生成target目录，里面存放着源码编译成的.class文件以及测试报告mvn test 测试mvn package 打包成jar包mvn clean 删除target目录mvn install 安装jar包到本地仓库中 mvn install例子代码见maven02如果我们想要在maven02工程中使用上面例子中的maven01 package，需要先将maven01打包成jar包，然后将该jar包安装到本地仓库中(mvn install)。然后再将maven01的依赖写入maven02的pom文件即可。 maven中的坐标与仓库坐标：groupId+artifactId+version仓库：本地仓库和远程仓库，maven根据坐标在仓库中查找依赖的jar包 maven生命周期：https://www.liaoxuefeng.com/wiki/1252599548343744/1309301196980257clean：清理项目default：构建项目site：生成项目站点 maven插件https://www.liaoxuefeng.com/wiki/1252599548343744/1309301217951777 pom.xml中常见元素解析 &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; //当前pom版本 &lt;groupId&gt;反写公司网址+项目名&lt;/groupId&gt; &lt;artifactId&gt;项目名+模块名&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;packaging&gt;&lt;/packaging&gt; //项目打包方式，默认是jar，也可以是war，zip，pom &lt;name&gt;&lt;/name&gt; //项目描述名 &lt;url&gt;&lt;/url&gt; //项目地址 &lt;description&gt;&lt;/description&gt; //项目描述 &lt;developers&gt;&lt;/developers&gt; &lt;licenses&gt;&lt;licenses&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;反写公司网址+项目名&lt;/groupId&gt; &lt;artifactId&gt;项目名+模块名&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;type&gt;&lt;/type&gt; &lt;scope&gt;test&lt;/scope&gt; //依赖范围，比如这里这个依赖只在测试阶段有用 &lt;optional&gt;&lt;/optional&gt; //设置依赖是否可选，默认false &lt;exclusions&gt; //排除依赖列表 &lt;exclusion&gt; &lt;exclusion&gt; &lt;exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; //另一在父模块中，用于子模块继承，但是这之中的依赖不会被使用 &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;反写公司网址+项目名&lt;/groupId&gt; &lt;artifactId&gt;项目名+模块名&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;parent&gt;&lt;/parent&gt; &lt;modules&gt;&lt;/modules&gt; maven依赖范围Dependency scope is used to limit the transitivity of a dependency, and also to affect the classpath used for various build tasks.https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html默认的依赖范围是compile，对编译，测试，运行三种阶段的classpath均有效 maven依赖传递与依赖冲突maven的依赖是逐步传递的 如何某个依赖多次被使用，那么依据1.短路优先 2.若路径长度相同，谁先出现使用谁","link":"/2020/03/26/Backend/Maven%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"Servlets and JSPs","text":"ServletUnderstanding the servletTomcat可以简单的理解为一个web容器，我们编写的servelet程序必须要在web容器中才能运行，这很好理解，因为单单一个servlet java程序并不能够接收浏览器的信息，我们需要通过web容器接收到浏览器的命令，然后web容器再调用servlet处理并返回结果。Tomcat从浏览器接收到请求后生成request和response两个对象，将这两个对象传入servlet，servelet处理后再返回Tomcat。Servlet可以使用xml或者annotation来处理路径。 12345678910111213141516171819202122232425262728293031package org.shiyu.liu;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * Servlet implementation class SimpleServlet */@WebServlet(description = &quot;A simple servlet&quot;, urlPatterns = { &quot;/SimpleServletPath&quot; })//使用annotation来处理路径public class SimpleServlet extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {//从Tomcat中接收到的request和response对象 // TODO Auto-generated method stub System.out.println(&quot;Hello From Get Method&quot;); response.setContentType(&quot;text/html&quot;); PrintWriter writer = response.getWriter(); writer.println(&quot;&lt;h3&gt;Hello from html&lt;/h3&gt;&quot;); }} Servlet XML configuration我们可以不使用annonation配置servlet的url，而是直接在web.xml中进行配置: welcome-file-list的工作原理是，按照welcome-file的.list一个一个去检查是否web目录下面存在这个文件，如果存在，继续下面的工作，先去webcontent(这里是Eclipse的工程目录根目录)下是否真的存在index.html这个文件，如果不存在去找是否存在index.jsp这个文件，以此类推。: 关联和: 关联和 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;4.0&quot;&gt; &lt;display-name&gt;SimpleServletProject&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;servlet&gt; &lt;servlet-name&gt;xmlServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.shiyu.liu.XmlServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;xmlServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/xmlServletPath&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; xml比annotation的优势在于，当我们改变路径的时候，如果是在xml修改，只需要重启Tomcat即可，但是如果修改java代码，那么需要重新编译。 The POST Method and Passing Parameters1234567891011121314151617181920212223242526272829package org.shiyu.liu;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * Servlet implementation class XmlServlet */public class XmlServlet extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub response.setContentType(&quot;text/html&quot;); PrintWriter out = response.getWriter(); String userName = request.getParameter(&quot;userName&quot;);//得到userName这个参数的值 out.println(&quot;Hello &quot; + userName); }} Request, Session, contextresponse, request和servlet本身都是objects，由Tomcat创建(我们只写了servlet的class，它的instantiate是由Tomcat实现的)。request和response objects每一次有浏览器发起请求都会由Tomcat实例化一次(因为HTTP协议是stateless的)servlet object只有一个，不同的请求有不同的servlet thread，但是都是在这一个实例下面的 由于request object在每次请求事都会被重置，有的时候我们需要记住已有的信息(比如用户的登录信息)，这个时候就要使用session。Tomcat将session存在内存中。https://www.zhihu.com/question/19786827https://www.runoob.com/servlet/servlet-session-tracking.html 12345678910111213protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub response.setContentType(&quot;text/html&quot;); PrintWriter out = response.getWriter(); String userName = request.getParameter(&quot;userName&quot;); HttpSession session = request.getSession(); if(userName!=null &amp;&amp; !userName.equals(&quot;&quot;)) { session.setAttribute(&quot;savedUserName&quot;, userName); } out.println(&quot;Hello from GET moethd &quot; + userName); out.println(&quot;Saved session user name: &quot;+ (String)session.getAttribute(&quot;savedUserName&quot;)); } session object对于不同的用户(浏览器)有不同的值，如果我们需要一个对于所有用户都存有同样值的对象，那么可以使用context object。https://blog.csdn.net/gavin_john/article/details/51399425 Understanding init, service and ServletConfig(how a servlet is initialized, the methods that get called and the objects used on initialization and execution)There are methods which run before the doGet and doPost. 代码都可以在HttpServlet.java中查看init(servletConfig):第一次call servlet的时候，进行servlet初始化service():service通过判断HTTP code来调用doGet或者其他方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { long lastModified = getLastModified(req); if (lastModified == -1) { // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); } else { long ifModifiedSince; try { ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); } catch (IllegalArgumentException iae) { // Invalid date header - proceed as if none was set ifModifiedSince = -1; } if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) { // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); } else { resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); } } } else if (method.equals(METHOD_HEAD)) { long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp); } else if (method.equals(METHOD_PUT)) { doPut(req, resp); } else if (method.equals(METHOD_DELETE)) { doDelete(req, resp); } else if (method.equals(METHOD_OPTIONS)) { doOptions(req,resp); } else if (method.equals(METHOD_TRACE)) { doTrace(req,resp); } else { // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); }} 所以比如连接数据库的操作就可以在init()中完成。 Servlet一个最大的缺点就是在java code中写html，JSP可以解决这个问题，JSP其实就是一种动态思想，web界面主要由html显示，其中需要改变的地方可以使用java变量。 JSPJSP baiscsServlet一个最大的缺点就是在java code中写html，JSP可以解决这个问题，JSP其实就是一种动态思想，web界面主要由html显示，其中需要改变的地方可以使用java变量。JSP和EJS里用于表示变量的方法很像(我感觉ejs应该是模仿JSP的吧)，JSP使用&lt;% JAVA语句 %&gt;来写java代码， &lt;%= JAVA变量%&gt;来显示到html中，&lt;%! JAVA函数 %&gt;来定义一个全局函数。 123456789&lt;%! public int add(int a, int b){ return a+b;}%&gt;&lt;%int t = add(234, 123);%&gt;t's value is: &lt;%=t %&gt; 所以其实JSP/EJS/jinja2本质上其实就是simple templating language that lets you generate HTML markup with plain JAVA/JavaScript/python。 understanding JSPJSP在运行的时候，其实会被Tomcat转化成java class文件，也就是一个servlet，所有&lt;% %&gt;里面的语句都会运行在servlet的doGet method中。所以我们不能在&lt;% %&gt;中间写另一个函数。而&lt;%! %&gt;里的内容只会被放在class中。而对于JSP中其他的html tag，其实就相当于java调用了out.println()函数。这也是JSP可以像下面这样写的原因(和ejs类似) 123456789&lt;% for(int p = 0;p&lt;=5;p++){%&gt;&lt;br&gt; The value of p is: &lt;%=p %&gt;&lt;% }%&gt; JSP被翻译的java class可以在Tomcat的work文件夹下面找到 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188/* * Generated by the Jasper component of Apache Tomcat * Version: Apache Tomcat/9.0.33 * Generated at: 2020-03-30 18:00:34 UTC * Note: The last modified time of this file was set to * the last modified time of the source file after * generation to assist with modification tracking. */package org.apache.jsp;import javax.servlet.*;import javax.servlet.http.*;import javax.servlet.jsp.*;public final class test_jsp extends org.apache.jasper.runtime.HttpJspBase implements org.apache.jasper.runtime.JspSourceDependent, org.apache.jasper.runtime.JspSourceImports { public int add(int a, int b){ return a+b; } private static final javax.servlet.jsp.JspFactory _jspxFactory = javax.servlet.jsp.JspFactory.getDefaultFactory(); private static java.util.Map&lt;java.lang.String,java.lang.Long&gt; _jspx_dependants; private static final java.util.Set&lt;java.lang.String&gt; _jspx_imports_packages; private static final java.util.Set&lt;java.lang.String&gt; _jspx_imports_classes; static { _jspx_imports_packages = new java.util.HashSet&lt;&gt;(); _jspx_imports_packages.add(&quot;javax.servlet&quot;); _jspx_imports_packages.add(&quot;javax.servlet.http&quot;); _jspx_imports_packages.add(&quot;javax.servlet.jsp&quot;); _jspx_imports_classes = null; } private volatile javax.el.ExpressionFactory _el_expressionfactory; private volatile org.apache.tomcat.InstanceManager _jsp_instancemanager; public java.util.Map&lt;java.lang.String,java.lang.Long&gt; getDependants() { return _jspx_dependants; } public java.util.Set&lt;java.lang.String&gt; getPackageImports() { return _jspx_imports_packages; } public java.util.Set&lt;java.lang.String&gt; getClassImports() { return _jspx_imports_classes; } public javax.el.ExpressionFactory _jsp_getExpressionFactory() { if (_el_expressionfactory == null) { synchronized (this) { if (_el_expressionfactory == null) { _el_expressionfactory = _jspxFactory.getJspApplicationContext(getServletConfig().getServletContext()).getExpressionFactory(); } } } return _el_expressionfactory; } public org.apache.tomcat.InstanceManager _jsp_getInstanceManager() { if (_jsp_instancemanager == null) { synchronized (this) { if (_jsp_instancemanager == null) { _jsp_instancemanager = org.apache.jasper.runtime.InstanceManagerFactory.getInstanceManager(getServletConfig()); } } } return _jsp_instancemanager; } public void _jspInit() { } public void _jspDestroy() { } public void _jspService(final javax.servlet.http.HttpServletRequest request, final javax.servlet.http.HttpServletResponse response) throws java.io.IOException, javax.servlet.ServletException { if (!javax.servlet.DispatcherType.ERROR.equals(request.getDispatcherType())) { final java.lang.String _jspx_method = request.getMethod(); if (&quot;OPTIONS&quot;.equals(_jspx_method)) { response.setHeader(&quot;Allow&quot;,&quot;GET, HEAD, POST, OPTIONS&quot;); return; } if (!&quot;GET&quot;.equals(_jspx_method) &amp;&amp; !&quot;POST&quot;.equals(_jspx_method) &amp;&amp; !&quot;HEAD&quot;.equals(_jspx_method)) { response.setHeader(&quot;Allow&quot;,&quot;GET, HEAD, POST, OPTIONS&quot;); response.sendError(HttpServletResponse.SC_METHOD_NOT_ALLOWED, &quot;JSP 只允许 GET、POST 或 HEAD。Jasper 还允许 OPTIONS&quot;); return; } } final javax.servlet.jsp.PageContext pageContext; javax.servlet.http.HttpSession session = null; final javax.servlet.ServletContext application; final javax.servlet.ServletConfig config; javax.servlet.jsp.JspWriter out = null; final java.lang.Object page = this; javax.servlet.jsp.JspWriter _jspx_out = null; javax.servlet.jsp.PageContext _jspx_page_context = null; try { response.setContentType(&quot;text/html; charset=UTF-8&quot;); pageContext = _jspxFactory.getPageContext(this, request, response, null, true, 8192, true); _jspx_page_context = pageContext; application = pageContext.getServletContext(); config = pageContext.getServletConfig(); session = pageContext.getSession(); out = pageContext.getOut(); _jspx_out = out; out.write(&quot;\\n&quot;); out.write(&quot;&lt;!DOCTYPE html&gt;\\n&quot;); out.write(&quot;&lt;html&gt;\\n&quot;); out.write(&quot;&lt;head&gt;\\n&quot;); out.write(&quot;&lt;meta charset=\\&quot;UTF-8\\&quot;&gt;\\n&quot;); out.write(&quot;&lt;title&gt;Test jsp&lt;/title&gt;\\n&quot;); out.write(&quot;&lt;/head&gt;\\n&quot;); out.write(&quot;&lt;body&gt;\\n&quot;); out.write(&quot;\\t&quot;); int i = 1; int j = 2; int k; k = i + j; out.println(k); out.write(&quot;\\n&quot;); out.write(&quot;\\tThe value of k is: &quot;); out.print( k ); out.write(&quot;\\n&quot;); out.write(&quot;\\t\\n&quot;); out.write(&quot;\\t&quot;); out.write('\\n'); out.write(' '); int t = add(234, 123); out.write(&quot;\\n&quot;); out.write(&quot;\\tt's value is: &quot;); out.print(t ); out.write(&quot;\\n&quot;); out.write(&quot;\\t\\n&quot;); out.write(&quot;\\t&quot;); for(int p = 0;p&lt;=5;p++){ out.write(&quot;\\n&quot;); out.write(&quot;\\t&lt;br&gt; \\n&quot;); out.write(&quot;\\tThe value of p is: &quot;); out.print(p ); out.write('\\n'); out.write(' '); } out.write(&quot;\\n&quot;); out.write(&quot;&lt;/body&gt;\\n&quot;); out.write(&quot;&lt;/html&gt;&quot;); } catch (java.lang.Throwable t) { if (!(t instanceof javax.servlet.jsp.SkipPageException)){ out = _jspx_out; if (out != null &amp;&amp; out.getBufferSize() != 0) try { if (response.isCommitted()) { out.flush(); } else { out.clearBuffer(); } } catch (java.io.IOException e) {} if (_jspx_page_context != null) _jspx_page_context.handlePageException(t); else throw new ServletException(t); } } finally { _jspxFactory.releasePageContext(_jspx_page_context); } }} page directives用于java程序的一些全局配置 12&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; import=&quot;java.util.Date&quot;%&gt; Scopes in JSP and the PageContext object JSP中可以直接使用类似servlet的request, response, session, context objects。 12345678910111213141516171819202122232425262728&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;% String userName = request.getParameter(&quot;userName&quot;); application.setAttribute(&quot;applicationContextName&quot;, &quot;defaultName&quot;); if(userName!=null){ session.setAttribute(&quot;sessionName&quot;, userName); application.setAttribute(&quot;applicationContextName&quot;, userName);//application context object pageContext.setAttribute(&quot;pageContextName&quot;, userName);//page context object } %&gt; &lt;br&gt; The user name in the request object is : &lt;%= userName %&gt; &lt;br&gt; The user name in the session object is : &lt;%= session.getAttribute(&quot;sessionName&quot;) %&gt; &lt;br&gt; The user name in the application context object is : &lt;%= application.getAttribute(&quot;applicationContextName&quot;) %&gt; &lt;br&gt; The user name in the page context object is : &lt;%= pageContext.getAttribute(&quot;pageContextName&quot;) %&gt;&lt;/body&gt;&lt;/html&gt; Using jspInit and InitParamsJSP也可以配置initParameter或者重写jspInit()函数。 MVCServlet(Controller)Bean(Model)JSP(View)我们这里的MVC数据由JSP(View层)直接返回给user，也可以是JSP返回给COntroller，Controller处理后再返回给user，这取决于MVC的设计。 jstljsp的缺点是要在html中夹杂很多java code，所以产生了jstl","link":"/2020/03/28/Backend/Servlets%20and%20JSPs/"},{"title":"Spring","text":"Inversion of controlThe approach of outsourcing(外包) the construction and management of objects(outsource to a object factory). 下面这段程序是一个普通的java程序 12345678public class MyApp { public static void main(String[] args) { // TODO Auto-generated method stub Coach theCoach = new TrackCoach(); System.out.println(theCoach.getDailyWorkout()); }} Java编程中我们通常直接使用new创建一个新的对象，这样类和类之间存在高耦合，也就是说如果我们想要此时不想要TrackCoach给我们建议而是让其他Coach给我们建议，我们只能更改源代码。而IOC就是为了解决这个问题，对象的创建由Spring Container(Object Factory)帮我们创建。 Spring Container的主要功能：1.Create and Manage objects(IOC) 2.Inject object’s dependencies(Dependency Injection) 我们使用Spring Container之前需要进行配置，主要有三种方式：1.XML file(legacy, but most legacy apps use it) 2.Java annotation(modern) 3.Java source code(modern) XML file configurationIOC Spring程序的开发流程：1.Configure your Spring Beans什么是Spring Beans？A “Spring Bean” is simply a Java object.When Java objects are created by the Spring Container, then Spring refers to them as “Spring Beans”. 12&lt;bean id=&quot;myCoach&quot; class=&quot;com.luv2code.springdemo.TrackCoach&quot;&gt;&lt;/bean&gt; 2.Create a Spring ContainerSpring Container is generally known as ApplicationContect. 它有一些具体的实现: ClassPathXmlApplicationContext, AnnotationApplicationContext, GenericWebApplicationContext…这里我们先用xml配置的这种。3.Retrieve Beans from Spring Container 1234567891011121314package com.luv2code.springdemo;import org.springframework.context.support.ClassPathXmlApplicationContext;public class HelloSpringApp { public static void main(String[] args) { //load spring configuration file, Create a Spring Container ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); //retrieve bean from spring Coach theCoach = context.getBean(&quot;myCoach&quot;, Coach.class);//这里我们在getBean方法后面加上Coach.class，spring会自动帮我们进行类型转换 //call methods on the bean System.out.println(theCoach.getDailyWorkout()); //close the context context.close(); }} Coach theCoach = context.getBean(&quot;myCoach&quot;, Coach.class);, 这里我们在getBean方法后面加上Coach.class，spring会自动帮我们进行类型转换, 这样比直接自己手动转换Coach theCoach = (Coach) context.getBean(&quot;myCoach&quot;);的好处是provides a measure of type safety by throwing a BeanNotOfRequiredTypeException if the bean is not of the required type. Java AnnotationJava Annotations are special labels/marks added to Java classes whcih provide meta-data about the class and proceed at compile time or run-time for special processing.Thus spring will scan java classes for special annotations and automatically register the beans in the Spring container.所以使用Java Annotations开发IOC Spring程序的流程是： Enable component scanning in Spring config file.12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- add entry to enable component running --&gt; &lt;context:component-scan base-package=&quot;com.luv2code.springdemo&quot;&gt;&lt;/context:component-scan&gt; &lt;/beans&gt; Add @Component Annotation to your java classes.123456789package com.luv2code.springdemo;import org.springframework.stereotype.Component;@Component(&quot;thatSillyCoach&quot;)public class TennisCoach implements Coach { @Override public String getDailyWorkout() { return &quot;Practise your backhand volley&quot;; }} Retrieve Beans from Spring Container.12345678910111213141516package com.luv2code.springdemo;import org.springframework.context.support.ClassPathXmlApplicationContext;public class AnnotationDemoApp { public static void main(String[] args) { //read spring config file ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); //get the bean from spring container Coach theCoach = context.getBean(&quot;thatSillyCoach&quot;, Coach.class);//这里的名字就是我们在annotation定义的ID //call a method on the bean System.out.println(theCoach.getDailyWorkout()); //close the context context.close(); }} Spring也支持不写Bean ID，那么它默认的Bean ID就是class name的首字母小写：比如TennisCoach类，那么我们用的时候就是”tennisCoach” Dependency InjectionDependency Injection指的是如果我们跟object factory要一个car object，car object由许多包括tire object, seat object, engine object组成，那么object factory会自动帮我们组装好，这就是依赖注入。“dependency” is the same thing as “helper objects”. Injection Types: 1. Construction Injection 2. Setter Injection 3.auto-wiring(in annotation section) XML configurarion - Construction injectionConstruction injection的开发流程: Define the dependency interface and class1234567package com.luv2code.springdemo;public class HappyFortuneService implements FortuneService { @Override public String getFortune() { return &quot;Today is your lucky day&quot;; }} Create a constructor in your class for injections1234567891011121314151617181920package com.luv2code.springdemo;public class BaseballCoach implements Coach{ //define a private field for the dependency private FortuneService fortuneService; //define a constructor for dependency injection public BaseballCoach(FortuneService theFortuneService) { this.fortuneService = theFortuneService; } @Override public String getDailyWorkout() { return &quot;Spend 30 minutes on batting practise&quot;; } @Override public String getDailyFortune() { //use my fortuneService to get a fortune return fortuneService.getFortune(); }} Configure the dependency injdection in spring config file12345678 &lt;!-- define the dependency(helper object) --&gt; &lt;bean id=&quot;myFortune&quot; class=&quot;com.luv2code.springdemo.HappyFortuneService&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;myCoach&quot; class=&quot;com.luv2code.springdemo.BaseballCoach&quot;&gt; &lt;!-- set up constructor injection --&gt; &lt;constructor-arg ref=&quot;myFortune&quot; /&gt;&lt;/bean&gt; 当我们配置好后，这个时候再在主程序中执行Coach theCoach = (Coach) context.getBean(&quot;myCoach&quot;);，这个时候spring container(object factory)就会按照IOC和DI把组装好的对象直接给我们用了。 所以Dependency Injection帮我们做了什么呢？ 12345678 &lt;!-- define the dependency(helper object) --&gt; &lt;bean id=&quot;myFortune&quot; class=&quot;com.luv2code.springdemo.HappyFortuneService&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;myCoach&quot; class=&quot;com.luv2code.springdemo.BaseballCoach&quot;&gt; &lt;!-- set up constructor injection --&gt; &lt;constructor-arg ref=&quot;myFortune&quot; /&gt;&lt;/bean&gt; 等价于 12HappyFortuneService myFortuneService = new HappyFortuneService();//Dependency Injection帮助我们创建helper object，并帮我们注入到我们需要的Bean里面BaseballCoach myCoach = new BaseballCoach(myFortuneService);//这里Spring调用的是BaseballCoach的constructor是IOC的作用 IOC+DI使得我们的程序耦合度非常低，所有的关键信息都在配置文件中体现，我们的程序的高度可复用的！ XML configurarion - Setter injectionSetter Injection的开发流程： Define the dependency interface and class Create setter method in your class for injection1234567891011121314151617181920212223package com.luv2code.springdemo;public class CricketCoach implements Coach { private FortuneService fortuneService; public CricketCoach() { System.out.println(&quot;Call Cricket Coach Constructor&quot;); } // our setter method public void setFortuneService(FortuneService fortuneService) { System.out.println(&quot;Call Cricket Coach setter method&quot;); this.fortuneService = fortuneService; } @Override public String getDailyWorkout() { return &quot;Practise fast bowling for 15 minutes&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); }} Configure the dependency injdection in spring config file123&lt;bean id=&quot;myCricketCoach&quot; class=&quot;com.luv2code.springdemo.CricketCoach&quot;&gt; &lt;property name=&quot;fortuneService&quot; ref=&quot;myFortune&quot;&gt;&lt;/property&gt;&lt;/bean&gt; spring会去寻找name属性对应的setter函数进行依赖注入，寻找的原则是set+name(首字母大写)，所以这里会去找setFortuneService()这个函数。 从输出可以看出spring在setter依赖注入时先调用没有参数的constructor，然后调用setter进行依赖注入。 上面依赖注入的是类，如果注入的是String的话则有不一样的用法： 12345678&lt;bean id=&quot;myCricketCoach&quot; class=&quot;com.luv2code.springdemo.CricketCoach&quot;&gt; &lt;!-- set up setter injection --&gt; &lt;property name=&quot;fortuneService&quot; ref=&quot;myFortune&quot;&gt;&lt;/property&gt; &lt;!-- inject literal values --&gt; &lt;property name=&quot;emailAddress&quot; value=&quot;shiyuliucu@gmail.com&quot;&gt;&lt;/property&gt; &lt;property name=&quot;team&quot; value=&quot;Sachid&quot;&gt;&lt;/property&gt;&lt;/bean&gt; 更好的做法是把value写在properties file。 create properties file创建一个sport.properties文件，在里面加入这两行foo.email = shiyuliucu@gmail.comfoo.team = Sachid load properties file in spring config file &lt;context:property-placeholder location=&quot;classpath:sport.properties&quot; /&gt; reference values from properties file 1234567891011121314151617181920212223242526272829&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=&quot;classpath:sport.properties&quot; /&gt; &lt;!-- define the dependency(helper object) --&gt; &lt;bean id=&quot;myFortune&quot; class=&quot;com.luv2code.springdemo.HappyFortuneService&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;myCoach&quot; class=&quot;com.luv2code.springdemo.BaseballCoach&quot;&gt; &lt;!-- set up constructor injection --&gt; &lt;constructor-arg ref=&quot;myFortune&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;myCricketCoach&quot; class=&quot;com.luv2code.springdemo.CricketCoach&quot;&gt; &lt;!-- set up setter injection --&gt; &lt;property name=&quot;fortuneService&quot; ref=&quot;myFortune&quot;&gt;&lt;/property&gt; &lt;!-- inject literal values --&gt; &lt;property name=&quot;emailAddress&quot; value=&quot;${foo.email}&quot;&gt;&lt;/property&gt; &lt;property name=&quot;team&quot; value=&quot;${foo.team}&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; Java Annotations(Autowiring) - Contructor InjectionFor dependency injection, Spring can use auto wiring. Spring will look for a class or interface that matches the property. And then, Spring will inject it automatically.Autowiring的实现过程：Spring会扫描所有的@Component注解，如果发现里面有@autowired注解的成员变量，那么就会去找相对应的实现类并自动进行依赖注入。 开发流程是： Define the independency interface and class Create a constructor in your class for injection Configure the dependency injection with @Autowired Annotation12345678910111213141516171819202122232425package com.luv2code.springdemo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Component(&quot;thatSillyCoach&quot;)public class TennisCoach implements Coach { private FortuneService fortuneService; @Autowired public TennisCoach(FortuneService fs) { this.fortuneService = fs; } @Override public String getDailyWorkout() { return &quot;Practise your backhand volley&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); }} Java Annotations(Autowiring) - Setter Injection1234567891011121314151617181920212223242526272829303132package com.luv2code.springdemo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Component(&quot;thatSillyCoach&quot;)public class TennisCoach implements Coach { private FortuneService fortuneService; public TennisCoach() { System.out.println(&quot;Tennis Coach: inside default constructor&quot;); } @Autowired public void setFortuneService(FortuneService fortuneService) { this.fortuneService = fortuneService; } @Override public String getDailyWorkout() { return &quot;Practise your backhand volley&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); }} Java Annotations(Autowiring) - Field Injection其实最简单的方式是我们直接在class的fields上标注@Autowired，那么他们就会自动进行依赖注入，这是通过java的反射机制完成的。 123456789101112131415161718192021222324package com.luv2code.springdemo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Component(&quot;thatSillyCoach&quot;)public class TennisCoach implements Coach { @Autowired private FortuneService fortuneService; public TennisCoach() { System.out.println(&quot;Tennis Coach: inside default constructor&quot;); } @Override public String getDailyWorkout() { return &quot;Practise your backhand volley&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); }} Java Annotations(Autowiring) - Qualifiers现在出现了一个很严重的问题：前面我们的接口只有一个实现类，所以spring直到要用这个类进行依赖注入，但是如果对于一个接口有多个实现类呢？这个时候就用到了Qualifiers(限定词) 1234567891011121314151617181920212223242526package com.luv2code.springdemo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Component;@Component(&quot;thatSillyCoach&quot;)public class TennisCoach implements Coach { @Autowired @Qualifier(&quot;happyFortuneService&quot;) private FortuneService fortuneService; public TennisCoach() { System.out.println(&quot;Tennis Coach: inside default constructor&quot;); } @Override public String getDailyWorkout() { return &quot;Practise your backhand volley&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); }} @Qualifier使用的必须是想用的类的类名(首字母小写) Some tipsAnnotations - Default Bean Names … and the Special CaseIn general, when using Annotations, for the default bean name, Spring uses the following rule.If the annotation’s value doesn’t indicate a bean name, an appropriate name will be built based on the short name of the class (with the first letter lower-cased).For example:HappyFortuneService –&gt; happyFortuneServiceHowever, for the special case of when BOTH the first and second characters of the class name are upper case, then the name is NOT converted.For the case of RESTFortuneServiceRESTFortuneService –&gt; RESTFortuneServiceNo conversion since the first two characters are upper case.Behind the scenes, Spring uses the Java Beans Introspector to generate the default bean name. Here’s a screenshot of the documentation for the key method.https://docs.oracle.com/javase/8/docs/api/java/beans/Introspector.html#decapitalize(java.lang.String) Using @Qualifier with Constructors@Qualifier is a nice feature, but it is tricky when used with Constructors. The syntax is much different from other examples and not exactly intuitive. Consider this the “deep end of the pool” when it comes to Spring configuration LOL :-) You have to place the @Qualifier annotation inside of the constructor arguments. Here’s an example from our classroom example. I updated it to make use of constructor injection, with @Autowired and @Qualifier. Make note of the code in bold below: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.luv2code.springdemo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Component;@Componentpublic class TennisCoach implements Coach { private FortuneService fortuneService; // define a default constructor public TennisCoach() { System.out.println(&quot;&gt;&gt; TennisCoach: inside default constructor&quot;); } @Autowired public TennisCoach(@Qualifier(&quot;randomFortuneService&quot;) FortuneService theFortuneService) { System.out.println(&quot;&gt;&gt; TennisCoach: inside constructor using @autowired and @qualifier&quot;); fortuneService = theFortuneService; } /* @Autowired public void doSomeCrazyStuff(FortuneService theFortuneService) { System.out.println(&quot;&gt;&gt; TennisCoach: inside doSomeCrazyStuff() method&quot;); fortuneService = theFortuneService; } */ /* @Autowired public TennisCoach(FortuneService theFortuneService) { fortuneService = theFortuneService; } */ @Override public String getDailyWorkout() { return &quot;Practice your backhand volley&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); }} For detailed documentation on using @Qualified with Constructors, see this link in the Spring Reference Manualhttps://docs.spring.io/spring/docs/current/spring-framework-reference/core.html#beans-autowired-annotation-qualifiers How to inject properties file using Java annotationsFAQ: How to inject properties file using Java annotations Answer: This solution will show you how inject values from a properties file using annotatons. The values will no longer be hard coded in the Java code. Create a properties file to hold your properties. It will be a name value pair.New text file: src/sport.properties foo.email=myeasycoach@luv2code.comfoo.team=Silly Java CodersNote the location of the properties file is very important. It must be stored in src/sport.properties Load the properties file in the XML config file.File: applicationContext.xmlAdd the following lines: 1&lt;context:property-placeholder location=&quot;classpath:sport.properties&quot;/&gt; This should appear just after the &lt;context:component-scan …/&gt; line Inject the properties values into your Swim Coach: SwimCoach.java 12345@Value(&quot;${foo.email}&quot;)private String email; @Value(&quot;${foo.team}&quot;)private String team; Spring Beans Scopes and LifecycleBeans ScopesScope指的是Bean对象的作用范围 How long does a bean live How many instances are created How is the bean shared 1.默认的作用范围是singleton Spring container(Object Factory) 只会默认为这个bean创建一个实例 It is cashed in memory All requests for the bean will return a SHARED reference to the same BEAN 2.prototype: Creates a new bean instance for each container request3.request: Scoped to a HTTP web request. Only used for web apps.4.session: Scoped to a HTTP web session. Only used for web apps.5.global-session: Scoped to a global HTTP web session. Only used for web apps. 1234567891011121314151617package com.luv2code.springdemo;import org.springframework.context.support.ClassPathXmlApplicationContext;public class BeanScopeDemoApp { public static void main(String[] args) { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;beanScope-applicationContext.xml&quot;); Coach theCoach = context.getBean(&quot;myCoach&quot;, Coach.class); Coach alphaCoach = context.getBean(&quot;myCoach&quot;, Coach.class); //check if they are the same System.out.println(theCoach==alphaCoach); context.close(); }} singleton模式下结果是true，prototype模式下结果是false。 我们也可以使用Anotation @Scope： 12345678910111213141516171819202122232425262728package com.luv2code.springdemo;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Scope;import org.springframework.stereotype.Component;@Component(&quot;thatSillyCoach&quot;)@Scope(&quot;prototype&quot;)//在这里进行scope的注解public class TennisCoach implements Coach { @Autowired @Qualifier(&quot;happyFortuneService&quot;) private FortuneService fortuneService; public TennisCoach() { System.out.println(&quot;Tennis Coach: inside default constructor&quot;); } @Override public String getDailyWorkout() { return &quot;Practise your backhand volley&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); }} Beans lifecycle we can add custom code during bean intialization calling custom business logic method setting up handles to resources(db, sockets, file, etc) we can add custom code during bean destruction calling custom business logic method cleaning up handles to resources(db, sockets, file, etc) 使用initialization和destruction的方法是先定义init或者destroy函数，然后再spring配置文件中进行配置。 12345&lt;bean id=&quot;myCoach&quot; class=&quot;com.luv2code.springdemo.TrackCoach&quot; init-method=&quot;doMyStartUpStuff&quot; destroy-method=&quot;doMyCleanUpStuff&quot;&gt; &lt;!-- set up constructor injection --&gt; &lt;constructor-arg ref=&quot;myFortune&quot; /&gt;&lt;/bean&gt; 我们也可以使用Annotation：@PostConstruct and @PreDestroy Special Note about @PostConstruct and @PreDestroy Method Signatures I want to provide additional details regarding the method signatures of @PostContruct and @PreDestroy methods. Access modifier The method can have any access modifier (public, protected, private) Return typeThe method can have any return type. However, “void’ is most commonly used. If you give a return type just note that you will not be able to capture the return value. As a result, “void” is commonly used. Method nameThe method can have any method name. ArgumentsThe method can not accept any arguments. The method should be no-arg. 123456789101112131415161718192021222324252627282930313233343536373839404142package com.luv2code.springdemo;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Scope;import org.springframework.stereotype.Component;@Component(&quot;thatSillyCoach&quot;)public class TennisCoach implements Coach { @Autowired @Qualifier(&quot;happyFortuneService&quot;) private FortuneService fortuneService; public TennisCoach() { System.out.println(&quot;Tennis Coach: inside default constructor&quot;); } @Override public String getDailyWorkout() { return &quot;Practise your backhand volley&quot;; } @Override public String getDailyFortune() { return fortuneService.getFortune(); } @PostConstruct //define my init method public void doStartUpStuff() { System.out.println(&quot;Tennis Coach: inside default doStartUpStuff()&quot;); } @PreDestroy //define my destroy method public void doCleanUpStuff() { System.out.println(&quot;Tennis Coach: inside default doCleanUpStuff()&quot;); }} Spring Configuration with java code(no xml)3 ways to configure Spring Container: Full xml config xml Component scan + Annotation Java configuration class 开发流程： Create a Java Class and annotate as @Configuration Add component scanning support: @ComponentScan(optional)12345678910package com.luv2code.springdemo;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;@Configuration@ComponentScan(&quot;com.luv2code.springdemo&quot;)public class SportConfig {} Read Spring Configuration class Retrieve bean from Spring container123456789101112131415161718package com.luv2code.springdemo;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class JavaConfigDemoApp { public static void main(String[] args) { //read spring config file AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(SportConfig.class); //get the bean from spring container Coach theCoach = context.getBean(&quot;thatSillyCoach&quot;, Coach.class); //call a method on the bean System.out.println(theCoach.getDailyWorkout()); System.out.println(theCoach.getDailyFortune()); //close the context context.close(); }} Java config的方式不仅可以定义Spring Container，也可以定义Bean Object开发流程： Define method to expose bean using @Bean Inject bean dependencies12345678910111213141516171819202122package com.luv2code.springdemo;import org.springframework.context.annotation.Bean;//import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;@Configuration//@ComponentScan(&quot;com.luv2code.springdemo&quot;) 因为我们定义好Bean了，所以也不需要自动扫描了public class SportConfig { //define bean for our sad fortune service @Bean public FortuneService sadFortuneService() {//函数名是Bean id return new SadFortuneService(); } //define bean for our swim coach AND inject dependency @Bean public Coach swimCoach() { return new SwimCoach(sadFortuneService()); }} Read Spring Java configuration class Retrieve bean from Spring Container123456789101112131415161718package com.luv2code.springdemo;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class SwimJavaConfigDemoApp { public static void main(String[] args) { //read spring config file AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(SportConfig.class); //get the bean from spring container Coach theCoach = context.getBean(&quot;swimCoach&quot;, Coach.class); //call a method on the bean System.out.println(theCoach.getDailyWorkout()); System.out.println(theCoach.getDailyFortune()); //close the context context.close(); }} 使用java code从properties file中读取数据也是可以的。开发流程是： Create properties file Load properties file in Spring Config123456789101112131415161718192021package com.luv2code.springdemo;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;@Configuration@PropertySource(&quot;classpath:Sport.properties&quot;)public class SportConfig { //define bean for our sad fortune service @Bean public FortuneService sadFortuneService() {//函数名是Bean id return new SadFortuneService(); } //define bean for our swim coach AND inject dependency @Bean public Coach swimCoach() { return new SwimCoach(sadFortuneService()); }} Reference Value from Properties File123456789101112131415161718192021222324252627282930313233343536package com.luv2code.springdemo;import org.springframework.beans.factory.annotation.Value;public class SwimCoach implements Coach { private FortuneService fortuneService; @Value(&quot;${foo.email}&quot;) private String email; @Value(&quot;${foo.team}&quot;) private String team; public String getEmail() { return email; } public String getTeam() { return team; } public SwimCoach(FortuneService fs) { this.fortuneService = fs; } @Override public String getDailyWorkout() { return &quot;Swim 1000 meters as a wram up&quot;; } @Override public String getDailyFortune() { return this.fortuneService.getFortune(); }} Spring MVC Controller Code created by developer Contains your business logic handle the request store/retrieve data(db, web service…) place data in a model send to appropriate view template Model contains your data store/retrieve data via backend systems database, wev services … using a spring bean if you like place your data in the model data can be any java object/collection View Template Spring MVC is flexible support many view templates Most common is JSP+JSTL developer creates a page display data Configuration因为所有的java web项目本质上都是对servlets的封装并加入一些方便程序员编写的特性，所以配置SpringMVC的第一步就是在web.xml文件中配置Spring写好的DispatcherServlet，Servlet的相关知识包含在在Servlets and JSPs的课程里。 JAR configuration: 将所需的jar file放入WebContent/WEBINF/lib中，eclipse自动将他们加载到项目的classpath中。所需的jar有spring core的jar和JSTL的jar web.xml(配置servlet)1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.1&quot;&gt; &lt;display-name&gt;spring-mvc-demo&lt;/display-name&gt; &lt;absolute-ordering /&gt; &lt;!-- Spring MVC Configs --&gt; &lt;!-- Step 1: Configure Spring MVC Dispatcher Servlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;!-- servlet在启动前扫描spring-mvc-demo-servlet.xml的配置进行IOC和DI --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/spring-mvc-demo-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- Step 2: Set up URL mapping for Spring MVC Dispatcher Servlet --&gt; &lt;!-- 这一句相当于所有访问的指定都会给到spring提供的这个servlet去 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; applicationContext.xml(这个demo里面名字叫spring-mvc-demo-servlet.xml)1234567891011121314151617181920212223242526272829&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt; &lt;!-- Step 3: Add support for component scanning --&gt; &lt;context:component-scan base-package=&quot;com.luv2code.springdemo&quot; /&gt; &lt;!-- Step 4: Add support for conversion, formatting and validation support --&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- Step 5: Define Spring MVC view resolver --&gt;&lt;!-- 这里是告诉ViewResolver我们的jsp文件都放在什么地方了，这样SpringMVC才能找到它们。 也就是ViewResolver会自动去/WEB-INF/view/文件夹下去找.jsp文件 --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/view/&quot; /&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; Create Controllers and ViewsBasic Controller开发流程： Create Controller Class对class使用@Controller这个Annotation，@Controller继承自@Component，所以Spring也会自动扫描@Controller的类。 Define Controller Method Add Request Mapping to Controller method Return View Name12345678910111213package com.luv2code.springdemo.mvc;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class HomeController { @RequestMapping(&quot;/&quot;) public String showPage() {//函数名，参数都是随意的 return &quot;main-menu&quot;; //由于我们的配置，spring会去找/WEB-INF/view/main-menu.jsp }} Develop View Page123456789101112&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Spring MVC demo - Home Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Spring MVC demo - Home Page&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; QuestionHow does component scan work in this example? You have different package names.You listed the component scan package as: com.luv2code.springdemoBut the our MVC controllers are defined in com.luv2code.springdemo.mvc AnswerFor the Spring attribute: base-package=”com.luv2code.springdemo”Spring will recursively scan for components starting at the base package: “com.luv2code.springdemo”When I say “recursive”, it means that Spring will start at the base package and scan all sub packages.The package com.luv2code.springdemo.mvc is a sub package because of naming structure, just like folders on a file system.As a result, it will be included in the scan. Controller进阶：读取html表格里的数据HelloWorldController.java 1234567891011121314151617181920package com.luv2code.springdemo.mvc;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class HelloWorldController { //need a controller method to show the initial HTML form @RequestMapping(&quot;/showForm&quot;) public String showForm() { return &quot;helloworld-form&quot;; } //need a controller method to process the HTML form @RequestMapping(&quot;/processForm&quot;) public String processForm() { return &quot;helloworld&quot;; }} helloworld-form.jsp 12345678910111213141516&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Hello World - Input Form&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=&quot;processForm&quot; method=&quot;get&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;studentName&quot; placeholder=&quot;what's your name&quot; /&gt; &lt;input type=&quot;submit&quot; /&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; helloworld.jsp 1234567891011121314&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Hello world of spring!&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- EL表达式，比我学的JSP进化了一些，不用写复杂的JAVA code了--&gt; &lt;!-- Student Name: &lt;%= request.getParameter(&quot;studentName&quot;) %&gt; --&gt; Student Name: ${param.studentName} &lt;/body&gt;&lt;/html&gt; Controller进阶：Adding data to the Spring ModelSpring Model: The Model is a container for your application data In your controller You can put anything in a model strings, object, info from database, etc… 12345678910111213141516171819202122232425262728293031323334353637package com.luv2code.springdemo.mvc;import javax.servlet.http.HttpServletRequest;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class HelloWorldController { //need a controller method to show the initial HTML form @RequestMapping(&quot;/showForm&quot;) public String showForm() { return &quot;helloworld-form&quot;; } //need a controller method to process the HTML form @RequestMapping(&quot;/processForm&quot;) public String processForm() { return &quot;helloworld&quot;; } //new a controller method to read form data and add data to the model @RequestMapping(&quot;/processFormVersionTwo&quot;) public String letsShoutDude(HttpServletRequest request, Model model) { //read the request parameter from the HTML form String theName = request.getParameter(&quot;studentName&quot;); //convert data to all caps theName = theName.toUpperCase(); //create the message String result = &quot;Yo! &quot; + theName; //add message to model model.addAttribute(&quot;message&quot;, result); return &quot;helloworld&quot;; }} Your view page(JSP) can access data from model 12345678910111213&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Hello world of spring!&lt;/title&gt;&lt;/head&gt;&lt;body&gt; Student Name: ${message}&lt;/body&gt;&lt;/html&gt; Controller进阶： How do I use CSS, JavaScript and Images in a Spring MVC Web App?Here are the steps on how to access static resources in a Spring MVC. For example, you can use this to access images, css, JavaScript files etc. Any static resource is processed as a URL Mapping in Spring MVC. You can configure references to static resources in the spring-mvc-demo-servlet.xml. In my example, I’m going to have the following directory structure:I chose to put everything in the “resources” directory. But you can use any name for “resources”, such as “assets”, “foobar” etc. Also, you can give any name that you want for the subdirectories under “resources”. Step 1: Add the following entry to your Spring MVC configuration file: spring-mvc-demo-servlet.xml You can place this entry anywhere in your Spring MVC config file. &lt;mvc:resources mapping=&quot;/resources/**&quot; location=&quot;/resources/&quot;&gt;&lt;/mvc:resources&gt; Step 2: Now in your view pages, you can access the static files using this syntax: &lt;img src=&quot;${pageContext.request.contextPath}/resources/images/spring-logo.png&quot;&gt; You need to use the JSP expression ${pageContext.request.contextPath} to access the correct root directory for your web application. Apply the same technique for reading CSS and JavaScript. Here’s a full example that reads CSS, JavaScript and images. 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt; &lt;html&gt;&lt;head&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;${pageContext.request.contextPath}/resources/css/my-test.css&quot;&gt; &lt;script src=&quot;${pageContext.request.contextPath}/resources/js/simple-test.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;Spring MVC Demo - Home Page&lt;/h2&gt;&lt;a href=&quot;showForm&quot;&gt;Plain Hello World&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;img src=&quot;${pageContext.request.contextPath}/resources/images/spring-logo.png&quot; /&gt;&lt;br&gt;&lt;br&gt;&lt;input type=&quot;button&quot; onclick=&quot;doSomeWork()&quot; value=&quot;Click Me&quot;/&gt;&lt;/body&gt;&lt;/html&gt; Request Params and Request MappingBind data using @RequestParam Annotation上面我们是使用String theName = request.getParameter(&quot;studentName&quot;);，Spring提供了@RequestParam注解来直接读取request的内容并bind到我们的参数中。 12345678910@RequestMapping(&quot;/processFormVersionThree&quot;)public String processFormVersionThree(@RequestParam(&quot;studentName&quot;) String theName, Model model) { //convert data to all caps theName = theName.toUpperCase(); //create the message String result = &quot;Yo! &quot; + theName; //add message to model model.addAttribute(&quot;message&quot;, result); return &quot;helloworld&quot;;} 我们需要理解的是：这里我们是因为要对request params进行处理，所以先将request params使用@RequestParam绑定到theName变量上，再将处理后的结果放入model中让我们的前端接收到，但是其实在前端仍旧是可以使用{$param.studentName}去获取最初始的request params的，只不过拿到的是没处理过得！ Controller level Request Mapping我们可以在Controller层面添加一个Request Mapping，那么我们所有函数的Request Mapping都将相对于这个路径。 Spring MVC Form Tags and data bindingSpring MVC Form Tags are the building block for a web page. Form Tags are configurable and resuable for a web page.Spring MVC Form Tags can make use of data binding. Automatically setting/retrieving data from a Java Bean/Object. Text Fieldsstudent-form.jsp 123456789101112131415161718192021222324&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;!-- 用了这一句我们才能使用Form Tags --&gt;&lt;%@ taglib prefix=&quot;form&quot; uri=&quot;http://www.springframework.org/tags/form&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Student Registration Form&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- modelAttribute对应着我们加入model的对象的名字 --&gt; &lt;form:form action=&quot;processForm&quot; modelAttribute=&quot;student&quot;&gt; &lt;!-- path对应着对象的变量名 --&gt; First Name: &lt;form:input path=&quot;firstName&quot;/&gt; &lt;br&gt; Last Name: &lt;form:input path=&quot;lastName&quot;/&gt; &lt;br&gt; &lt;input type=&quot;submit&quot;/&gt; &lt;/form:form&gt;&lt;/body&gt;&lt;/html&gt; When form is loaded, Spring MVC will call student.getFirstName(), student.getLastName(). 也就是Spring根据modelAttribute和path去自动调用get函数。When form is submitted, Spring MVC will call student.setFirstName(), student.setLastName(). Student.java 12345678910111213141516171819package com.luv2code.springdemo.mvc;public class Student { private String firstName; private String lastName; public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; }} StudentController.java 1234567891011121314151617181920212223242526272829package com.luv2code.springdemo.mvc;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;@Controller@RequestMapping(&quot;/student&quot;)public class StudentController { @RequestMapping(&quot;/showForm&quot;) public String showForm(Model model) { //create a student object Student theStudent = new Student(); //add student object to the model //NAME VALUE model.addAttribute(&quot;student&quot;, theStudent); return &quot;student-form&quot;; } @RequestMapping(&quot;/processForm&quot;) public String processForm(@ModelAttribute(&quot;student&quot;) Student theStudent) { return &quot;student-confirmation&quot;; }} student-confirmation.jsp 1234567891011121314&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Student Confirmation&lt;/title&gt;&lt;/head&gt;&lt;body&gt; The student is confirmed: ${student.firstName} ${student.lastName} &lt;br&gt;&lt;/body&gt;&lt;/html&gt; student.firstName会call student.getFirstName()函数。 我们需要理解的是：这里我们是直接从student-form.jsp把Model传给student-confirmation.form，然后在前端我们直接使用绑定好的{$student.firstName}即可。但是request params仍旧是存在的，我们在前端仍旧可以使用{$param。firstName}来获取数据，只是为了符合MVC里的Model的概念，我们希望在Controller之间传递的是Model而不是一个又一个的参数！ Drop Down Listsstudent-form.jsp 12345678910111213141516171819202122232425262728293031323334353637&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;!-- 用了这一句我们才能使用Form Tags --&gt;&lt;%@ taglib prefix=&quot;form&quot; uri=&quot;http://www.springframework.org/tags/form&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Student Registration Form&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- modelAttribute对应着我们加入model的对象的名字 --&gt; &lt;form:form action=&quot;processForm&quot; modelAttribute=&quot;student&quot;&gt; &lt;!-- Text Fields --&gt; &lt;!-- path对应着对象的变量名 --&gt; First Name: &lt;form:input path=&quot;firstName&quot;/&gt; &lt;br&gt; Last Name: &lt;form:input path=&quot;lastName&quot;/&gt; &lt;br&gt; &lt;!-- Dropdown Lists --&gt; Country: &lt;form:select path=&quot;country&quot;&gt; &lt;!-- value是java code的值，label是在网页上显示的值 --&gt; &lt;form:option value=&quot;Brasil&quot; label=&quot;BRA&quot;&gt;&lt;/form:option&gt; &lt;form:option value=&quot;France&quot; label=&quot;Fra&quot;&gt;&lt;/form:option&gt; &lt;form:option value=&quot;Germany&quot; label=&quot;DEU&quot;&gt;&lt;/form:option&gt; &lt;form:option value=&quot;India&quot; label=&quot;INR&quot;&gt;&lt;/form:option&gt; &lt;/form:select&gt; &lt;br&gt; &lt;input type=&quot;submit&quot;/&gt; &lt;/form:form&gt;&lt;/body&gt;&lt;/html&gt; student-confirmation.jsp 1234567891011121314&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Student Confirmation&lt;/title&gt;&lt;/head&gt;&lt;body&gt; The student is confirmed: ${student.firstName} ${student.lastName} &lt;br&gt; The student's country is: ${student.country}&lt;/body&gt;&lt;/html&gt; 这种写法是吧所有的选项都在jsp里面列出来，但是在我们真正的项目中，我们往往是从数据库中读取数据然后显示一个下拉菜单。student.java 123456789101112131415161718192021222324252627282930313233343536373839404142package com.luv2code.springdemo.mvc;import java.util.LinkedHashMap;public class Student { private String firstName; private String lastName; private String country; private LinkedHashMap&lt;String, String&gt; countryOptions; public Student() { //模仿从数据库拿数据的过程 countryOptions = new LinkedHashMap&lt;String, String&gt;(); countryOptions.put(&quot;BR&quot;, &quot;Brasil&quot;); countryOptions.put(&quot;FR&quot;, &quot;France&quot;); countryOptions.put(&quot;DE&quot;, &quot;Germany&quot;); countryOptions.put(&quot;IN&quot;, &quot;India&quot;); countryOptions.put(&quot;BR&quot;, &quot;Brasil&quot;); } public LinkedHashMap&lt;String, String&gt; getCountryOptions() { return countryOptions; } public String getCountry() { return country; } public void setCountry(String country) { this.country = country; } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; }} student-form.jsp 12345678910111213141516171819202122232425262728293031323334&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;!-- 用了这一句我们才能使用Form Tags --&gt;&lt;%@ taglib prefix=&quot;form&quot; uri=&quot;http://www.springframework.org/tags/form&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Student Registration Form&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- modelAttribute对应着我们加入model的对象的名字 --&gt; &lt;form:form action=&quot;processForm&quot; modelAttribute=&quot;student&quot;&gt; &lt;!-- Text Fields --&gt; &lt;!-- path对应着对象的变量名 --&gt; First Name: &lt;form:input path=&quot;firstName&quot;/&gt; &lt;br&gt; Last Name: &lt;form:input path=&quot;lastName&quot;/&gt; &lt;br&gt; &lt;!-- Dropdown Lists --&gt; Country: &lt;form:select path=&quot;country&quot;&gt; &lt;!-- items指向的是java中的一个collection。Spring会call student.getCountryOptions() --&gt; &lt;form:options items=&quot;${student.countryOptions}&quot;/&gt; &lt;/form:select&gt; &lt;br&gt; &lt;input type=&quot;submit&quot;/&gt; &lt;/form:form&gt;&lt;/body&gt;&lt;/html&gt; Radio buttons 1234567&lt;!-- Radio Buttons --&gt;Favorite Languages:Java&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;Java&quot;/&gt;C#&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;C#&quot;/&gt;PHP&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;JaPHPva&quot;/&gt;Ruby&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;Ruby&quot;/&gt;&lt;br&gt; 当我们提交form的时候，会call setFavoriteLanguage()函数。在student-confirmation.jsp页面中的${student.favoriteLanguage}会call student.getFavoriteLanguage()。 Ckeckboxesstudent-form.jsp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;!-- 用了这一句我们才能使用Form Tags --&gt;&lt;%@ taglib prefix=&quot;form&quot; uri=&quot;http://www.springframework.org/tags/form&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Student Registration Form&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- modelAttribute对应着我们加入model的对象的名字 --&gt; &lt;form:form action=&quot;processForm&quot; modelAttribute=&quot;student&quot; method=&quot;post&quot;&gt; &lt;!-- Text Fields --&gt; &lt;!-- path对应着对象的变量名 --&gt; First Name: &lt;form:input path=&quot;firstName&quot;/&gt; &lt;br&gt; Last Name: &lt;form:input path=&quot;lastName&quot;/&gt; &lt;br&gt; &lt;!-- Dropdown Lists --&gt; Country: &lt;form:select path=&quot;country&quot;&gt; &lt;!-- items指向的是java中的一个collection。Spring会call student.getCountryOptions() --&gt; &lt;form:options items=&quot;${student.countryOptions}&quot;/&gt; &lt;/form:select&gt; &lt;br&gt; &lt;!-- Radio Buttons --&gt; Favorite Languages: Java&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;Java&quot;/&gt; C#&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;C#&quot;/&gt; PHP&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;JaPHPva&quot;/&gt; Ruby&lt;form:radiobutton path=&quot;favoriteLanguage&quot; value=&quot;Ruby&quot;/&gt; &lt;br&gt; &lt;!-- checkbox --&gt; Operating Systems: linux&lt;form:checkbox path=&quot;operatingSystems&quot; value=&quot;linux&quot; /&gt; mac&lt;form:checkbox path=&quot;operatingSystems&quot; value=&quot;mac&quot; /&gt; windows&lt;form:checkbox path=&quot;operatingSystems&quot; value=&quot;windows&quot; /&gt; &lt;br&gt; &lt;input type=&quot;submit&quot;/&gt; &lt;/form:form&gt;&lt;/body&gt;&lt;/html&gt; Student.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.luv2code.springdemo.mvc;import java.util.LinkedHashMap;public class Student { private String firstName; private String lastName; private String country; private String favoriteLanguage; private String[] operatingSystems; public String[] getOperatingSystems() { return operatingSystems; } public void setOperatingSystems(String[] operatingSystems) { this.operatingSystems = operatingSystems; } public String getFavoriteLanguage() { return favoriteLanguage; } public void setFavoriteLanguage(String favoriteLanguage) { this.favoriteLanguage = favoriteLanguage; } private LinkedHashMap&lt;String, String&gt; countryOptions; public Student() { //模仿从数据库拿数据的过程 countryOptions = new LinkedHashMap&lt;String, String&gt;(); countryOptions.put(&quot;BR&quot;, &quot;Brasil&quot;); countryOptions.put(&quot;FR&quot;, &quot;France&quot;); countryOptions.put(&quot;DE&quot;, &quot;Germany&quot;); countryOptions.put(&quot;IN&quot;, &quot;India&quot;); countryOptions.put(&quot;BR&quot;, &quot;Brasil&quot;); } public LinkedHashMap&lt;String, String&gt; getCountryOptions() { return countryOptions; } public String getCountry() { return country; } public void setCountry(String country) { this.country = country; } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; }} 由于checkboxes可以选多个，所以这里是数组。 student-confirmation.jsp 123456789101112131415161718192021222324252627&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!-- 使用jstl，这样我们才能使用for loop --&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Student Confirmation&lt;/title&gt;&lt;/head&gt;&lt;body&gt; The student is confirmed: ${student.firstName} ${student.lastName} &lt;br&gt; The student's country is: ${student.country} &lt;br&gt; Favorite Language is: ${student.favoriteLanguage} &lt;br&gt; Operating Systems is: &lt;ul&gt; &lt;!-- jstl --&gt; &lt;c:forEach var=&quot;temp&quot; items=&quot;${student.operatingSystems}&quot;&gt; &lt;li&gt;${temp}&lt;/li&gt; &lt;/c:forEach&gt; &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 使用jstl去做for loop。 Form ValidationJava’s Standard Bean Validation API: Java has a standard Bean validation API defines a metadata model and API for entity validation not tied to either the web tier or the persistence tier available for server-side apps and also client-side JavaFX/Swing apps Spring and validation Spring version 4 and higher supports Beans Validation API Preferred method for validation when building Spring apps Simply add Validation JARs to our project Validation features include: required, validate length， validate numbers, validate with regular expressions, custom validation 我们使用的Validation JAR是Hibernate Team开发的。https://hibernate.org/validator/ Validate Required Fields开发流程： Add validation rule to Customer class Customer.java 12345678910111213141516171819202122232425package com.luv2code.springdemo.mvc;import javax.validation.constraints.NotNull;import javax.validation.constraints.Size;public class Customer { private String firstName; @NotNull(message = &quot;is required&quot;) @Size(min=1) private String lastName; public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; }} Display error messages on HTML form customer-form.jsp 123456789101112131415161718192021222324252627&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;form&quot; uri=&quot;http://www.springframework.org/tags/form&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Customer Register page&lt;/title&gt;&lt;style type=&quot;text/css&quot;&gt; .error {color:red}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;Fill out the form. * means required. &lt;form:form action=&quot;processForm&quot; modelAttribute=&quot;customer&quot;&gt; First Name: &lt;form:input path=&quot;firstName&quot; /&gt; &lt;br&gt; Last Name (*): &lt;form:input path=&quot;lastName&quot; /&gt; &lt;form:errors path=&quot;lastName&quot; cssClass=&quot;error&quot; /&gt; &lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt; &lt;/form:form&gt;&lt;/body&gt;&lt;/html&gt; Perform validation in the Controller class ConstomerContoller.java 12345678910111213141516171819202122232425262728293031package com.luv2code.springdemo.mvc;import javax.validation.Valid;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.validation.BindingResult;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;@Controller@RequestMapping(&quot;/customer&quot;)public class CustomerController { @RequestMapping(&quot;/showForm&quot;) public String showForm(Model model) { model.addAttribute(&quot;customer&quot;, new Customer()); return &quot;customer-form&quot;; } @RequestMapping(&quot;/processForm&quot;) public String processForm(@Valid @ModelAttribute Customer theCustomer, BindingResult bindingResult) { if(bindingResult.hasErrors()) { return &quot;customer-form&quot;; } else { return &quot;customer-confirmation&quot;; } } } @Valid注解可以判断Validation是否符合并可以在后面跟一个BindingResult参数。 Update confirmation page cutomer-confirmation.jsp 1234567891011121314&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt; &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;Customer Confirmation Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt; The customer is confirmed: ${customer.firstName} ${customer.lastName}&lt;/body&gt;&lt;/html&gt; 现在还有一个问题是如果我们的lastName是whitespaces时，我们的validation不能检测到。我们采用的方法是使用@InitBinder，它的作用是pre-process each web request to our controller. 1234567// add an initbinder// remove leading and trailing whitespace@InitBinderpublic void InitBinder(WebDataBinder dataBinder) { StringTrimmerEditor stringTrimmerEditor = new StringTrimmerEditor(true); dataBinder.registerCustomEditor(StringTrimmerEditor.class, stringTrimmerEditor);} StringTrimmerEditor类会帮我们去掉leading和trailing whitespace，去掉以后还会检查输入是不是长度为零，为零的话会将其变为null。 Validate Number Range 开发流程： Add validation rule to Customer class Customer.java 12345678910@Min(value=0, message = &quot;must be greater or equal to 0&quot;)@Max(value=10, message = &quot;must be less or equal to 10&quot;)private int freePasses;public int getFreePasses() { return freePasses;}public void setFreePasses(int freePasses) { this.freePasses = freePasses;} Display error messages on HTML form customer-form.jsp 123Free Passes: &lt;form:input path=&quot;freePasses&quot; /&gt;&lt;form:errors path=&quot;freePasses&quot; cssClass=&quot;error&quot; &gt;&lt;/form:errors&gt;&lt;br&gt; Perform validation in the Controller class这一步不用改了，就是@Valid注解 Update confirmation page 如果我们还想要freePasses非空，那么我们可以加入@notNull注解，但是错误信息显示int是不能处理not null的，所以我们将其转换为Integer。但这个时候我们如果再输入一大堆String，错误信息会是”不能将String转为Integer”。我们的解决办法是加入custom error message。（https://www.udemy.com/course/spring-hibernate-tutorial/learn/lecture/6747542#questions） Validation with regular expression 开发流程： Add validation rule to Customer class Customer.java 123456789@Pattern(regexp = &quot;[a-zA-Z0-9]{5}&quot;, message = &quot;only 5 chars/digits&quot;)private String postalCode;public String getPostalCode() { return postalCode;}public void setPostalCode(String postalCode) { this.postalCode = postalCode;} Display error messages on HTML form customer-form.jsp 123Postal Code: &lt;form:input path=&quot;postalCode&quot; /&gt;&lt;form:errors path=&quot;postalCode&quot; cssClass=&quot;error&quot; &gt;&lt;/form:errors&gt;&lt;br&gt; Perform validation in the Controller class这一步不用改了，就是@Valid注解和BindingReasult Update confirmation page Custom Validation(A Custom Annotation)为我们的coursecode定制一个validation：前缀必须为luv开发流程 Create custom validation rule Create @CourceCode annotation CourseCode.java 123456789101112131415161718192021222324package com.luv2code.springdemo.mvc.validation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import javax.validation.Constraint;import javax.validation.Payload;@Constraint(validatedBy = CourseCodeConstrainValidator.class) //helper class that contains business rules/validation logic@Target({ElementType.METHOD, ElementType.FIELD}) //can apply our annotation to a method or field@Retention(RetentionPolicy.RUNTIME) //Retain this annotation in the Java class file. Process it at runtimepublic @interface CourceCode { //define default course code public String value() default &quot;LUV&quot;; //define default error message public String message() default &quot;Must start with LUV&quot;; //define default groups public Class&lt;?&gt;[] groups() default {}; //define default payload public Class&lt;? extends Payload&gt;[] payload() default {};} Create CourseCodeConstraintValidator CourseCodeConstrainValidator.class 12345678910111213141516171819202122232425262728package com.luv2code.springdemo.mvc.validation;import javax.validation.ConstraintValidator;import javax.validation.ConstraintValidatorContext;public class CourseCodeConstrainValidator implements ConstraintValidator&lt;CourseCode, String&gt;{ private String coursePrefix; @Override public void initialize(CourseCode theCourseCode) { coursePrefix = theCourseCode.value(); } @Override public boolean isValid(String theCode, ConstraintValidatorContext constraintValidatorContext) { boolean result; if(theCode!=null) { result = theCode.startsWith(coursePrefix); } else { result = true; } return result; } } Add validation rule to Customer Class Customer.java 123456789@CourseCode(value = &quot;luv&quot;, message=&quot;must start with luv&quot; )private String courseCode;public String getCourseCode() { return courseCode;}public void setCourseCode(String courseCode) { this.courseCode = courseCode;} Display error messages on HTML form customer-form.jsp 123Course Code: &lt;form:input path=&quot;courseCode&quot; /&gt;&lt;form:errors path=&quot;courseCode&quot; cssClass=&quot;error&quot; &gt;&lt;/form:errors&gt;&lt;br&gt; Update confirmation page Bonus: Deploying your App to Tomcat as a Web Application Archive (WAR) file**When you deploy your Java web apps, you can make use of a Web Application Archive (WAR) file. The Web Application Archive (WAR) file is a compressed version of your web application. It uses the zip file format but the file has the .war extension. If you are using Eclipse, then the best way to visualize it is think of your “WebContent” directory being compressed as a zip file with the .war extension. This includes all of your web pages, images, css etc. It also includes the WEB-INF directory which includes your classes in WEB-INF/classes and supporting JAR files in WEB-INF/lib. The WAR file format is part of the Java EE / Servlet specification. As a result, all Java EE servers support this format (ie jboss, weblogic, websphere, glassfish and tomcat). Below, I provide steps on how to create a WAR file in Eclipse. I also show how to deploy the WAR file on Tomcat. In Eclipse, stop Tomcat Right-click your project and select Export &gt; WAR File In the Destination field, enter: /mycoolapp.war Outside of Eclipse, start Tomcat If you are using MS Windows, then you should find it on the Start menu Make sure Tomcat is up and running by visiting: http://localhost:8080 Deploy your new WAR file by copying it to \\webapps Give it about 10-15 seconds to make the deployment. You’ll know the deployment is over because you’ll see a new folder created in webapps … with your WAR file name. Visit your new app. If your war file was: mycoolapp.war then you can access it with: http://localhost:8080/mycoolapp/ HibernateHibernate is a framework for persisting/saving Java Objects in a database. Benefits of Hibernate: 1. Hibernate handles all of the low-level SQL 2. Minimizes the amount of JDBC code you have to develop 3.Hibernate provides the Object-to-Relational Mapping(ORM) JDBC(Java Database Connection)是Java web程序连接数据库的时候使用的库文件，但是它的问题是需要手动写SQL语句。Hibernate是建立在JDBC上的ORM框架，本质上还是使用JDBC，只不过帮我们做好了封装。 开发Hibernate需要的其他库：1.JDK 2.Database Server(MySQL) 3.Hibernate JAR files and JDBC driver. Configuration Add Hibernate Configuration file hibernate.cfg.xml 1234567891011121314151617181920212223242526272829&lt;!DOCTYPE hibernate-configuration PUBLIC &quot;-//Hibernate/Hibernate Configuration DTD 3.0//EN&quot; &quot;http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd&quot;&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- JDBC Database connection settings --&gt; &lt;property name=&quot;connection.driver_class&quot;&gt;com.mysql.cj.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;connection.url&quot;&gt;jdbc:mysql://localhost:3306/hb_student_tracker?useSSL=false&amp;amp;serverTimezone=UTC&lt;/property&gt; &lt;property name=&quot;connection.username&quot;&gt;hbstudent&lt;/property&gt; &lt;property name=&quot;connection.password&quot;&gt;hbstudent&lt;/property&gt; &lt;!-- JDBC connection pool settings ... using built-in test pool --&gt; &lt;property name=&quot;connection.pool_size&quot;&gt;1&lt;/property&gt; &lt;!-- Select our SQL dialect --&gt; &lt;property name=&quot;dialect&quot;&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- Echo the SQL to stdout --&gt; &lt;property name=&quot;show_sql&quot;&gt;true&lt;/property&gt; &lt;!-- Set the current session context --&gt; &lt;property name=&quot;current_session_context_class&quot;&gt;thread&lt;/property&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; Annotate Java Class Map class to database Map fields to database columns 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.luv2code.hibernate.demo.entity;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;import javax.persistence.Table;@Entity@Table(name=&quot;student&quot;)public class Student { @Id @GeneratedValue(strategy=GenerationType.IDENTITY) @Column(name=&quot;id&quot;) private int id; @Column(name=&quot;first_name&quot;) private String firstName; @Column(name=&quot;last_name&quot;) private String lastName; @Column(name=&quot;email&quot;) private String email; public Student() { } public Student(String firstName, String lastName, String email) { super(); this.firstName = firstName; this.lastName = lastName; this.email = email; } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getFirstName() { return firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } public String getLastName() { return lastName; } public void setLastName(String lastName) { this.lastName = lastName; } public String getEmail() { return email; } public void setEmail(String email) { this.email = email; } //for debug @Override public String toString() { return &quot;Student [id=&quot; + id + &quot;, firstName=&quot; + firstName + &quot;, lastName=&quot; + lastName + &quot;, email=&quot; + email + &quot;]&quot;; }} Why we are using JPA Annotation instead of Hibernate ? For example, why we are not using this org.hibernate.annotations.Entity? ANSWER:JPA is a standard specification. Hibernate is an implementation of the JPA specification. Hibernate implements all of the JPA annotations. The Hibernate team recommends the use of JPA annotations as a best practice. Hibernate CRUDTwo Key Players: - SessionFactory - Reads the hibernate config file - Creates Session objects - Heavy-weight object - Only create once in your app - Session - Wraps a JDBC connection - Main object used to save/retrieve objects - Short-lived object - Retrieve from session-factory Create Object 1234567891011121314151617181920212223242526272829303132333435363738package com.luv2code.hibernate.demo;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration;import com.luv2code.hibernate.demo.entity.Student;public class CreateStudentDemo { public static void main(String[] args) { //create session factory SessionFactory factory = new Configuration() .configure(&quot;hibernate.cfg.xml&quot;) .addAnnotatedClass(Student.class) .buildSessionFactory(); //create a session Session session = factory.getCurrentSession(); //use the session object to save Java Object try { //Create a student object System.out.println(&quot;Creating a new student object&quot;); Student newStudent = new Student(&quot;shiyu&quot;, &quot;liu&quot;, &quot;shiyuliucu@gmail.com&quot;); //Start a transaction session.beginTransaction(); //Save the student object System.out.println(&quot;Saving the student...&quot;); session.save(newStudent); //Commit transaction session.getTransaction().commit(); } catch (Exception e) { factory.close(); } }} Read ObjectsStudent myStudent = session.get(Student.class, newStudent.getId()); Query ObjectsHibernate使用HQL进行query，其实就是SQL。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.luv2code.hibernate.demo;import java.util.List;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration;import com.luv2code.hibernate.demo.entity.Student;public class QueryStudentDemo { public static void main(String[] args) { //create session factory SessionFactory factory = new Configuration() .configure(&quot;hibernate.cfg.xml&quot;) .addAnnotatedClass(Student.class) .buildSessionFactory(); //create a session Session session = factory.getCurrentSession(); //use the session object to save Java Object try { //Start a transaction session.beginTransaction(); //query students //这里from Student的Student是类的名字 List&lt;Student&gt; theStudents = session.createQuery(&quot;from Student&quot;).getResultList(); //display students for(Student s:theStudents) { System.out.println(s); } //query students: lastName=&quot;liu&quot; //use Java property name, not database column name theStudents = session.createQuery(&quot;from Student s where s.lastName='liu' &quot;).getResultList(); //display students for(Student s:theStudents) { System.out.println(s); } //query students: lastName=&quot;liu&quot; or fistName=&quot;amy&quot; theStudents = session.createQuery(&quot;from Student s where s.lastName='liu' OR s.firstName='amy' &quot;).getResultList(); //display students for(Student s:theStudents) { System.out.println(s); } //query students where email like %qq.com&quot; theStudents = session.createQuery(&quot;from Student s where s.email LIKE '%qq.com' &quot;).getResultList(); //display students for(Student s:theStudents) { System.out.println(s); } //Commit transaction session.getTransaction().commit(); } catch (Exception e) { factory.close(); } }} Update Objects 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.luv2code.hibernate.demo;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration;import com.luv2code.hibernate.demo.entity.Student;public class UpdateStudentDemo { public static void main(String[] args) { //create session factory SessionFactory factory = new Configuration() .configure(&quot;hibernate.cfg.xml&quot;) .addAnnotatedClass(Student.class) .buildSessionFactory(); //create a session Session session = factory.getCurrentSession(); //use the session object to save Java Object try { session.beginTransaction(); int studentId = 1; Student theStudent = session.get(Student.class, studentId); //update the firstName where id==1 theStudent.setFirstName(&quot;Cindy&quot;); session.getTransaction().commit(); //update all student email with liushiyu@gmail session = factory.getCurrentSession(); session.beginTransaction(); session.createQuery(&quot;UPDATE Student SET email='liushiyu@gmail' &quot;).executeUpdate(); session.getTransaction().commit(); } catch (Exception e) { factory.close(); } }} Delete Objects 1234567891011121314151617181920212223242526272829303132333435363738394041package com.luv2code.hibernate.demo;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration;import com.luv2code.hibernate.demo.entity.Student;public class DeleteStudentDemo { public static void main(String[] args) { //create session factory SessionFactory factory = new Configuration() .configure(&quot;hibernate.cfg.xml&quot;) .addAnnotatedClass(Student.class) .buildSessionFactory(); //create a session Session session = factory.getCurrentSession(); //use the session object to save Java Object try { session.beginTransaction(); int studentId = 1; Student theStudent = session.get(Student.class, studentId); //delete the student where id==1 session.delete(theStudent); session.getTransaction().commit(); //delete student where id==2 session = factory.getCurrentSession(); session.beginTransaction(); session.createQuery(&quot;DELETE from Student WHERE id=2 &quot;).executeUpdate(); session.getTransaction().commit(); } catch (Exception e) { factory.close(); } }} SpringMVC + HibernateConfiguration Define database datasource/connection pool Setup Hibernate session factory Setup Hibernate transaction manager Enable configuration of transactional annotations123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!-- Add support for component scanning --&gt; &lt;context:component-scan base-package=&quot;com.luv2code.springdemo&quot; /&gt; &lt;!-- Add support for conversion, formatting and validation support --&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- Define Spring MVC view resolver --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/view/&quot; /&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt; &lt;/bean&gt; &lt;!-- Step 1: Define Database DataSource / connection pool --&gt; &lt;bean id=&quot;myDataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot; /&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/web_customer_tracker?useSSL=false&amp;amp;serverTimezone=UTC&quot; /&gt; &lt;property name=&quot;user&quot; value=&quot;springstudent&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;springstudent&quot; /&gt; &lt;!-- these are connection pool properties for C3P0 --&gt; &lt;property name=&quot;minPoolSize&quot; value=&quot;5&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;20&quot; /&gt; &lt;property name=&quot;maxIdleTime&quot; value=&quot;30000&quot; /&gt; &lt;/bean&gt; &lt;!-- Step 2: Setup Hibernate session factory --&gt; &lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate5.LocalSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;myDataSource&quot; /&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.luv2code.springdemo.entity&quot; /&gt; &lt;property name=&quot;hibernateProperties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQLDialect&lt;/prop&gt; &lt;prop key=&quot;hibernate.show_sql&quot;&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- Step 3: Setup Hibernate transaction manager --&gt; &lt;bean id=&quot;myTransactionManager&quot; class=&quot;org.springframework.orm.hibernate5.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot;/&gt; &lt;/bean&gt; &lt;!-- Step 4: Enable configuration of transactional behavior based on annotations --&gt; &lt;tx:annotation-driven transaction-manager=&quot;myTransactionManager&quot; /&gt;&lt;/beans&gt; DAOData Access Object: Responsible for interfacing with the database This is a common design pattern: DAO 由于我们已经xml中设置了&lt;property name=&quot;packagesToScan&quot; value=&quot;com.luv2code.springdemo.entity&quot; /&gt;，所以我们不需要像在普通的Hibernate项目中那样手动说明Entity Class(Java中与数据库一一对应的类叫做Entity Class): SessionFactory factory = new Configuration().configure(&quot;hibernate.cfg.xml&quot;).addAnnotatedClass(Student.class).buildSessionFactory();。Spring会自动去扫描@Entity。 DAO层需要SessionFactory，SessionFactory需要DataSource，这俩都是dependency，我们可以使用依赖注入。DataSource已经被自动注入好了，我们xml配置中有&lt;property name=&quot;dataSource&quot; ref=&quot;myDataSource&quot; /&gt;，这是setter injection，所以如果我们去看org.springframework.orm.hibernate5.LocalSessionFactoryBean的源码的话就会发现它实现了setter injection。https://github.com/spring-projects/spring-framework/blob/master/spring-orm/src/main/java/org/springframework/orm/hibernate5/LocalSessionFactoryBean.java 接下来需要做的就是：1.Define DAO interfaceCustomerDAO.java 123456789package com.luv2code.springdemo.dao;import java.util.List;import com.luv2code.springdemo.entity.Customer;public interface CustomerDAO { public List&lt;Customer&gt; getCustomers();} Define DAO implementation(inject the session factory)Spring @Transactional: Automatically begin and end a trasaction for your Hibernate code, no need for you to explicitly do this in your code.(The Spring magic happens behind the scenes)Spring @Repository: 我们之前已经见过@Controller，这里我们的DAO implementation需要使用@Repository。It will automatically register DAO implementation(Component auto-scanning) and also provide translation of any JDBC related exceptions. CustomerDAOImpl 1234567891011121314151617181920212223242526272829303132333435package com.luv2code.springdemo.dao;import java.util.List;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.query.Query;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Repository;import org.springframework.transaction.annotation.Transactional;import com.luv2code.springdemo.entity.Customer;@Repositorypublic class CustomerDAOImpl implements CustomerDAO { //need to inject the session factory @Autowired private SessionFactory sessionFactory; @Override @Transactional public List&lt;Customer&gt; getCustomers() { //get current hibernate session Session currentSession = sessionFactory.getCurrentSession(); //create a query Query&lt;Customer&gt; theQuery = currentSession.createQuery(&quot;from Customer&quot;, Customer.class); //execute query and get result list List&lt;Customer&gt; customers = theQuery.getResultList(); //return the result return customers; }} Inject DAO into Controller CustomerController.java 12345678910111213141516171819202122232425262728293031package com.luv2code.springdemo.controller;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import com.luv2code.springdemo.dao.CustomerDAO;import com.luv2code.springdemo.entity.Customer;@Controller@RequestMapping(&quot;/customer&quot;)public class CustomerController { //need to inject the customer DAO @Autowired private CustomerDAO customerDAO; @GetMapping(&quot;/list&quot;) public String listCustomers(Model model) { //get customers form dao List&lt;Customer&gt; customers = customerDAO.getCustomers(); //add the customers to the model model.addAttribute(&quot;customers&quot;, customers); return &quot;list-customers&quot;; }} Adding CSS开发流程： Place CSS in a “resourses” directory Configure Spring to serve up “resources” directory spring-mvc-crud-demo-servlet.xml 12&lt;!-- Add support for reading web resources : css, images, js, etc --&gt;&lt;mvc:resources location=&quot;/resources/&quot; mapping=&quot;/resources/**&quot;&gt;&lt;/mvc:resources&gt; 这里mapping=&quot;/resources/**&quot;中的**的意思是recursively的去subfolder里寻找资源文件。3. Reference CSS in your JSP 1&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;${pageContext.request.contextPath}/resources/css/style.css&quot; /&gt; Refactor: Add a service layerPurpose of Service Layer Service Facade design pattern Intermediate layer for customer business logic Integrate data from mutiple sources(DAO/repositories) 我们已经使用过@Controller和@Repository，分别用于Controller层和DAO层。Service我们使用的是@Service。这三个Annotation都继承与@Component，所以也都会被自动扫描。 开发流程： Define Service interface Define Service implementation：这里我们要把DAO注入到Service层，再把Service层注入到Controller层。同时我们把@Transational注解改到Service层去。 CustomerServiceImpl.java 123456789101112131415161718192021package com.luv2code.springdemo.service;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import com.luv2code.springdemo.dao.CustomerDAO;import com.luv2code.springdemo.entity.Customer;@Servicepublic class CustomerServiceImpl implements CustomerService { @Autowired private CustomerDAO customerDAO; @Override @Transactional //define transaction in service layer public List&lt;Customer&gt; getCustomers() { return customerDAO.getCustomers(); }} CustomerDAOImpl 123456789101112131415161718192021222324252627282930313233package com.luv2code.springdemo.dao;import java.util.List;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.query.Query;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Repository;import org.springframework.transaction.annotation.Transactional;import com.luv2code.springdemo.entity.Customer;@Repositorypublic class CustomerDAOImpl implements CustomerDAO { //need to inject the session factory @Autowired private SessionFactory sessionFactory; @Override public List&lt;Customer&gt; getCustomers() { //get current hibernate session Session currentSession = sessionFactory.getCurrentSession(); //create a query Query&lt;Customer&gt; theQuery = currentSession.createQuery(&quot;from Customer&quot;, Customer.class); //execute query and get result list List&lt;Customer&gt; customers = theQuery.getResultList(); //return the result return customers; }} 所以总结一下，Controller层负责接收浏览器的GET/POST请求，DAO层负责与数据库交互获取数据，Service层负责处理从DAO层拿到的数据，处理结束后传回Controller层。","link":"/2020/03/30/Backend/Spring/"},{"title":"java web发展史与java学习路线","text":"最近在准备学spring和spring boot，但是又看到servelet什么的很困惑，所以了解了以下java web的发展。同时也看到一个很好的java学习路线图。https://www.jianshu.com/p/bec6736dcc3dhttps://www.tianmaying.com/tutorial/web-historyhttps://www.runoob.com/servlet/servlet-intro.htmlhttps://www.runoob.com/jsp/jsp-intro.html Web开发技术发展历史Web的诞生提到Web，不得不提一个词就是“互联网”。Web是World Wide Web的简称，中文译为万维网。“万维网”和我们经常说的“互联网”是两个联系极其紧密但却不尽相同的概念。今天“互联网”三个字已经承载了太多的内涵，提到互联网，我们通常想到的一种战略思维，或者是一种颠覆传统的商业模式。抛开那些纷繁凌乱的商业化概念，回归技术本身，互联网就是指通过TCP/IP协议族互相连接在一起的计算机网络。而Web是运行在互联网上的一个超大规模的分布式系统。Web设计初衷是一个静态信息资源发布媒介，通过超文本标记语言（HTML）描述信息资源，通过统一资源标识符（URI）定位信息资源，通过超文本转移协议（HTTP）请求信息资源。HTML、URL和HTTP三个规范构成了Web的核心体系结构，是支撑着Web运行的基石。用通俗的一点的话来说，客户端（一般为浏览器）通过URL找到网站(如www.google.com)，发出HTTP请求，服务器收到请求后返回HTML页面。可见，Web是基于TCP/IP协议的，TCP/IP协议把计算机连接在一起，而Web在这个协议族之上，进一步将计算机的信息资源连接在一起，形成我们说的万维网。大家开发的Web应用本质上就是可以提供信息或者功能的Web资源，成为Web这个全球超大规模分布式系统中的一部分。在技术层面进一步理解Web和互联网，建议找一本计算机网络的书去看看，了解一下计算机网络的分层结构和发展历史。 1991年8月6日，Tim Berners Lee在alt.hypertext新闻组贴出了一份关于World Wide Web的简单摘要，标志了Web页面在Internet上的首次登场。最早Web主要被一帮科学家们用来共享和传递信息，全世界的Web服务器也就几十台。第一个Web浏览器是Berners Lee在NeXT机器上实现，也只能跑在NeXT机器上，苹果和乔布斯的粉丝对NeXT的历史肯定耳熟能详。真正使得Web开始流行起来的是Mosaic浏览器，这便是曾经大名鼎鼎的Netscape Navigator的前身。Berners Lee在1993年建立了万维网联盟（World Wide Web Consortium，W3C），负责Web相关标准的制定。浏览器的普及和W3C的推动，使得Web上可以访问的资源逐渐丰富起来。这个时候Web的主要功能就是浏览器向服务器请求静态HTML信息。95年的时候马云在美国看到了互联网，更准确的说他其实看到的就是Web，阿里早先做的黄页也就是把企业信息通过进行HTML展示的Web应用。 动态内容的出现：CGI最初在浏览器中主要展现的是静态的文本或图像信息，GIF图片则第一次为HTML页面引入了动态元素。不过人们已经不仅仅满足于访问放在Web服务器上的静态文件，1993年CGI（Common Gateway Interface）出现了，Web上的动态信息服务开始蓬勃兴起。CGI定义了Web服务器与外部应用程序之间的通信接口标准，因此Web服务器可以通过CGI执行外部程序，让外部程序根据Web请求内容生成动态的内容。Perl因为跨操作系统和易于修改的特性成为CGI的主要编写语言。当然，CGI可以用任何支持标准输入输出和环境变量的语言编写，比如Shell脚本,C/C++语言，只要符合接口标准即可。比如你用C语言编写CGI程序，你把希望返回的HTML内容通过printf输出就可以发送给Web服务器，进而返回给用户。 Web编程脚本语言：PHP/ASP/JSP这个时候我们已经可以在Web上提供动态功能了，比如网站访问的计数，表单的处理。CGI对每个请求都会启动一个进程来处理，因此性能上的扩展性不高。另外，想象一下用在Perl和C语言中的程序中去输出一大堆复杂的HTML字符串，是不是有点蛋疼，可读性和维护性是个大问题。为了处理更复杂的应用，一种方法是把HTML返回中固定的部分存起来（我们称之为模版），把动态的部分标记出来，Web请求处理的时候，你的程序先生成那部分动态的内容，再把模版读入进来，把动态内容填充进去，形成最终返回。举个例子，搜索一个关键词，搜索引擎的Web服务器可以先从后台索引服务器里拿到数据，然后把这些数据填充到返回结果的HTML模版中，返回给浏览器。但是这件事情自己来做显然太繁琐而且是重复劳动。于是1994年的时候，PHP诞生了，PHP可以把程序（动态内容）嵌入到HTML（模版）中去执行，不仅能更好的组织Web应用的内容，而且执行效率比CGI还更高。之后96年出现的ASP和98年出现的JSP本质上也都可以看成是一种支持某种脚本语言编程（分别是VB和Java）的模版引擎。96年W3C发布了CSS1.0规范。CSS允许开发者用外联的样式表来取代难以维护的内嵌样式，而不需要逐个去修改HTML元素，这让HTML页面更加容易创建和维护。此时，有了这些脚本语言，搭配上后端的数据库技术，Web更是开始大杀四方了，像电子商务这样的应用系统也可以通过Web技术来构建。Web已经从一个静态资源分享媒介真正变为了一个分布式的计算平台了。反过来看，你也应该知道，不是只有当今这些流行脚本语言可以写Web应用，C语言一样可以做这件事情。前面举的搜索引擎通过C语言来获取数据和渲染Web页面的例子在追求极致访问速度的互联网公司是非常常见的，但是脚本语言在开发效率上更胜一筹。 分布式企业计算平台：J2EE/.NetWeb开始广泛用于构建大型应用时，在分布式、安全性、事务性等方面的要求催生了J2EE(现在已更名为Java EE)平台在1999年的诞生，从那时开始为企业应用提供支撑平台的各种应用服务器也开始大行其道。Java Servlet、Java Server Pages (JSP)和Enterprise Java Bean (EJB )是Java EE中的核心规范，Servlet和JSP是运行在服务器端的Web组件，EJB运行在服务器端的业务组件，是一种分布式组件技术。2000年随之而来的.net平台，其ASP.net构件化的Web开发方式以及Visual Stidio.net开发环境的强大支持，大大降低了开发企业应用的复杂度。ASP.Net第一次让程序员可以像拖拽组件来创建Windows Form程序那样来组件化地创建Web页面，Java平台后来出现的JSF也承袭了这一思想。两大平台在相互竞争和模仿中不断向前发展。 框架横飞的年代：MVC，ORM两大平台诞生之后，组件化编程技术盛极一时，Web技术的发展开始了一段框架横飞的年代，各种辅助Web开发的技术框架层出不穷。虽然脚本语言大大提高了应用开发效率，但是试想一个复杂的大型Web应用，访问各种功能的URL地址纷繁复杂，涉及到的Web页面多种多样，同时还管理着大量的后台数据，因此我们需要在架构层面上解决维护性和扩展性等问题。这个时候，MVC的概念被引入到Web开发中来了。2004年出现的Struts就是当时非常流行的Java Web开发的MVC框架。MVC早在1978年就作为Smalltalk的一种设计模式被提出来了，应用到Web应用上，模型Model用于封装与业务逻辑相关的数据和数据处理方法，视图View是数据的HTML展现，控制器Controller负责响应请求，协调Model和View。Model，View和Controller的分开，是一种典型的关注点分离的思想，不仅使得代码复用性和组织性更好，使得Web应用的配置性和灵活性更好。这是Spring MVC的示意图，典型的MVC架构。 此外，数据访问也逐渐通过面向对象的方式来替代直接的SQL访问，出现了ORM（Object Relation Mapping）的概念，2001年出现的Hibernate就是其中的佼佼者，已经成为Java持久层的规范JPA的主要参考和实现。更多的全栈框架开始出现，比如2003年出现的Java开发框架Spring，同时更多的动态语言也被加入到Web编程语言的阵营中，2004年出现的Ruby开发框架Rails，2005出现的Python开发框架Django，都提供了全栈开发框架，或者自身提供Web开发的各种组件，或者可以方便的集成各种组件。比如Spring基于IoC和AOP思想可以方便得整合出全套Web开发组件，SSH（Struts+Spring+Hibernate）一度成为Java Web开发的标配。值得一提的时Rails这个MVC框架，26岁的丹麦大神David Heinemeier Hansson在开发著名项目管理软件BaseCamp的过程中形成，Ruby语言本身在快速开发上的优势，加上Rails诸如崇尚DRY（Don’t）Repeat Yourself)原则, 约定优于配置，拥抱REST等特性，使其迅速成为一个极其流行的Web开发框架。 回归Web本质：REST注意，看到这里的时候，你会发现Web开发的重点已经不在于HTTP/HTML/URL这样的Web基础架构了，而是各种平台下的各种框架和组件技术（MVC/ORM/分布式组件技术等等）。所以今天很多人可能会用一个MVC框架构建Web网站，但是可能并不了解Web本身。2000年的时候，Roy Fielding在他的博士论文中从构架风格的角度来剖析了Web本身，将Web内在的设计原则和思路系统得论述出来。Roy Fielding是HTTP协议的主要设计者，也是Apache服务器项目的联合创始人，他的这篇博士论文提出来的REST（Representation State Transformation）也成为一种流行的Web架构风格。REST鼓励基于URL来组织系统功能，充分利用HTTP本身的语义，而不是仅仅将HTTP作为一种远程数据传输协议。Web应用的开发应该回归Web的本质特征。Rails在发展过程中也完全拥抱REST，成为REST的坚定支持者。有些人认为REST和MVC是两种对立的风格，其实不尽然，两者是互为补充的，从Rails是一个全面支持REST的MVC框架这一点就可窥见。 浏览器端的魔术：AJAXWeb应用同时涉及到浏览器端和服务器端，之前的介绍除了简单提到了CSS规范之外，主要关注的是服务器端的技术发展。在客户端，1995年NetScape公司设计的JavaScript被用作浏览器上运行脚本语言为网页增加动态性。微软随后推出类似JScript，但是缺乏统一的语言规范，使得浏览器兼容性成为一个程序员的梦魇。JavaScript最终被提交到欧洲计算机制造商协会(ECMA)，做为中立的ECMA开始了标准化脚本语言之路，并将其命名为ECMAScript。JavaScript可以响应浏览器端的用户事件，检测表单的正确性，动态修改HTML页面结构DOM，因此可以减少与服务器端的通信开销，并且做出很酷的页面动态效果。2005年出现的AJAX这个概念使得JavaScript再次大放异彩。AJAX即“Asynchronous JavaScript and XML”（异步的JavaScript与XML技术），指的是一套综合了多项技术的浏览器端网页开发技术，可以基于JavaScript的XmlHttpRequest的用于创建交互性更强的Web应用。AJAX是一种已有技术的mashup，多种技术组合在一起形成了其特色和优势，早在1998年就已经开始有人使用。Google在地图和Gmail等产品中对这项技术的深入应用，以及AJAX这个吸引眼球的名字的提出，使其正式站在了聚光灯下，开始吸引无数人的目光。我们知道Web应用中用户提交表单时就向Web服务器发送一个请求，服务器接收并处理传来的表单，并返回一个新的网页。而前后两个页面中的往往大部分HTML代码是一样的，每次都返回整个页面内容是一种带宽资源的浪费。而AJAX应用仅向服务器发送并取回必须的数据，并在客户端采用JavaScript处理来自服务器响应，更新页面的局部信息。这样不仅浏览器和服务器的数据交换大大减少，而且客户端也可以更加快速地响应用户操作。如果你用Gmail就应该知道，Gmail从来都不刷新页面，所有的请求都是通过AJAX获取数据进行局部更新。AJAX的出现，以及诸如EXTJS、DOJO等一些前端开发框架的出现，也使得单页应用（Single Page Application）在这个时候流行起来。 前端MVC：Angular/Backbone这种模式下，前后端的分工非常清晰，前后端的关键协作点是 Ajax 接口，规定好交互接口后，前后端工程师就可以根据约定，分头开工，开发环境中通过Mock等方式进行测试，同时在特定时间节点进行前后端集成测试。但是，随着业务功能的愈发复杂（看看现在的Gmail），这种模式本质上和JSP时代的Web开发并无本质区别，只不过是将复杂的业务逻辑从JSP文件转移到了JavaScript文件中而已。现在，对于一个前端功能、交互复杂的SPA，JavaScript代码很容易膨胀（超过10万行）。很自然地，像服务端从JSP向MVC框架转换的过程一样，前端开发也出现了大量的MVC框架，比较典型的包括BackboneJS, AngularJS, EmberJS, KnockoutJS。总的来说，MV*框架的提出是为了解决前端开发的复杂度，提供一套规则组织代码、分层（MVC），通过合理的组织和分层，前端的代码职责明确、清晰，便于开发与测试。 JavaScript在服务器端的逆袭：Node各大浏览器的竞争，使其引擎的性能不断提升，至今Google V8引擎的性能已经足以运行大型Javascript程序。在V8之上加以网络、文件系统等内置模块，形成了如今的Node.js。 随着Node.js的出现，JavaScript开始拥有在服务端运行的能力，它的异步本质使得Node.js在处理I/O密集型业务中优势凸显，而大多Web业务中I/O性能都是瓶颈。eBay、Yahoo、甚至Microsoft Azure纷纷引入Node.js以提升性能。Node.js的package每天都有几千万的下载量。这对前端工程师来说可是一个好消息，精通JavaScript的他们也能够做服务端开发了！虽然现实中并不是这样美好（服务端开发涉及的不仅仅是语言层面），但一种新的开发模式也因此兴起：浏览器端处理展现层逻辑、而服务端Controller这一层以及相关的模板渲染、路由、数据接口以及Session/Cookie先关处理实际上交给了Nodejs来做。通过Nodejs, 意味着前后端很多代码可以复用（例如数据验证逻辑），在需要SEO的场景下也可以选择服务端模板渲染。 但另一方面，JavaScript刚被引入到服务器端开发，其生态环境还未成熟，甚至大量的常用package主版本号都是0。长期用来实现页面逻辑，天生自由的JavaScript，在服务器端开发中，仍未形成统一的开发范型。不同开发原则和编码风格的应用，都将对Node.js项目的性能、可维护性产生重大影响。现在而言，服务器端javascript开发究竟是魔鬼还是天使，仍取决于团队中的开发者。 结语Web技术依然在快速发展，Web本身的基础规范也在不断完善，HTML5和CSS3引入了更多激动人心的特性。回顾Web的发展历史，从某个角度看，就是抽象层次不断提高的一个过程，更高的抽象层次屏蔽更低层的复杂性，从而提高开发效率。每当技术发展到一定程度，出现某些局限性的时候，就会有更优秀的技术出现来突破这些局限性。其实这是计算机技术发展的一个普遍规律，比如高级语言的出现屏蔽了汇编语言的复杂性，帮助我们更快速的编程；数据库技术的出现使得我们无需关心物理存储和访问细节，写简单的SQL语句就能搞定，更进一步，ORM框架使得我们通过一条语句调用一个类的一个方法就能方便就行数据操作。我们应该让自己的技术视野具备一定的高度和广度，看到一门技术的发展规律和发展历程，这是一种技术修养的体现，其实跟人文修养是一样的。同时也应该具有一定的深度，因为我们往往站在比较高的抽象层次，比如今天你写几行代码就能把数据库创建好，增删改查的功能也自动生成好了，但是成为高手需要你对底层的原理机制有更透彻的理解，真正遇到问题的时候才能抽丝剥茧迎刃而解。 Java Web 开发发展简介远古期 - 静态页面时代讲Java Web开发的历史进程，不得不提Web开发的历史进程。 在互联网刚发展的时候，那时候的网站功能是很简单的。那时候的网站还都是静态的。这里所说的静态是指，请求访问的网页都是事先编辑好的，不能改变的。 这里先讲下当时一个请求是如何返回结果的。 比如，你想访问新浪上的一张图片，会在浏览器键入这个图片的地址： 浏览器会根据地址像新浪服务器发送HTTP请求。新浪服务器上的HTTP Server接收到请求后，会根据路径地址/img/12345.jpg查找的这个文件，然后read文件，再把图片数据发送给客户端，客户端的浏览器就能正确展示图片了。 也就是说，这里的URL对服务器来说就是查找文件的地址，而文件必须实实在在存在于服务器中的特定目录下的。 缺点 很明显，访问的资源必须事先已经存在，否则访问不到。而动态展示也是没法实现的。比如：某人刚发布了一篇文章，想在首页立即看到是不可能的。只能重新手动编辑首页，把文章链接加进去 混沌期 - CGI时代然而，如果页面一直是静态的额，也就不会有现在纷繁复杂的网站了。那么动态展示页面的解决方案是什么呢？是CGI！ CGI全称是通用网关接口(Common Gateway Interface)。那么它的作用是啥呢？ CGI是啥首先，要清楚CGI是啥？ CGI是一个可执行的程序或者可运行的脚本。几乎所有语言都能写CGI，像python，C，甚至shell。 举个例子。下面一段C代码，经过编译成可执行程序后，就是一个CGI。 123456int _tmain(int argc, _TCHAR* argv[]){ printf(&quot;Content-type:text/html\\n\\n&quot;); printf(&quot;%s&quot;,getenv(&quot;QUERY_STRING&quot;)); //打印get获取的信息 return 0;} 再或者，下面一个python脚本，也是一个CGI 1234567891011121314#!/usr/bin/python# -*- coding: UTF-8 -*-print &quot;Content-type:text/html&quot;print # 空行，告诉服务器结束头部print '&lt;html&gt;'print '&lt;head&gt;'print '&lt;meta charset=&quot;utf-8&quot;&gt;'print '&lt;title&gt;Hello Word - 我的第一个 CGI 程序！&lt;/title&gt;'print '&lt;/head&gt;'print '&lt;body&gt;'print '&lt;h2&gt;Hello Word! 我是来自菜鸟教程的第一CGI程序&lt;/h2&gt;'print '&lt;/body&gt;'print '&lt;/html&gt;' OK，知道了CGI是可执行的程序或脚本，但是怎么工作的呢？ CGI怎么用 如上图，当浏览器发送一个CGI请求后，服务器会启动一个进程运行CGI程序或脚本，由CGI来处理数据，并将结果返回给服务器，服务器再将结果返回给浏览器。 举个表单提交的例子： 12345678&lt;form id=&quot;form&quot; name=&quot;form&quot; method=&quot;post&quot; action=&quot;http://localhost/cgi-bin/test/cgi_test.cgi&quot;&gt; &lt;p&gt;输入内容： &lt;input type=&quot;text&quot; name=&quot;user&quot; id=&quot;user&quot; /&gt; &lt;/p&gt; &lt;p&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; id=&quot;submit&quot; value=&quot;提交&quot; /&gt; &lt;/p&gt;&lt;/form&gt; 上面是一个表单提交的html代码，展示的效果是下面这个样子： 细心的你会发现，action的值是http://localhost/cgi-bin/test/cgi_test.cgi。这里，cgi_test.cgi就是一个cgi程序。 还记得上面那段C++代码吗？ 123456int _tmain(int argc, _TCHAR* argv[]){ printf(&quot;Content-type:text/html\\n\\n&quot;); printf(&quot;%s&quot;,getenv(&quot;QUERY_STRING&quot;)); //打印get获取的信息 return 0;} cgi_test.cgi就是这段代码编译出来的可执行程序。 这段代码的作用是什么呢？ 作用是将表单提交的信息直接打印出来。 如何做到的？ 只有两行代码，第二行代码是关键。getenv()是C函数库中的函数，getenv(&quot;QUERY_STRING&quot;)的意思是读取环境变量QUERY_STRING的值。而QUERY_STRING的值就是表单提交的信息。 OK，这个CGI的功能就清晰了。表单提交后展示下面的结果也就不奇怪了： 我们再通过一个图梳理下上述流程： 综上，CGI工作模式示意图如下： CGI的特点 由Http Server唤起。常见的Http Server如Apache，Lighttpd，nginx都支持CGI CGI单独启动进程，并且每次调用都会重新启动进程 可以用任何语言编写，只要该语言支持标准输入、输出和环境变量 CGI的缺点 消耗资源多：每个请求都会启动一个CGI进行，进程消耗资源15M内存的话，同时到达100个请求的话，就会占用1.5G内存。如果请求更多，资源消耗是不可想象的。 慢：启动进程本身就慢。每次启动进程都需要重新初始化数据结构等，会变得更慢。 引申 为了解决CGI重复启动进程和初始化的问题，后来出现了FastCGI 开荒期 - Servlet时代在CGI繁荣发展的时代，Java还没有发展起来。当Java开始参与历史，引领潮流的时候，也必然会借鉴和改进之前的技术和思想。 鉴于CGI的一些缺点，Java Web在开始设计的时候就想出了一种解决方案 – Servlet 同样，第一个问题，Servlet是啥？ Servlet是啥？举个例子，网站一般都有注册功能。当用户填写好注册信息，点击“注册”按钮时，谁来处理这个请求？用户名是否重复谁来校验？用户名和密码需要写入数据库，谁来写入？是Servlet！ Servlet是实现javax.servlet.Servlet接口的类。一般处理Web请求的Servlet还需要继承javax.servlet.http.HttpServlet 1234abstract class HttpServlet implements Servlet{ void doGet(); void doPost();} doGet()方法处理GET请求 doPost()方法处理POST请求 浏览器发来的请求是怎么被Servlet处理的呢？还是举表单提交的例子。 我们假设表单样式如下，只是简单提交两个数据：网址名和网址。并假设处理URL为http://localhost:8080/TomcatTest/HelloForm 浏览器工作 当表单使用GET方式提交时，浏览器会把表单数据组装成这样的URL：http://localhost:8080/TomcatTest/HelloForm?name=菜鸟教程&amp;url=www.runoob.com 好，现在浏览器的任务暂时告一段落，开始Java Web服务工作了。 Java Web服务 首先，我们得指定http://localhost:8080/TomcatTest/HelloForm这个URL由谁来处理。这个映射关系需要在web.xml中配置： 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app&gt; &lt;servlet&gt; &lt;servlet-name&gt;HelloForm&lt;/servlet-name&gt; &lt;servlet-class&gt;com.runoob.test.HelloForm&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloForm&lt;/servlet-name&gt; &lt;url-pattern&gt;/TomcatTest/HelloForm&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; web.xml中配置的意思是：当URI为/TomcatTest/HelloForm时，交给com.runoob.test.HelloForm处理。而HelloForm正是个Servlet。 因此，我们需要编写HelloForm这样一个Servlet： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * Servlet implementation class HelloForm */@WebServlet(&quot;/HelloForm&quot;)public class HelloForm extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public HelloForm() { super(); // TODO Auto-generated constructor stub } /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // 设置响应内容类型 response.setContentType(&quot;text/html;charset=UTF-8&quot;); PrintWriter out = response.getWriter(); String title = &quot;使用 GET 方法读取表单数据&quot;; // 处理中文 String name =new String(request.getParameter(&quot;name&quot;).getBytes(&quot;ISO8859-1&quot;),&quot;UTF-8&quot;); String docType = &quot;&lt;!DOCTYPE html&gt; \\n&quot;; out.println(docType + &quot;&lt;html&gt;\\n&quot; + &quot;&lt;head&gt;&lt;title&gt;&quot; + title + &quot;&lt;/title&gt;&lt;/head&gt;\\n&quot; + &quot;&lt;body bgcolor=\\&quot;#f0f0f0\\&quot;&gt;\\n&quot; + &quot;&lt;h1 align=\\&quot;center\\&quot;&gt;&quot; + title + &quot;&lt;/h1&gt;\\n&quot; + &quot;&lt;ul&gt;\\n&quot; + &quot; &lt;li&gt;&lt;b&gt;站点名&lt;/b&gt;：&quot; + name + &quot;\\n&quot; + &quot; &lt;li&gt;&lt;b&gt;网址&lt;/b&gt;：&quot; + request.getParameter(&quot;url&quot;) + &quot;\\n&quot; + &quot;&lt;/ul&gt;\\n&quot; + &quot;&lt;/body&gt;&lt;/html&gt;&quot;); } // 处理 POST 方法请求的方法 public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { doGet(request, response); }} 由于请求方式是GET，因此需要doGet()方法来处理。仔细阅读doGet()方法的代码，发现处理逻辑只是把表单数据放入到了一段html代码中。这段html代码会被传输给浏览器，然后浏览器渲染出结果，如下图所示： Servlet的特点Servlet相对于CGI有了很大的改进，效率更高，功能更强大，更容易移植。主要表现在一下几个方面： CGI每个请求启动一个进程，而Servlet是更轻量的线程。线程和进程的对比和优劣请自行Google。 CGI每个进程都需要初始化，Servlet只初始化一次实例就行 Servlet依托于Java语言，具有很好的跨平台型。CGI根据语言的不同，跨平台型不同 CGI与数据库连接需要重连，Servlet可以使用数据库连接池。 Java有丰富的、各种各样的库函数 Servlet的缺点看上面的代码，会发现，html代码是写在Java代码中的。对于前端人员来说，这种形式非常非常难以开发和修改。 Servlet的升级 – JSPServlet是在Java代码中写HTML代码。与之对应的就是在HTML代码中写Java代码，这就是JSP。 JSP是啥？JSP：JavaServer Pages 简单点说，就是可以在html中写Java代码。 还是先从例子中大概了解下JSP： 还是上面表单处理的例子。表单的html代码就不展示了，我们直接模拟GET请求，即在浏览器中输入地址：http://localhost:8080/testjsp/main.jsp?name=菜鸟教程&amp;url=http://www.runoob.com 很明显，这个URL的关键是main.jsp。这个文件的内容是啥呢？ main.jsp 123456789101112131415161718192021&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ page import=&quot;java.io.*,java.util.*&quot; %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;使用 GET 方法读取数据&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;站点名:&lt;/b&gt; &lt;%= request.getParameter(&quot;name&quot;)%&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;网址:&lt;/b&gt; &lt;%= request.getParameter(&quot;url&quot;)%&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 这就是JSP，在html代码中插入Java代码。java代码被&lt;% %&gt;所包围。 &lt;%= request.getParameter(&quot;name&quot;)%&gt;表示获取请求参数name的值，&lt;%= request.getParameter(&quot;url&quot;)%&gt;表示获取请求参数url的值。最终展示结果是怎样的呢？看下图： JSP是如何工作的？为啥html代码中可以写Java代码呢？看下图： 其实原理是这样的： 就像其他普通的网页一样，您的浏览器发送一个HTTP请求给服务器。 Web服务器识别出这是一个对JSP网页的请求，并且将该请求传递给JSP引擎。通过使用URL或者.jsp文件来完成。 JSP引擎从磁盘中载入JSP文件，然后将它们转化为servlet。这种转化只是简单地将所有模板文本改用println()语句，并且将所有的JSP元素转化成Java代码。 JSP引擎将servlet编译成可执行类，并且将原始请求传递给servlet引擎。 Web服务器的某组件将会调用servlet引擎，然后载入并执行servlet类。在执行过程中，servlet产生HTML格式的输出并将其内嵌于HTTP response中上交给Web服务器。 Web服务器以静态HTML网页的形式将HTTP response返回到您的浏览器中。 最终，Web浏览器处理HTTP response中动态产生的HTML网页，就好像在处理静态网页一样。 用一句话来讲：每个JSP都最终会变成对应的Servlet执行 JSP的缺点在HTML代码中写Java代码，方便了前端人员，但是苦了后端人员。因此，单纯使用JSP，开发效率依旧不高。 后来，有牛人发现，Servlet天生非常适合逻辑处理(因为主要是Java代码)，而JSP非常适合页面展示(因为主要是html代码)，那么在结合Servlet和JSP各自的优缺点后，诞生了Web开发中最常用和最重要的架构设计模式：MVC 发展期 - MVC时代 MVC模式（Model-View-Controller）是软件工程中的一种软件架构模式，把软件系统分为三个基本部分：模型（Model）、视图（View）和控制器（Controller）： Controller——负责转发请求，对请求进行处理 View——负责界面显示 Model——业务功能编写（例如算法实现）、数据库设计以及数据存取操作实现 简而言之，请求发来后，会首先经过Controller层处理，需要返回的结果封装成对象传递给JSP，然后JSP负责取出数据展示就够了。这样，后端开发人员只负责编写Servlet，前端人员负责JSP，极大提升了开发效率。 1234567891011121314151617@WebServlet(&quot;/userPosts&quot;)public class UserPostController extends HttpServlet { private static final long serialVersionUID = -4208401453412759851L; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String username = req.getParameter(&quot;username&quot;); User user = Data.getByUsername(username); List&lt;Post&gt; posts = Data.getPostByUser(user); req.setAttribute(&quot;posts&quot;, posts); req.setAttribute(&quot;user&quot;, user); RequestDispatcher dispatcher = req.getRequestDispatcher(&quot;/templates/userPost.jsp&quot;); dispatcher.forward(req, resp); }} 像上面这段代码，UserPostController就是一个Servlet，负责逻辑处理。需要返回的数据封装到HttpServletRequest对象中，传递给jsp页面。而负责展示的就是/templates/userPost.jsp这个jsp文件。 繁盛期 - 框架时代有了Servlet和JSP，相当于有了武器。有了MVC，相当于有了战术。但是武器和战术之间还缺少一层，就是具体实施者。 实践证明，单纯使用Servlet、JSP和MVC开发，依然会面临诸多的问题。而程序员普遍存在一种特质，就是懒。因为懒，所以才想着能有更简单的解决办法。因为懒，针对一些通用问题，才会想出通用解决方法。可以说，因为懒，科技才有了进步。。。这时候，为了解放劳动力，一些开源框架营运而出。这些框架的目的只有一个：让开发简单，简单，更简单 提到Java Web框架，就不得不提几乎所有开发者都知道的三大框架：SSH SSH关于三大框架，这里不做介绍了，网上的文章铺天盖地。想要说的是：无论什么框架，都是对常见问题的抽象和封装，再出什么新的框架，也万变不离其宗，脱离不了Servlet这个根基。学习的时候千万不能跟着框架走，框架让做什么就做什么，而是要想为什么这样做。否则，今天学会了一个框架，明天又出了新的框架，又会抓瞎了。 Java学习路线 Java EE and Springhttps://www.zhihu.com/question/268742981/answer/341770209在回答题主的问题之前，我先要简单介绍一下什么是JavaEE，什么是Spring。JavaEE是一组建立在JavaSE之上的标准，解决企业级开发中的一系列问题。请特别留意，它仅仅是个标准，是对一系列接口的约定，众多厂商围绕这个标准做实现。如JBoss，WebSphere等。第一个版本的JavaEE 1.2在1999年被发布，到2017年的JavaEE 8，已经经历了将近20年。那么JavaEE都有哪些标准，解决了什么问题呢？我这里简单列举一下主要的标准：Servlet：定义了如何处理Web请求，这个相信大家最熟悉Java Server Faces：定义了如何使编写Web界面JAX-RS：定义了如何编写RESTFul的接口EJB：定义了如何编写“企业Bean”JPA：定义了如何编写ORM和数据存取JTA：定义了如何编写事务相关的代码JMS：定义了如何编写消息队列程序CDI：定义了如何编写依赖注入JAX：定义了如何编写XML程序JAX-WS: 定义了如何编写基于XML的网络服务，即SOAP……看到这些，你可能机会发现，你平时其实经常使用其中一些标准接口，即便你认为你在用Spring。什么是Spring呢？Spring最早可以追溯到2002～2004年。在那几年作者Rod Johnson出版了两本书：“Expert One-on-One J2EE Design and Development“和“Expert One-on-One J2EE Development without EJB“，和最初几个版本的Springframework。早期的Spring定位于解决J2EE在实际使用上的一系列问题，因为JavaEE的API实在是太难用了。Rod估计是趟了不少大坑，于是总结了一套最佳实践，并总结到了一套框架里。其中最重要的，就是所谓IoC（控制反转）。经过多年发展，Spring发布了很多组件：spring-core：Spring的Bean的管理，控制反转和程序上下文spring-mvc: web开发中的model-view-controllerspring-data: 数据层访问和封装spring-boot: spring全家桶自助配置和部署管理工具spring-batch：一个简单的批处理框架spring-cloud：支持与许多云服务接口的整合spring-security：认证和权限管理……spring中其实大量使用或者实现了JavaEE标准。比如spring-mvc是在servlet基础之上的封装。spring本身并不提供容器，而是支持使用任何支持servlet标准的容器（如tomcat，jetty等）。spring-data也实现了JPA，通过标准接口对进行CRUD等。归根到底Spring只是想更好的解决实际问题。JavaEE的实现做得好的就用，做得不好的用比较恰当的方式独立实现或者封装。俗称“接地气”。见过不少人喜欢用“JavaEE vs Spring”来提问引战。但是，由上面的介绍可以看到JavaEE和Spring并不对立。作为开发工程师，其实还是哪个能解决问题，生态好，支持好，成本低就用哪个。而且混着用也没有什么大的问题。随着时间的发展，JavaEE已经越来越落后，这是由于它的体制造成的。JavaEE的制定是由几大巨头定期开会协商通过，发布。然后个大容器实现厂商跟进。但这样太慢了。互联网的发展速度已经远不是这样一个僵化的体制能够适应的。反观Spring相对就快速的多。Spring自己就是一家公司，觉得整个社区什么东西最前沿，最急缺就立刻响应去做了。比如，Restful刚流行，你是愿意等一年半载出JAX-RS标准，然后再出Jersey，才能用；还是选择直接用Spring MVC直接就把事办了？结果不言而喻。对解决问题的态度是二者目前境遇不同的主要原因。最早期JavaEE是领导者，所有的技术厂商要想在这个圈子里混，必须跟着标准走。而Spring逐渐占据领导地位之后，JavaEE的一些标准反而要跟着Spring走。CDI就是一个很好的例子。Spring IoC是整个框架的核心。它解决了在Java中只能import类，却import不了组件的问题。这个问题在js，python之类的环境中都是小菜一碟。但是Java中，如果没有IoC，程序员就要花大量的时间写new和set，组装整个服务的引用关系（你不觉得这很不人道吗？）。Spring流行之后，JavaEE在2009年才发布CDI标准。其样子就是活脱脱的把Spring的Annotation换了个名字而已。如果说未来的发展，我认为JavaEE早已经没有了未来。JavaEE里那些做得很好的，或者和其他框架能够很容易相融的标准继续存在；那些被骂成翔的，比如JSF；或者一开始就没有市场的，比如CDI，会成为Wiki上的一段段文字记录。但，Spring也不一定好过。在Java体系内他也要面临play，vert.x的冲击；在体系外，它会受到其他语言环境的巨大压力，如nodejs，python和go。说Spring灵活是相对于JavaEE而言。无论标准、框架、服务，都是为了解决问题而存在，而不是如“多么的OO”，“多么的标准”，“多么的概念清晰“。哪个工具解决的好，解决的快，就用哪个。最近2～3年，docker+微服务的发展进一步的强化了这个现实。大量的新技术会随着业务领域形成自己的生态。这其实是好事，不是吗？P.S. 题主在题目中给了一个文章，我认为其JavaEE和IoT的说法完全是扯淡。一个不注重解决问题，总想画个大饼的东东，还想抢占新领域？先老老实实做几个能跑的东西再说吧。2018年3月17日更新。有知友询问还是不理解什么是规范。那我索性再唠叨一些。Java各种标准的制定是通过Java Community Process - JCP进行的。JCP的成员可以根据需要提出Java Specification Request - JSR。每个JSR都要经过提交给JCP，然后JCP讨论，修订，表决通过，并最终定稿；当然，运气不好的就被拒绝/废弃了。而JavaEE是一组被通过的JSR的合集。JSR和JavaEE的关系就好像是文章和经过编辑整理过的文集。以Servlet为例。Servlet的标准有很多个版本，从1.1到目前最新的4.0。Servlet从2.2版本被纳入到JavaEE。目前比较常见的Servlet 3.0是JSR-315，在2009年年底发布。在JCR Servlet 3.0可以看到这个提案整体的流程，并可下载原文。那么到底什么是Specification呢？是一组实现约定。还拿Servlet规范举例子，它的其中一个规定是：为了支持处理一个Web请求，必须实现一个HttpServlet类，这个类必须继承Servlet接口，当然也得实现其中的所有接口方法，比如doGet，doPost。doGet方法必须接受两个参数，HttpServletRequest req, HttpServletResponse resp，分别表示请求和返回，出了问题可以返回ServletException或者IOException。整个规范大概几十上百页。所规定的项目包括接口定义，抽象类和关系，状态和生命周期等等。而所有开发基于Java的企业应用的厂商就可以选择支持这些规范。Tomcat、Jetty、glassfish等都支持Servlet。所以你不管用哪个，编写出来的Java代码是基本一样的。当然，这些实现除了支持规范外都有各自独有功能和接口，不然咋竞争……。但白话了这么多，我其实是希望大家不要过于在意JavaEE到底是什么这件事情。在开发时，并不会以“一个库是不是遵守标准“为最优先的考量（尽管一些标准狂热分子的确会这样，还会时不时圣战一把）。如果有能干活的框架/库，符合一个广泛接受的标准，当然好；如果不符合，也不用太纠结。毕竟我们是为自己的工作任务打工，而不是为标准和编程语言打工，对吧？","link":"/2020/03/28/Backend/java%20web%E5%8F%91%E5%B1%95%E5%8F%B2%E4%B8%8Ejava%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/"},{"title":"Angular学习笔记","text":"Angular笔记 Basics Angular的Component可以反复使用也可以使用在其他Component中， Angular有一个根Component叫做&lt;app-root&gt;&lt;/app-root&gt;，其他我们生成的Component都需要在该Component内部 可以手动生成Component，**但不要忘记在app.modules.ts的declarations中声明(类似于spring中对Component的scan)**；也可以用ng generate component&lt;name&gt; 自动生成，则不再需要手动添加声明(确保ng serve在运行)。 @Component指明了该组件的配置情况，其中templateUrl指定了该组件的内容(可以不用templateUrl而是使用template，那么此时是在typescript文件中直接写html)，styleUrls和styles起着相同的作用，唯一的区别是style可以有多个css文件。selector很像css的selector，不止可以做为选中元素，也可以做为选中属性( [&lt;attribute&gt;] )或者选中class ( [.&lt;class&gt;] ) 1234567891011121314import { Component, OnInit } from '@angular/core';@Component({ selector: 'app-servers', templateUrl: './servers.component.html', styleUrls: ['./servers.component.css']})export class ServersComponent implements OnInit { constructor() { } ngOnInit() { }} Angular databinding的四种方式 1. String Interpolation：{{ }}写在html文件中，{{ }}中间可以是typescript中声明的变量或函数，只要{{ }}中间最后是一个String类型即可。 2. Property Binding：改变某个元素的原生属性的值，比如将某个元素的disabled属性绑定到某个布尔变量上。 &lt;button class=&quot;btn btn-primary&quot; [disabled]=&quot;!allowNewServer&quot;&gt;&lt;/button&gt; 3. Event Binding：当触发绑定的event(比如click event)后，会执行expression。一个很重要的预留关键词是$event，这个关键词代表的是触发该event产生的数据。比如我们可以监听input元素的input event，每当我们改变input元素的内容的时候，我们都可以拿到这个值。&lt;input class=&quot;form-control&quot; (input)=&quot;onUpdataServerName($event)&quot;&gt; 4. Two Way Binding：typescript中变量的改变会改变template上的显示，template上的显示被手动改变也会改变typescript中变量的值。需要加入FormModule这个库。 Directives:组件是一个带模板的指令；@Component装饰器实际上就是一个@Directive装饰器，只是扩展了一些面向模板的特性。一些angular内置的directives：带*号的是structural directives，structural directives会导致元素的增加或删除，普通的attribute directives不会造成元素的增加或删除，只会改变元素。 *ngIf：如果判断为真，那么元素存在，如果判断为假，那么该元素不存在(注意与disabled属性的区别，disabled是指元素存在但不可见)。&lt;p *ngIf=&quot;getServerStatus()&quot;&gt;&lt;/p&gt;[ngStyle]：attribute directive，他本身是一个directive，我们使用的时候用Property Binding来动态的改变某个元素的style。&lt;p [ngStyle]=&quot;{ backgroundColor: getColor() }&quot;&gt;&lt;/p&gt;语法格式是：冒号前面是style名字，冒号后面是一个String，代表该style的属性。[ngClass]：动态增加css class。&lt;p [ngClass]=&quot;{ Online: getServerStatus==='online' } &quot;&gt;&lt;/p&gt;语法格式是：冒号前面是我们css文件中的某个class，冒号后面是boolean值，可以是表达式或函数，如果boolean为真，那么在该元素上增加该class。*ngFor：&lt;p *ngFor=&quot;let server of servers; let i = index&quot;&gt;{{ server }}&lt;/p&gt;servers是我们定义的一个javascript array。index是ngFor预留的关键词，可以获取ngFor循环的index。i可以在这个元素中当做变量使用。 一个很重要的问题：两个Component之间如何进行数据的交互。Custom Properties &amp; Events：Native Properties &amp; Events指的是对已有元素的property进行绑定，比如disabled属性。Custom Properties &amp; Events for Directives指的是类似*ngFor。Custom Properties &amp; Event for Components 用于Component间的数据交互。 父Component传入子Component 1234567891011export class ServerElementComponent implements OnInit { @Input('srvElement') element : { type: string, name: string, content: string } constructor() { } ngOnInit() { }} 使用了input注解之后，我们再使用ServerElementComponent的时候就像之前我们使用disabled属性一样使用element属性了，所以也可以为其绑定数据。&lt;app-server-element *ngFor=&quot;let serverElement of serverElements&quot; [srvElement]='serverElement'&gt;&lt;/app-server-element&gt;@Input(alias),如果我们想为property起一个别名，乐意在里面加一个alias，这时候使用的时候就必须要用这个alias。如果不加alias，那么使用的时候就是用他本来的名字(element)。 子Component发射event，父Component接受event(子Component向父Component传数据)app.html. &lt;app-cockpit (serverCreated)=&quot;onServerAdded($event)&quot; (blueprintCreated)=&quot;onBlueprintAdded($event)&quot;&gt;&lt;/app-cockpit&gt; app.ts 12345678910111213141516171819export class AppComponent { serverElements = [{type:'server', name:'test', content:'test'}]; onServerAdded(serverData:{serverName: string, serverContent:string}) { this.serverElements.push({ type: 'server', name: serverData.serverName, content: serverData.serverContent }); } onBlueprintAdded(serverData:{serverName: string, serverContent:string}) { this.serverElements.push({ type: 'blueprint', name: serverData.serverName, content: serverData.newServerContent }); }} cockpit.html 12345678910111213141516&lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-xs-12&quot;&gt; &lt;p&gt;Add new Servers or blueprints!&lt;/p&gt; &lt;label&gt;Server Name&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; [(ngModel)]=&quot;newServerName&quot;&gt; &lt;label&gt;Server Content&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; [(ngModel)]=&quot;newServerContent&quot;&gt; &lt;br&gt; &lt;button class=&quot;btn btn-primary&quot; (click)=&quot;onAddServer()&quot;&gt;Add Server&lt;/button&gt; &lt;button class=&quot;btn btn-primary&quot; (click)=&quot;onAddBlueprint()&quot;&gt;Add Server Blueprint&lt;/button&gt; &lt;/div&gt;&lt;/div&gt; cockpit.ts 123456789101112131415161718192021222324export class CockpitComponent implements OnInit { @Output() serverCreated = new EventEmitter&lt;{serverName:string, serverContent:string}&gt;(); @Output() blueprintCreated = new EventEmitter&lt;{serverName:string, serverContent:string}&gt;(); newServerName = ''; newServerContent = ''; constructor() { } ngOnInit() { } onAddServer() { //当我们接受到click信号的时候，触发这个函数，在这个函数中将serverCreated信号发射，这样我们的app-component会接受到serverCreated信号并把新加入的server加入数组。 this.serverCreated.emit({ serverName:this.newServerName, serverContent:this.newServerContent }); } onAddBlueprint() { this.blueprintCreated.emit({ serverName:this.newServerName, serverContent:this.newServerContent }); } View Encapsulation默认是emulated，可选的有none和native。emulated意思是css文件只对该Component起作用。 传数据的其他方式Local Reference我们现在使用双向绑定获取input的值，我们也可以在html元素中加入#reference_name，然后我们可以在html的其他位置引用该元素。@ViewChild在html使用#号标识引用，然后再ts文件中使用viewchild声明一个变量。@ViewChild('nameInput', {static: false}) nameInputRef:ElementRef后面我们就可以使用这个变量，并且它的值与html关联。this.nameInputRef.nativeElement.valueng-content Lifecycle More of directive basic attribute directive : 123456789101112import { Directive, ElementRef, OnInit } from '@angular/core';@Directive({ selector:'[appBasicHightlight]'})export class BasicHighlightDirective implements OnInit { constructor(private elementRef:ElementRef){} ngOnInit(): void { this.elementRef.nativeElement.style.backgroundColor = 'green'; }} better attribute directive: 因为有的时候不能直接操作DOM，所以这是一个更好的方法。 12345678910111213import { Directive, Renderer2, OnInit, ElementRef } from '@angular/core';@Directive({ selector: '[appBetterHighlight]'})export class BetterHighlightDirective implements OnInit{ constructor(private elRef:ElementRef, private renderer:Renderer2) { } ngOnInit(){ this.renderer.setStyle(this.elRef.nativeElement, 'background-color', 'blue') }} responsive attribute directive:使用HostListener注解可以像jQuery一样接收到event。 1234567@HostListener('mouseenter') mouseover(eventData:Event){ this.renderer.setStyle(this.elRef.nativeElement, 'back-ground-color', 'blue');} @HostListener('mouseleave') mouseleave(eventData:Event){ this.renderer.setStyle(this.elRef.nativeElement, 'back-ground-color', 'transparent');} 以上这种responsive attribute directive还是有些麻烦，我们可以不使用renderer2而是使用@HostBinding 1234567891011121314151617export class BetterHighlightDirective implements OnInit{ @HostBinding('style.backgroundColor') backgroundColor:string = 'transparent'; constructor(private elRef:ElementRef, private renderer:Renderer2) { } ngOnInit(){ } @HostListener('mouseenter') mouseover(eventData:Event){ // this.renderer.setStyle(this.elRef.nativeElement, 'back-ground-color', 'blue'); this.backgroundColor = 'blue'; } @HostListener('mouseleave') mouseleave(eventData:Event){ // this.renderer.setStyle(this.elRef.nativeElement, 'back-ground-color', 'transparent'); this.backgroundColor = 'green'; }} directive也像component一样可以进行custom binding，语法格式完全一样（在directive中新建@input成员变量），然后就可以在使用directive的时候绑定值。 1234567891011121314151617181920212223@Directive({ selector: '[appBetterHighlight]'})export class BetterHighlightDirective implements OnInit{ @Input() defaultColor:string = 'transparent'; @Input() changedColor:string = 'blue'; @HostBinding('style.backgroundColor') backgroundColor:string; constructor(private elRef:ElementRef, private renderer:Renderer2) { } ngOnInit(){ this.backgroundColor = this.defaultColor; } @HostListener('mouseenter') mouseover(eventData:Event){ // this.renderer.setStyle(this.elRef.nativeElement, 'back-ground-color', 'blue'); this.backgroundColor = this.changedColor; } @HostListener('mouseleave') mouseleave(eventData:Event){ // this.renderer.setStyle(this.elRef.nativeElement, 'back-ground-color', 'transparent'); this.backgroundColor = this.defaultColor; }} 12345&lt;ul class=&quot;list-group&quot;&gt; &lt;li class=&quot;list-group-item&quot; appBetterHighlight [changedColor]=&quot;'red'&quot; [defaultColor]=&quot;'pink'&quot;&gt; content &lt;/li&gt;&lt;/ul&gt; structural directive: Angular本身没有符号，符号其实是告诉Angular将*ngIf变成&lt;ng-template [ngIf]&gt;&lt;/ng-template&gt; Service and Dependency Injection 与spring boot的dependency injection相同，angular也采用了相同的思想，所以对于我们的服务类，我们不需要去实例化他们，而是应该在需要使用该依赖的时候使用依赖注入。 12345678910111213141516171819import { Component, EventEmitter, Output } from '@angular/core';import { LoggingService } from '../logging.service';@Component({ selector: 'app-new-account', templateUrl: './new-account.component.html', styleUrls: ['./new-account.component.css'], providers: [LoggingService]})export class NewAccountComponent { @Output() accountAdded = new EventEmitter&lt;{name: string, status: string}&gt;(); constructor(private loggingService:LoggingService){} onCreateAccount(accountName: string, accountStatus: string) { this.accountAdded.emit({ name: accountName, status: accountStatus}); this.loggingService.logStatusChange(accountStatus); }} Hierarchical Injector如果在一个component中使用了依赖注入，那么这个component及它的子component都会共享同一个相同的实例。所以如果在父component和它的子component中都对同一个service进行依赖注入，那么会产生两个实例。 所以，如果想要在子component使用父component的实例，那么不要在providers中填写service类！ 如果想在一个一个依赖中注入另一个依赖，需要标注@Injectable,同时在appModule的provider中注明。 Injection Dependency的好处：①代码结构更清晰，分离操作与接口 ② 不再需要component之间繁琐的数据传输，数据传输都可以通过service层 Routing routing的基础配置12345678910111213141516171819202122232425262728293031323334353637import { BrowserModule } from '@angular/platform-browser';import { NgModule } from '@angular/core';import { FormsModule } from '@angular/forms';import { AppComponent } from './app.component';import { HomeComponent } from './home/home.component';import { UsersComponent } from './users/users.component';import { ServersComponent } from './servers/servers.component';import { UserComponent } from './users/user/user.component';import { EditServerComponent } from './servers/edit-server/edit-server.component';import { ServerComponent } from './servers/server/server.component';import { ServersService } from './servers/servers.service';import { Routes, RouterModule } from '@angular/router';const appRoutes: Routes = [ {path: 'users', component: UsersComponent}, {path: '', component: HomeComponent }, {path: 'servers', component: ServersComponent}];@NgModule({ declarations: [ AppComponent, HomeComponent, UsersComponent, ServersComponent, UserComponent, EditServerComponent, ServerComponent ], imports: [ BrowserModule, FormsModule, RouterModule.forRoot(appRoutes) ], providers: [ServersService], bootstrap: [AppComponent]})export class AppModule { } 12345&lt;div class=&quot;row&quot;&gt;&lt;div class=&quot;col-xs-12 col-sm-10 col-md-8 col-sm-offset-1 col-md-offset-2&quot;&gt; &lt;router-outlet&gt;&lt;/router-outlet&gt;&lt;/div&gt;&lt;/div&gt; navigation:使用routerlink而不是href去进行navigation。 123&lt;li role=&quot;presentation&quot; class=&quot;active&quot;&gt;&lt;a [routerLink]=&quot;[ '/' ]&quot;&gt;Home&lt;/a&gt;&lt;/li&gt;&lt;li role=&quot;presentation&quot;&gt;&lt;a [routerLink]=&quot;[ '/servers' ]&quot;&gt;Servers&lt;/a&gt;&lt;/li&gt;&lt;li role=&quot;presentation&quot;&gt;&lt;a [routerLink]=&quot;[ '/users']&quot;&gt;Users&lt;/a&gt;&lt;/li&gt; 绝对路径：/&lt;path&gt; 相对路径：&lt;path&gt;, ../, ./ route active：routerLinkActive=&quot;active&quot;用于该route被选中时将会添加的active类，这里的active是bootstrap自带的active类，我们也可以写自己的active样式。[routerLinkActiveOptions]=&quot;{exact: true}指明是否只在绝对路径才会active。(不加这个那么点击servers和users时home也是active) 123456789&lt;li role=&quot;presentation&quot; routerLinkActive=&quot;active&quot; [routerLinkActiveOptions]=&quot;{exact: true}&quot;&gt; &lt;a [routerLink]=&quot;[ '/' ]&quot;&gt;Home&lt;/a&gt;&lt;/li&gt;&lt;li role=&quot;presentation&quot; routerLinkActive=&quot;active&quot;&gt; &lt;a [routerLink]=&quot;[ '/servers' ]&quot;&gt;Servers&lt;/a&gt;&lt;/li&gt;&lt;li role=&quot;presentation&quot; routerLinkActive=&quot;active&quot;&gt; &lt;a [routerLink]=&quot;[ '/users']&quot;&gt;Users&lt;/a&gt;&lt;/li&gt; 在typescipt进行routing 12345678910111213141516@Component({ selector: 'app-home', templateUrl: './home.component.html', styleUrls: ['./home.component.css']})export class HomeComponent implements OnInit { constructor(private router:Router) { } ngOnInit() { } onClickButton(){ this.router.navigate(['/servers']); }} typescript的navigate函数并不像html一样知道目前的路径，所以如果我们需要相对路径，需要手动添加，也可以添加目前的activeRoute。 12345678910111213141516@Component({ selector: 'app-home', templateUrl: './home.component.html', styleUrls: ['./home.component.css']})export class HomeComponent implements OnInit { constructor(private router:Router, private activedRoute:ActivatedRoute) { } ngOnInit() { } onClickButton(){ this.router.navigate(['servers'],{relativeTo: this.activedRoute}); }} url parameters{path: 'users/:id/:name', component:UsersComponent}在typescript中使用dynamic params：ActivatedRoute是一个javascript object，里面含有active页面的很多信息。 123456789101112export class UserComponent implements OnInit { user: {id: number, name: string}; constructor(private activedRouter:ActivatedRoute) { } ngOnInit() { this.user = { id: this.activedRouter.snapshot.params['id'], name: this.activedRouter.snapshot.params['name'] }; }} 由于angular是single page application，所以它默认的行为是如果已经加载了某一route，当我们想再次进入同一route时(在一个component中再次进入该component)，angular默认不进行任何动作，所以会出现我们在某一route更新值页面不变化的情况。 解决办法是使用ActivatedRouter.params这个angular预留observable来监听是否该route上有参数变化，有变化的话即发射event，我们可以监听这个event 1234&lt;p&gt;User with {{user.id}} loaded.&lt;/p&gt;&lt;p&gt;User name is {{user.name}}&lt;/p&gt;&lt;a [routerLink]=&quot;[ '/users', 10, 'shiyu']&quot;&gt;Go to shiyu page&lt;/a&gt; 1234567891011121314151617export class UserComponent implements OnInit { user: {id: number, name: string}; constructor(private activedRouter:ActivatedRoute) { } ngOnInit() { this.user = { id: this.activedRouter.snapshot.params['id'], name: this.activedRouter.snapshot.params['name'] }; this.activedRouter.params.subscribe((params:Params)=&gt;{ this.user.id = params['id']; this.user.name = params['name']; }); }} 这里我们不需要手动在onDestroy()的时候unsubscribe，但是如果是我们自己创建的observable，那么需要unsubscribe(后面的observable章节会讲)。 query parameters html中使用query parameters 1234567&lt;a [routerLink] = &quot;['/servers', 5, 'edit']&quot; [queryParams] = &quot;{ allowEdit: '1'}&quot; class=&quot;list-group-item&quot; *ngFor=&quot;let server of servers&quot;&gt; {{ server.name }}&lt;/a&gt; typescript中使用query parameters 1234567891011export class HomeComponent implements OnInit { constructor(private router:Router, private activedRoute:ActivatedRoute) { } ngOnInit() { } onClickButton(id:number){ this.router.navigate(['servers', id, 'edit'], {queryParams:{allowEdit: '1'}}); }} 使用的时候与url parameter类似： 1234console.log(this.activatedRouter.snapshot.queryParams);console.log(this.activatedRouter.snapshot.fragment);this.activatedRouter.queryParams.subscribe();this.activatedRouter.fragment.subscribe(); child(nested) routing如果我们想要在一个页面（route）中嵌入一个子页面(route)，比如在页面上显示详细信息，而不是另起一个页面显示详细信息，这个时候我们可以使用child routing。 123456789const appRoutes: Routes = [ {path: 'users', component: UsersComponent, children:[ {path: 'users/:id/:name', component:UserComponent} ]}, {path: '', component: HomeComponent }, {path: 'servers', component: ServersComponent, children: [ {path: 'servers/:id/edit', component : EditServerComponent}, {path: 'servers/:id',component:ServerComponent}]}]; 同时在users.component.ts和servers.component.ts的想要显示详细信息的地方加入&lt;router-outlet&gt;&lt;/router-outlet&gt;。 我们可以使用queryParamsHandling来保证子route保留（preserve）或融合（merge）父route的参数。 this.router.navigate(['edit'], {relativeTo:this.activitedRouter, queryParamsHandling:'preserve'}); redirect and wildcard 123456789101112const appRoutes: Routes = [ {path: 'users', component: UsersComponent, children:[ {path: ':id/:name', component:UserComponent} ]}, {path: '', component: HomeComponent }, {path: 'servers', component: ServersComponent, children: [ {path: ':id/edit', component : EditServerComponent}, {path: ':id',component:ServerComponent} ]}, {path: 'not-found', component: NotFoundComponent}, {path: '**', redirectTo: '/not-found'}]; **必须放在最后，意思是所有为定义的route。 redirect问题： Important: Redirection Path Matching In our example, we didn’t encounter any issues when we tried to redirect the user. But that’s not always the case when adding redirections. By default, Angular matches paths by prefix. That means, that the following route will match both /recipes and just / { path: ‘’, redirectTo: ‘/somewhere-else’ } Actually, Angular will give you an error here, because that’s a common gotcha: This route will now ALWAYS redirect you! Why? Since the default matching strategy is “prefix” , Angular checks if the path you entered in the URL does start with the path specified in the route. Of course every path starts with ‘’ (Important: That’s no whitespace, it’s simply “nothing”). To fix this behavior, you need to change the matching strategy to “full” : { path: ‘’, redirectTo: ‘/somewhere-else’, pathMatch: ‘full’ } Now, you only get redirected, if the full path is ‘’ (so only if you got NO other content in your path in this example). route guard（144）保护路径不被访问 canActiveGuard在用户离开页面前进行询问 canDeactiveGuard在component加载前获取一些数据 Resolve。resolve allows you load data (possibly asynchronously) BEFORE the component has been loaded. ngOnInit AFTER that happened. Both is perfectly fine, depending on your app and how you want to handle the possible “waiting time”. Observables 自己创建的observables切记要进行unsubscribe，否则会造成内存泄漏（因为observable是非同步的，所以相当于以前的进程没有杀死又开了新的进程）。 1234567891011121314export class HomeComponent implements OnInit, OnDestroy { private firstSubscription: Subscription; constructor() { } ngOnInit() { this.firstSubscription = interval(1000).subscribe((count)=&gt;{ console.log(count); }); } ngOnDestroy(): void { this.firstSubscription.unsubscribe(); }} custom observable如果error在complete之前发生，那么complete就不会发生，因为error之后就不再继续发射信号了。 1234567891011121314151617181920212223242526272829303132333435363738394041 export class HomeComponent implements OnInit, OnDestroy { private firstObsSubscription: Subscription; constructor() { } ngOnInit() { // this.firstObsSubscription = interval(1000).subscribe(count =&gt; { // console.log(count); // }); const customIntervalObservable = Observable.create(observer =&gt; { let count = 0; setInterval(() =&gt; { observer.next(count); if (count === 5) { observer.complete(); } if (count &gt; 3) { observer.error(new Error('Count is greater 3!')); } count++; }, 1000); }); this.firstObsSubscription = customIntervalObservable.subscribe(data =&gt; { console.log(data); }, error =&gt; { console.log(error); alert(error.message); }, () =&gt; { console.log('Completed!'); }); } ngOnDestroy(): void { this.firstObsSubscription.unsubscribe(); }} operator observable可以使用operator对数据进行操作，类似spark。 123456789101112this.firstObsSubscription = customIntervalObservable.pipe(filter(data =&gt; { return data &gt; 0;}), map((data: number) =&gt; { return 'Round: ' + (data + 1);})).subscribe(data =&gt; { console.log(data);}, error =&gt; { console.log(error); alert(error.message);}, () =&gt; { console.log('Completed!');}); subject rxjs提供一种类似于event emitter的observable，可以在observable外部手动调用next()触发，我们可以在cross component的情况中使用subject，而放弃使用event emitter。需要注意的是在@output的component交互的时候还是需要使用event emitter。所以其实就是说我们在service中使用的event emitter换成subject为好。 user.service中声明 1234@Injectable({providedIn: 'root'})export class UserService { activatedEmitter = new Subject&lt;boolean&gt;();} user.component中触发 12345678910111213141516export class UserComponent implements OnInit { id: number; constructor(private route: ActivatedRoute, private userService: UserService) { } ngOnInit() { this.route.params.subscribe((params: Params) =&gt; { this.id = +params.id; }); } onActivate() { this.userService.activatedEmitter.next(true); }} app.component中订阅，由于subject是一种特殊的observable，所以要记得unsubscribe。 1234567891011121314151617export class AppComponent implements OnInit, OnDestroy { userActivated = false; private activatedSub: Subscription; constructor(private userService: UserService) { } ngOnInit() { this.activatedSub = this.userService.activatedEmitter.subscribe(didActivate =&gt; { this.userActivated = didActivate; }); } ngOnDestroy(): void { this.activatedSub.unsubscribe(); }} Forms Forms有两种形式，一种是angular自动根据写好的form html来生成相应的javascript object，一种是直接通过在typescript中写出html的form。 Template-Driven在想要添加控制的html form元素上添加ngModel和name，angular即可自动识别。&lt;input type=&quot;email&quot; id=&quot;email&quot; cclass=&quot;form-control&quot; ngModel name=&quot;email&quot;&gt; 使用template-driven 使用local reference 123456789101112131415161718192021&lt;form (ngSubmit)=&quot;onSubmit(f)&quot; #f=&quot;ngForm&quot;&gt; &lt;div id=&quot;user-data&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;username&quot;&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;username&quot; class=&quot;form-control&quot; ngModel name=&quot;username&quot;&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot;&gt;Suggest an Username&lt;/button&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;email&quot;&gt;Mail&lt;/label&gt; &lt;input type=&quot;email&quot; id=&quot;email&quot; class=&quot;form-control&quot; ngModel name=&quot;email&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;secret&quot;&gt;Secret Questions&lt;/label&gt; &lt;select id=&quot;secret&quot; class=&quot;form-control&quot; ngModel name=&quot;selection&quot;&gt; &lt;option value=&quot;pet&quot;&gt;Your first Pet?&lt;/option&gt; &lt;option value=&quot;teacher&quot;&gt;Your first teacher?&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary&quot; type=&quot;submit&quot;&gt;Submit&lt;/button&gt;&lt;/form&gt; 使用@viewchild(viewchild其实也是获取靠获取local reference来获取该form javascipt object)，这种方式在判断form的内容是否validate的时候有用，因为是在submit前就得到了这个object。 1234567891011export class AppComponent {@ViewChild('f', {static: false}) signupForm: NgForm; suggestUserName() { const suggestedName = 'Superuser'; } onSubmit(f:NgForm){ console.log(this.signupForm); }} validation Object的格式： 12345678910111213141516171819202122232425262728NgForm {submitted: true, _directives: Array(3), ngSubmit: EventEmitter, form: FormGroup}control: (...)controls: Objectemail: FormControl {validator: ƒ, asyncValidator: null, _onCollectionChange: ƒ, pristine: false, touched: true, …}selection: FormControl {validator: null, asyncValidator: null, _onCollectionChange: ƒ, pristine: true, touched: false, …}username: FormControl {validator: ƒ, asyncValidator: null, _onCollectionChange: ƒ, pristine: false, touched: true, …}__proto__: Objectdirty: (...)disabled: (...)enabled: (...)errors: (...)form: FormGroup {validator: null, asyncValidator: null, _onCollectionChange: ƒ, pristine: false, touched: true, …}formDirective: (...)invalid: (...)ngSubmit: EventEmitter {_isScalar: false, observers: Array(1), closed: false, isStopped: false, hasError: false, …}path: (...)pending: (...)pristine: (...)status: (...)statusChanges: (...)submitted: truetouched: (...)untouched: (...)valid: (...)value: (...)valueChanges: (...)_directives: (3) [NgModel, NgModel, NgModel]__proto__: ControlContainer 我们可以发现这个form object本身有包括touched，valid，value等属性，同时它也包括controls，controls中的每个control代表单一的输入字段，他也有自身的各种属性。 我们可以使用前面得到的form object进行validation。 &lt;button class=&quot;btn btn-primary&quot; type=&quot;submit&quot; [disabled]=&quot;!f.valid&quot;&gt;Submit&lt;/button&gt; 我们也可以直接为更小的control直接添加local reference，但是这个时候我们赋给他的种类是ngModel而不是ngForm。 12345&lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;email&quot;&gt;Mail&lt;/label&gt; &lt;input type=&quot;email&quot; id=&quot;email&quot; class=&quot;form-control&quot; ngModel name=&quot;email&quot; required email #email=&quot;ngModel&quot;&gt; &lt;span class=&quot;help-block&quot; *ngIf=&quot;!email.valid&amp;&amp;email.touched&quot;&gt;Please enter a valid email!&lt;/span&gt;&lt;/div&gt; angular会为html添加生成的object的一些css类，类如ng-invalid，ng-touchded，我们可以使用这个添加一些交互效果。以下效果是用户点击后如果不是合法的输入，边框会变红。 123input.ng-invalid.ng-touched{ border: 1px solid red;} default value将之前的ngModel改为one way binding-property binding形式，即可以设定默认值。这是很好理解的，因为我们不想让之前对这个control的输可以更改typescript中这个value的值，所以我们不使用双向绑定而是使用单向绑定。 12345678&lt;input type=&quot;text&quot; id=&quot;username&quot; class=&quot;form-control&quot; [ngModel]=&quot;'initial value'&quot; name=&quot;username&quot; required&gt;&lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;secret&quot;&gt;Secret Questions&lt;/label&gt; &lt;select id=&quot;secret&quot; class=&quot;form-control&quot; [ngModel]=&quot;'pet'&quot; name=&quot;selection&quot;&gt; &lt;option value=&quot;pet&quot;&gt;Your first Pet?&lt;/option&gt; &lt;option value=&quot;teacher&quot;&gt;Your first teacher?&lt;/option&gt; &lt;/select&gt;&lt;/div&gt; 在某些特殊的情景下，我们可能需要双向绑定，比如同步实时显示输入的值。 ngModelGroup我们可以使用ngModelGroup将多个control放到一个javascript object中。 在typescript中改变form control的值。有两种方式，一种是直接在form上调用setValue()函数，作用是改变整个form；另一种是调用这个form的form.patchValue()函数，作用是overwrite 这个form的一部分。reset the form: 在form上调用reset()函数，reset不止改变form的值，也会改变它的属性，比如touched、valid等。 reactive form（我们不再需要FormsModule，而是需要ReactiveFormsModule）在typescript中创建formGroup对象 12345signupForm = new FormGroup({ 'username': new FormControl(null), 'email': new FormControl(null), 'gender': new FormControl('male')}); 同步html from与我们在typescript中船建的formGroup的对象 123456789101112131415161718192021222324252627282930313233&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-xs-12 col-sm-10 col-md-8 col-sm-offset-1 col-md-offset-2&quot;&gt; &lt;form [formGroup]=&quot;signupForm&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;username&quot;&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;username&quot; class=&quot;form-control&quot; [formControlName]=&quot;'username'&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;email&quot;&gt;email&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;email&quot; class=&quot;form-control&quot; [formControlName]=&quot;'email'&quot;&gt; &lt;/div&gt; &lt;div class=&quot;radio&quot; *ngFor=&quot;let gender of genders&quot;&gt; &lt;label&gt; &lt;input type=&quot;radio&quot; [value]=&quot;gender&quot; [formControlName]=&quot;'gender'&quot;&gt;{{ gender }} &lt;/label&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary&quot; type=&quot;submit&quot;&gt;Submit&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; reactive form validation 12345678signupForm: FormGroup;ngOnInit(){ this.signupForm = new FormGroup({ 'username': new FormControl(null, Validators.required), 'email': new FormControl(null, [Validators.required, Validators.email]), 'gender': new FormControl('male') });} 从formGroup中得到formControl我们可以使用get()函数来得到formGroup中的formControl。123456789&lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;username&quot;&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;username&quot; class=&quot;form-control&quot; [formControlName]=&quot;'username'&quot;&gt; &lt;span class=&quot;help-block&quot; *ngIf=&quot;!signupForm.get('username').valid&amp;&amp;signupForm.get('username').touched&quot;&gt;username is invalid!&lt;/span&gt;&lt;/div&gt; Nested Form Group我们可以在formGroup中嵌套更多的formGroup,这时候在html中同步要使用FormGroupName，同时我们的get函数也要做相应的改变1234567891011121314151617export class AppComponent implements OnInit{ genders = ['male', 'female']; signupForm: FormGroup; ngOnInit(){ this.signupForm = new FormGroup({ 'userData': new FormGroup({ 'username': new FormControl(null, Validators.required), 'email': new FormControl(null, [Validators.required, Validators.email]) }), 'gender': new FormControl('male') }); } onSubmit(){ console.log(this.signupForm); }} 12345678910111213141516171819202122232425262728293031323334353637&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-xs-12 col-sm-10 col-md-8 col-sm-offset-1 col-md-offset-2&quot;&gt; &lt;form [formGroup]=&quot;signupForm&quot; (ngSubmit)=&quot;onSubmit()&quot;&gt; &lt;div [formGroupName]=&quot;'userData'&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;username&quot;&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;username&quot; class=&quot;form-control&quot; [formControlName]=&quot;'username'&quot;&gt; &lt;span class=&quot;help-block&quot; *ngIf=&quot;!signupForm.get('userData.username').valid&amp;&amp;signupForm.get('userData.username').touched&quot;&gt;username is invalid!&lt;/span&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;email&quot;&gt;email&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;email&quot; class=&quot;form-control&quot; [formControlName]=&quot;'email'&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;radio&quot; *ngFor=&quot;let gender of genders&quot;&gt; &lt;label&gt; &lt;input type=&quot;radio&quot; [value]=&quot;gender&quot; [formControlName]=&quot;'gender'&quot;&gt;{{ gender }} &lt;/label&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary&quot; type=&quot;submit&quot;&gt;Submit&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; formArray1234567&lt;div formArrayName=&quot;hobbies&quot;&gt; &lt;h4&gt;Your Hobby&lt;/h4&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; (click)=&quot;onAddHobby()&quot;&gt;Add hobby&lt;/button&gt; &lt;div class=&quot;form-group&quot; *ngFor=&quot;let hobbyControl of signupForm.get('hobbies').controls; let i = index&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; [formControlName]=&quot;i&quot;&gt; &lt;/div&gt;&lt;/div&gt; 12345678910111213141516171819202122export class AppComponent implements OnInit{ genders = ['male', 'female']; signupForm: FormGroup; ngOnInit(){ this.signupForm = new FormGroup({ 'userData': new FormGroup({ 'username': new FormControl(null, Validators.required), 'email': new FormControl(null, [Validators.required, Validators.email]) }), 'gender': new FormControl('male'), 'hobbies': new FormArray([]) }); } onSubmit(){ console.log(this.signupForm); } onAddHobby(){ (&lt;FormArray&gt;this.signupForm.get(&quot;hobbies&quot;)).push(new FormControl(null, Validators.required)); }} custom validatorsynchronized validator：123456789101112131415161718192021222324252627282930export class AppComponent implements OnInit{ genders = ['male', 'female']; signupForm: FormGroup; forbiddenUserNames = ['chris', 'anna']; ngOnInit(){ this.signupForm = new FormGroup({ 'userData': new FormGroup({ 'username': new FormControl(null, [Validators.required, this.forbiddenNames.bind(this)]), 'email': new FormControl(null, [Validators.required, Validators.email]) }), 'gender': new FormControl('male'), 'hobbies': new FormArray([]) }); } onSubmit(){ console.log(this.signupForm); } onAddHobby(){ (&lt;FormArray&gt;this.signupForm.get(&quot;hobbies&quot;)).push(new FormControl(null, Validators.required)); } forbiddenNames(control:FormControl):{[s:string]:boolean}{ if(this.forbiddenUserNames.indexOf(control.value) !== -1){ return {'nameIsForbidden': true} } return null; }} 我们可以使用每个control的errors属性去查看错误信息。asynchronized validator：1234567891011121314151617181920212223242526272829303132333435363738394041424344export class AppComponent implements OnInit{ genders = ['male', 'female']; signupForm: FormGroup; forbiddenUserNames = ['chris', 'anna']; ngOnInit(){ this.signupForm = new FormGroup({ 'userData': new FormGroup({ 'username': new FormControl(null, [Validators.required, this.forbiddenNames.bind(this)]), 'email': new FormControl(null, [Validators.required, Validators.email], this.forbiddenEmails) }), 'gender': new FormControl('male'), 'hobbies': new FormArray([]) }); } onSubmit(){ console.log(this.signupForm); } onAddHobby(){ (&lt;FormArray&gt;this.signupForm.get(&quot;hobbies&quot;)).push(new FormControl(null, Validators.required)); } forbiddenNames(control:FormControl):{[s:string]:boolean}{ if(this.forbiddenUserNames.indexOf(control.value) !== -1){ return {'nameIsForbidden': true} } return null; } forbiddenEmails(control:FormControl):Promise&lt;any&gt; | Observable&lt;any&gt; { const promise = new Promise&lt;any&gt;((resolve, reject)=&gt;{ setTimeout(()=&gt;{ if(control.value ==='test@test.com'){ resolve({'emailIsForbidden': true}); } else { resolve(null); } }, 1500); }); return promise; }} formGroup自带的两个observablevalueChanges和statusChanges。123this.signupForm.valueChanges.subscribe((value)=&gt;{ console.log(value);}); 在typescript中改变form control的值可以直接调用formGroup.setValue(), formGroup.patchValue(), formGroup.reset() 实战经验 除了之前提到过的Component之间交流的方式，我们也可以使用@ViewChild达到在父Component中操纵子Component的目的。 这个本地变量方法是个简单便利的方法。但是它也有局限性，因为父组件-子组件的连接必须全部在父组件的模板中进行。父组件本身的代码对子组件没有访问权。 如果父组件的类需要读取子组件的属性值或调用子组件的方法，就不能使用本地变量方法。 当父组件类需要这种访问时，可以把子组件作为 ViewChild，注入到父组件里面。 Getter Setter ES6引入了class，以前的javascipt创建实例主要靠construcor，引入class后与java更加相似。同时ES6也保留了getter和setter。 getter和setter分别在使用该变量(即出现在等号右边)(变量名就是函数名)以及改变这个变量值(即出现在等号右边)的时候被调用。 12345678910111213141516171819class MyClass {constructor() { // ...}get prop() { return 'getter';}set prop(value) { console.log('setter: '+value);}}let inst = new MyClass();inst.prop = 123;// setter: 123inst.prop// 'getter' 所以不可以出现某个类中既有XX名字的变量，也有XX名字的setter和getter，因为会造成循环。常见的做法是将某个变量替换为setter+getter，这样的好处是可以在setter中对变量进行处理。 比如在angular中： 1234567891011121314151617private _fieldJson: any;@Input() public set fieldJson(value: any) { this._fieldJson = value; if (this.fieldJson) { this.initField(); if (this.editObj) { delete this.editObj['bindingPBRUri_name']; } if (this.data &amp;&amp; this.editObj) { this.editObj['AssociatedGroupUris'] = this.data['AssociatedGroupUris']; this.editObj['bindingPBRUri'] = this.data['bindingPBRUri']; } }}public get fieldJson(): any { return this._fieldJson;} 这里其实就相当于两个变量：fieldJson和_fieldJson，我们通过@input传入的是filedJson，我们通过setter对其进行处理并保存在_fieldJson中，每当我们要使用它时，他又会自动调用getter函数，所以我们用的其实是_fieldJson。 http://es6.ruanyifeng.com/#docs/class","link":"/2019/09/13/Frontend/Angular%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"元素脱离文档流的方法","text":"有三种情况将使得元素脱离文档流，分别是浮动(float left or right)、绝对定位(position:absolute)、固定定位(position:fixed)。 positionposition有四个选项，分别是默认值static，absolute，relative，fixed，常和top, bottom, left, right 或者 z-index联合使用，用来改变块元素位置。默认值static：默认值。没有定位，元素出现在正常的流中（忽略 top, bottom, left, right 或者 z-index 声明）。。将窗体自上而下分成一行行，并在每一行中按从左到右的顺序排放元素，即为文档流。absolute： 块元素根据第一个不是static属性的父元素进行定位(如果没有的则默认根据body定位)。对象虽然确定好了，但有些地方需要思考，如果父级设定了 margin，border，padding等属性，那么这个定位点将从哪里开始呢？答案是从padding开始。以下的例子中由于绿色div设置了position为absolute，同时它的父元素红色的position不是static，所以它会浮起并根据红色元素的padding进行定位。他下面的蓝色元素按照正常的static文件流进行定位。 1234567&lt;body&gt; &lt;div style=&quot;width: 1000px; height: 1000px; background: red; position: relative; left:300px&quot; &gt; &lt;div style=&quot;width: 100px; height: 100; background: green; position:absolute; left:50px&quot;&gt;&lt;/div&gt; &lt;div style=&quot;width: 500px; height: 500px; background: blue&quot;&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt; fixed： 很好理解，块元素永远根据打开浏览器的窗体进行定位relative：块元素根据本身原来自身的位置进行定位 float: https://www.cnblogs.com/iyangyuan/archive/2013/03/27/2983813.html","link":"/2019/09/13/Frontend/%E5%85%83%E7%B4%A0%E8%84%B1%E7%A6%BB%E6%96%87%E6%A1%A3%E6%B5%81%E7%9A%84%E6%96%B9%E6%B3%95/"},{"title":"692. Top K Frequent Words","text":"To help you guys have a better understanding of this problem, I tried to summary the methods I saw from others in this post. This is my first time to write a summary post, so correct me if there is any problem. Thanks! To analyze Time Complexity and Space Complexity: n is the total number of words, m is the average length of each word Just SortingThe easiest way to think of this problem and easy to implement.Time complexity: O(nlogn), naive sort is o(nlogn)Space complexity: O(n), for map and list 12345678910111213141516171819202122232425262728293031323334353637class Solution { public List&lt;String&gt; topKFrequent(String[] words, int k) { Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(String word:words){ map.put(word, map.getOrDefault(word, 0)+1); } List&lt;Map.Entry&lt;String, Integer&gt;&gt; l = new LinkedList&lt;&gt;(); for(Map.Entry&lt;String, Integer&gt; e:map.entrySet()){ l.add(e); } Collections.sort(l, new MyComparator());//just use our Comparator to sort List&lt;String&gt; ans = new LinkedList&lt;&gt;(); for(int i = 0;i&lt;=k-1;i++){ ans.add(l.get(i).getKey()); } return ans; }}/*Implement our own comparator for this problem, I will also use this Comparator in other methods(A little different in minHeap method).We can also use anonymous Comparaotr or Lambda function.*/class MyComparator implements Comparator&lt;Map.Entry&lt;String, Integer&gt;&gt; { public int compare(Map.Entry&lt;String, Integer&gt; e1, Map.Entry&lt;String, Integer&gt; e2){ String word1 = e1.getKey(); int freq1 = e1.getValue(); String word2 = e2.getKey(); int freq2 = e2.getValue(); if(freq1!=freq2){ return freq2-freq1; } else { return word1.compareTo(word2); } }} Max HeapMaintain a max heap and add all the words in it. Pop top K words to get the results.Time Complexity: O(nlogn + Klogn) = O(nlogn)Space Complexity: O(n), for heap 12345678910111213141516171819202122232425262728293031class Solution { public List&lt;String&gt; topKFrequent(String[] words, int k) { Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(String word:words){ map.put(word, map.getOrDefault(word, 0)+1); } PriorityQueue&lt;Map.Entry&lt;String, Integer&gt;&gt; pq = new PriorityQueue&lt;&gt;(new MyComparator()); for(Map.Entry&lt;String, Integer&gt; e:map.entrySet()){ pq.offer(e); } List&lt;String&gt; ans = new LinkedList&lt;&gt;(); for(int i = 0;i&lt;=k-1;i++){ ans.add(pq.poll().getKey()); } return ans; }}class MyComparator implements Comparator&lt;Map.Entry&lt;String, Integer&gt;&gt; { public int compare(Map.Entry&lt;String, Integer&gt; e1, Map.Entry&lt;String, Integer&gt; e2){ String word1 = e1.getKey(); int freq1 = e1.getValue(); String word2 = e2.getKey(); int freq2 = e2.getValue(); if(freq1!=freq2){ return freq2-freq1; } else { return word1.compareTo(word2); } }} Min HeapInstead of using a max heap, we only store Top K Freqency word we have met so far in our min heap.Time Complexity: O(nlogK), logK time for each wordSpace Complexity: O(K), since the largest number of words in our minheap is K 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution { public List&lt;String&gt; topKFrequent(String[] words, int k) { Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(String word:words){ map.put(word, map.getOrDefault(word, 0)+1); } MyComparator comparator = new MyComparator(); PriorityQueue&lt;Map.Entry&lt;String, Integer&gt;&gt; pq = new PriorityQueue&lt;&gt;(comparator); for(Map.Entry&lt;String, Integer&gt; e:map.entrySet()){ // If minHeap's size is smaller than K, we just add the entry if(pq.size()&lt;k){ pq.offer(e); } // Else, we compare the current entry with &quot;min&quot; entry in priority queue else { if(comparator.compare(e, pq.peek())&gt;0){ pq.poll(); pq.offer(e); } } } List&lt;String&gt; ans = new LinkedList&lt;&gt;(); for(int i = 0;i&lt;=k-1;i++){ ans.add(0, pq.poll().getKey());//the &quot;smaller&quot; entry poll out ealier } return ans; } }// The comparaotr is reversed as maxHeapclass MyComparator implements Comparator&lt;Map.Entry&lt;String, Integer&gt;&gt; { public int compare(Map.Entry&lt;String, Integer&gt; e1, Map.Entry&lt;String, Integer&gt; e2){ String word1 = e1.getKey(); int freq1 = e1.getValue(); String word2 = e2.getKey(); int freq2 = e2.getValue(); if(freq1!=freq2){ return freq1-freq2; } else { return word2.compareTo(word1); } }} Bucket sort + TrieThis method is derived from 347. Top K Frequent Elements. At 347, we use bucket sort(LinkedList in each bucket) to find top K frequency integers and we can choose any integer if there is a tie of frequency . But in this question, the problem is that when there is a tie of frequency, we need to compare the lexicographic order. Thus using bucket sort(LinkedList in each bucket) is not good.The way to solve the tie problem is to use either trie or BST.Time Complexity: O(nm) = O(n), m time to construct trie for each word and m is a constantSpace Complexity: O(nm) = O(n), m space for each bucket and m is a constant 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class Solution { public List&lt;String&gt; topKFrequent(String[] words, int k) { Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(String word:words){ map.put(word, map.getOrDefault(word, 0)+1); } Trie[] buckets = new Trie[words.length]; for(Map.Entry&lt;String, Integer&gt; e:map.entrySet()){ //for each word, add it into trie at its bucket String word = e.getKey(); int freq = e.getValue(); if(buckets[freq]==null){ buckets[freq] = new Trie(); } buckets[freq].addWord(word); } List&lt;String&gt; ans = new LinkedList&lt;&gt;(); for(int i = buckets.length-1;i&gt;=0;i--){ //for trie in each bucket, get all the words with same frequency in lexicographic order. Compare with k and get the result if(buckets[i]!=null){ List&lt;String&gt; l = new LinkedList&lt;&gt;(); buckets[i].getWords(buckets[i].root, l); if(l.size()&lt;k){ ans.addAll(l); k = k - l.size(); } else { for(int j = 0;j&lt;=k-1;j++){ ans.add(l.get(j)); } break; } } } return ans; }}class TrieNode { TrieNode[] children = new TrieNode[26]; String word = null;}class Trie { TrieNode root = new TrieNode(); public void addWord(String word){ TrieNode cur = root; for(char c:word.toCharArray()){ if(cur.children[c-'a']==null){ cur.children[c-'a'] = new TrieNode(); } cur = cur.children[c-'a']; } cur.word = word; } public void getWords(TrieNode node, List&lt;String&gt; ans){ //use DFS to get lexicograpic order of all the words with same frequency if(node==null){ return; } if(node.word!=null){ ans.add(node.word); } for(int i = 0;i&lt;=25;i++){ if(node.children[i]!=null){ getWords(node.children[i], ans); } } }} Bucket sort + BSTThe reason we use Trie is to break the tie of same word frequency. Thus we can easily use BST to replace Trie(In Java, we can use TreeMap or TreeSet)Time Complexity: O(n), not sureSpace Complexity: O(n), not sure 12345678910111213141516171819202122232425262728293031323334353637383940class Solution { public List&lt;String&gt; topKFrequent(String[] words, int k) { Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(String word:words){ map.put(word, map.getOrDefault(word, 0)+1); } TreeMap&lt;String, Integer&gt;[] buckets = new TreeMap[words.length]; for(Map.Entry&lt;String, Integer&gt; e:map.entrySet()){ String word = e.getKey(); int freq = e.getValue(); if(buckets[freq]==null){ buckets[freq] = new TreeMap&lt;&gt;((a, b)-&gt;{ return a.compareTo(b); }); } buckets[freq].put(word, freq); } List&lt;String&gt; ans = new LinkedList&lt;&gt;(); for(int i = buckets.length-1;i&gt;=0;i--){ if(buckets[i]!=null){ TreeMap&lt;String, Integer&gt; temp = buckets[i]; if(temp.size()&lt;k){ k = k - temp.size(); while(temp.size()&gt;0){ ans.add(temp.pollFirstEntry().getKey()); } } else { while(k&gt;0){ ans.add(temp.pollFirstEntry().getKey()); k--; } break; } } } return ans; }} Quick selectIf the question is to find Kth frequency word, quick select is a good solution and only cost O(n), for this question, after getting Top K frequency words by using quick select, we also need to do a sort to make sure they are in the right order.Time Complexity: O(n+KlogK), n time for quick select and KlogK time for sortSpace Complexity: O(n) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class Solution { public List&lt;String&gt; topKFrequent(String[] words, int k) { Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(String word:words){ map.put(word, map.getOrDefault(word, 0)+1); } Map.Entry&lt;String, Integer&gt;[] entrys = new Map.Entry[map.size()]; int index = 0; for(Map.Entry&lt;String, Integer&gt; e:map.entrySet()){ entrys[index] = e; index++; } //do quick select int start = 0; int end = entrys.length-1; int mid = 0; while(start&lt;=end){ mid = partition(entrys, start, end); if(mid == k-1){ break; } else if(mid&lt;k-1){ start = mid + 1; } else { end = mid - 1; } } List&lt;String&gt; ans = new LinkedList&lt;&gt;(); List&lt;Map.Entry&lt;String, Integer&gt;&gt; l = new LinkedList&lt;&gt;(); for(int i = 0;i&lt;=mid;i++){ l.add(entrys[i]); } //still need to sort these K words, because we only know they are in result, but not in right order Collections.sort(l, new MyComparator()); for(Map.Entry&lt;String, Integer&gt; e:l){ ans.add(e.getKey()); } return ans; } private int partition(Map.Entry&lt;String, Integer&gt;[] entrys, int start, int end){ int pivot = start; int left = start + 1; int right = end; MyComparator myComparator = new MyComparator(); while(true){ while(left&lt;=end){ if(myComparator.compare(entrys[left], entrys[pivot])&lt;=0){ left++; } else { break; } } while(right&gt;=start+1){ if(myComparator.compare(entrys[right], entrys[pivot])&gt;0){ right--; } else { break; } } if(left&gt;right){ break; } swap(entrys, left, right); } swap(entrys, pivot, right); return right; } private void swap(Map.Entry&lt;String, Integer&gt;[] entrys, int i, int j){ Map.Entry&lt;String, Integer&gt; a = entrys[i]; entrys[i] = entrys[j]; entrys[j] = a; }}class MyComparator implements Comparator&lt;Map.Entry&lt;String, Integer&gt;&gt; { public int compare(Map.Entry&lt;String, Integer&gt; e1, Map.Entry&lt;String, Integer&gt; e2){ String word1 = e1.getKey(); int freq1 = e1.getValue(); String word2 = e2.getKey(); int freq2 = e2.getValue(); if(freq1!=freq2){ return freq2-freq1; } else { return word1.compareTo(word2); } }}","link":"/2019/11/16/Leetcode/692/"},{"title":"Backtracking问题总结","text":"Backtracking总结Backtracking本质上就是DFS，相当于不停地往深处进行dfs，遇到不可能的情况就停止dfs回到上层。相当于有一些剪枝的DFS。 由于在进行backtracking的时候，在一次recursive中可能有多种情况(for loop)，那么我们在深入到下一层的时候需要已经改变的temporaryVector，但是很关键的一点是当我们完成所有下层的dfs以后，我们需要把temporaryVector变回来，因为我们还有没进行完的for loop要去做。 这种思想在dfs中很常见，比如经常需要把visited[]数组变成true去做dfs，结束后再变回false。 Backtracking模板 12345678910111213141516171819public ReturnVector Solution(input){ ReturnVector returnVector; TemporaryVector temporaryVector; dfs(input, returnVector, temporaryVector, index); return returnVector;}private void dfs(input, returnVector, temporaryVector, index){ if(Finished some condition){ returnVector.add(temporaryVector); return; } for(one possible situation in all situations){ temporaryVector deal with this situation and add it; dfs(input, returnVector, temporaryVector, changedIndex); temporaryVector return to its original state; }} N-Queens：NQueen问题，每一行我们只能放一个Queue，对于每一行我们都有N个位置可以放Queue，所以相当于递归深度是O(N)的DFS，每个深度都有N个选择。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class Solution { public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) { List&lt;List&lt;String&gt;&gt; ans = new LinkedList&lt;&gt;(); if(n==0) return ans; char[][] board = new char[n][n]; for(int i =0;i&lt;=board.length-1;i++){ for(int j =0;j&lt;=board[0].length-1;j++){ board[i][j] = '.'; } } solve(board, ans, 0); return ans; } private void solve(char[][] board, List&lt;List&lt;String&gt;&gt; ans, int line){ if(line==board.length){ List&lt;String&gt; l = helper(board); ans.add(l); return; } for(int i = 0;i&lt;=board.length-1;i++){ if(valid(board, line, i)){ board[line][i] = 'Q'; solve(board, ans, line+1); board[line][i] = '.'; } } } private boolean valid(char[][] board, int row, int column){ for(int i =0;i&lt;=board.length-1;i++){ if(board[row][i]=='Q' || board[i][column]=='Q'){ return false; } } for(int i = row-1, j=column-1;i&gt;=0 &amp;&amp; j&gt;=0;i--, j--){ if(board[i][j]=='Q'){ return false; } } for(int i = row-1, j=column+1;i&gt;=0&amp;&amp;j&lt;=board.length-1;i--,j++){ if(board[i][j]=='Q'){ return false; } } return true; } private List&lt;String&gt; helper(char[][] board){ List&lt;String&gt; ans = new LinkedList&lt;&gt;(); for(char[] c:board){ String s = String.valueOf(c); ans.add(s); } return ans; } } Generate Parentheses: 加括号只有两种情况，加(或者加)，所以不用for loop，同时我们helper(ans, left+1, right, n, s+'(');直接在s上加不会改变原来的s，所以结束dfs后也就不用再进行额外的操作。 123456789101112131415161718192021222324class Solution { public List&lt;String&gt; generateParenthesis(int n) { List&lt;String&gt; ans = new LinkedList&lt;&gt;(); if(n==0) return ans; int left = 0; int right = 0; helper(ans, left, right, n, &quot;&quot;); return ans; } private void helper(List&lt;String&gt; ans , int left, int right, int n, String s){ if(left==n &amp;&amp; right == n){ ans.add(s); return; } if(left&lt;n){ helper(ans, left+1, right, n, s+'('); } if(left&gt;right){ helper(ans, left, right+1, n, s+')'); } }} 以下这六道题都有类似的结构，前一道是不含duplicate，后一道是含duplicate，含duplicate的需要进行sort。 39与40题是类似题目，也都是很显而易见的backtracking。这里我们要注意到，对于同一层的recursive，下面会有很多种可能的situation，这里面会包含有不合法的situation，比如40题中的[1 1 6 7]会产生两个[1 7]。这种时候要格外小心，比如40题我们并不是所有candidate[i]==candiate[i-1]的情况都不要(if(i&gt;0 &amp;&amp; candidates[i]==candidates[i-1]))，如果这么写[1 1 6]就被排掉了；而是对于这一层的recursive，如果某个candidate不是第一次出现而且还和前面相等，那说明不要它39. Combination Sum: 12345678910111213141516171819202122232425class Solution { public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) { List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); List&lt;Integer&gt; temp = new LinkedList&lt;&gt;(); dfs(ans, temp, candidates, target, 0); return ans; } private void dfs(List&lt;List&lt;Integer&gt;&gt; ans ,List&lt;Integer&gt; l, int[] candidates, int target, int pos){ if(target==0){ ans.add(new LinkedList&lt;&gt;(l)); return; } if(target&lt;0){ return; } for(int i = pos;i&lt;=candidates.length-1;i++){ l.add(candidates[i]); dfs(ans, l, candidates, target-candidates[i], i); l.remove(l.size()-1); } }} Combination Sum II: 12345678910111213141516171819202122232425262728class Solution { public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) { Arrays.sort(candidates); List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); List&lt;Integer&gt; temp = new LinkedList&lt;&gt;(); dfs(ans, temp, candidates, target, 0); return ans; } private void dfs(List&lt;List&lt;Integer&gt;&gt; ans ,List&lt;Integer&gt; l, int[] candidates, int target, int pos){ if(target==0){ ans.add(new LinkedList&lt;&gt;(l)); return; } if(target&lt;0){ return; } for(int i = pos;i&lt;=candidates.length-1;i++){ if(i&gt;pos &amp;&amp; candidates[i]==candidates[i-1])//不是这次recursive第一次出现且与前面的数相同的，我们不要 continue; l.add(candidates[i]); dfs(ans, l, candidates, target-candidates[i], i+1); l.remove(l.size()-1); } }} 46与47类似于39与40，47的条件也需要好好思考：到底哪些situation会进入到下一层的recursive，哪些是重复情况不能进入下一层的recursive。46. Permutations: 1234567891011121314151617181920212223242526class Solution { public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); boolean[] visited = new boolean[nums.length]; List&lt;Integer&gt; l = new LinkedList&lt;&gt;(); dfs(ans, l, nums, visited); return ans; } private void dfs(List&lt;List&lt;Integer&gt;&gt; ans, List&lt;Integer&gt; l, int[] nums, boolean[] visited){ if(l.size()==nums.length){ ans.add(new LinkedList&lt;&gt;(l)); return; } for(int i =0;i&lt;=nums.length-1;i++){ if(visited[i]==false){ visited[i] = true; l.add(nums[i]); dfs(ans, l, nums, visited); visited[i] = false; l.remove(l.size()-1); } } }} Permutations II: 1234567891011121314151617181920212223242526272829class Solution { public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) { Arrays.sort(nums); List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); boolean[] visited = new boolean[nums.length]; List&lt;Integer&gt; l = new LinkedList&lt;&gt;(); dfs(ans, l, nums, visited); return ans; } private void dfs(List&lt;List&lt;Integer&gt;&gt; ans, List&lt;Integer&gt; l, int[] nums, boolean[] visited){ if(l.size()==nums.length){ ans.add(new LinkedList&lt;&gt;(l)); return; } for(int i =0;i&lt;=nums.length-1;i++){ if(visited[i]==false){ if(i&gt;0 &amp;&amp; nums[i]==nums[i-1] &amp;&amp; visited[i-1]==true)//条件很关键，要好好想想 continue; visited[i] = true; l.add(nums[i]); dfs(ans, l, nums, visited); visited[i] = false; l.remove(l.size()-1); } } }} Subsets: 123456789101112131415161718class Solution { public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) { List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); List&lt;Integer&gt; l = new LinkedList&lt;&gt;(); dfs(ans, l, nums, 0); return ans; } private void dfs(List&lt;List&lt;Integer&gt;&gt; ans, List&lt;Integer&gt; l, int[] nums, int pos){ ans.add(new LinkedList&lt;&gt;(l)); for(int i = pos;i&lt;=nums.length-1;i++){ l.add(nums[i]); dfs(ans, l, nums, i+1); l.remove(l.size()-1); } }} Subsets II: 123456789101112131415161718192021class Solution { public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) { Arrays.sort(nums); List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); List&lt;Integer&gt; l = new LinkedList&lt;&gt;(); dfs(ans, l, nums, 0); return ans; } private void dfs(List&lt;List&lt;Integer&gt;&gt; ans, List&lt;Integer&gt; l, int[] nums, int pos){ ans.add(new LinkedList&lt;&gt;(l)); for(int i = pos;i&lt;=nums.length-1;i++){ if(i&gt;pos &amp;&amp; nums[i]==nums[i-1]) continue; l.add(nums[i]); dfs(ans, l, nums, i+1); l.remove(l.size()-1); } }} Sudoku Solver：这道题和上面的backtracking有些许不同，原因是它不需要返回而是直接在原来的board中修改。我们之前的backtracking的思路都是在这一层的recursive进行修改，进行下面的dfs，完成后把这一层恢复原状。这道题如果还是直接恢复原状的话会相当于什么都不做，所以我们的dfs带有boolean的返回值：如果我们成功所有下层的dfs都解决了，那么我们不需要恢复，否则的话还是恢复。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Solution { public void solveSudoku(char[][] board) { solve(board, 0, 0); } private boolean solve(char[][] board, int i, int j){ if(i==8 &amp;&amp; j==9){ return true; } if(j==9){ i++; j = 0; } if(board[i][j]!='.'){ return solve(board, i, j+1); } else{ for(int num = 1;num&lt;=9;num++){ char c = (char)(num+'0'); if(valid(board, i, j, c)){ board[i][j] = c; if(solve(board, i, j+1)){ return true; }else{ board[i][j] = '.'; } } } return false; } } private boolean valid(char[][] board, int row ,int column, char c){ for(int i =0;i&lt;=board.length-1;i++){ if(board[i][column]==c||board[row][i]==c){ return false; } } int x = row/3*3; int y = column/3*3; for(int i =x;i&lt;=x+2;i++){ for(int j=y;j&lt;=y+2;j++){ if(board[i][j]==c){ return false; } } } return true; } }","link":"/2019/10/23/Leetcode/Backtracking%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"Basic Calculator类型题","text":"","link":"/2019/12/09/Leetcode/Basic%20Calculator%E7%B1%BB%E5%9E%8B%E9%A2%98/"},{"title":"Binary Search总结","text":"Binary Search And Search Problem总结Search问题的核心思想只有一个，就是每一步都会减少搜索域 Binary Search的核心思想是：每次只取搜索域的一半，舍弃另一半，我们的搜索域不断一半一半的减小最后找到结果，所以时间复杂度才会是O(logn)Binary search有固定的书写模板，容易出现问题的点是判断终止条件，主要有三种写法：start&lt;=end，start&lt;end，start+1&lt;end。我觉得采用第三种写法比较好，因为不会出现死循环的问题(比如使用start&lt;end，但是更改条件的时候写的是start=mid，这就会造成死循环，mid一直等于start，start又一直等于mid)，不过需要在最后判断一下left和right指针的结果。但是有的题型还是会用其他写法。 Binary Search By IndexRotated Array类型题： Search in Rotated Sorted Array：最重要的一道题，主要的思想是如果我们的pivot在左半部分(3456712)，那么rotated的数组的左半部分是递增的，也就是我们如果我们的value在左半部分这一递增的区间，我们就可以扔掉右半部分只管左半部分，反之亦然。所以我们可以看出来关键就是要每次舍弃掉一半的搜索区间。 follow-up是数组中会有重复的数，这样的情况下做法是把重复的情况单独拎出来 123456789101112131415161718192021222324252627282930313233343536373839class Solution { public int search(int[] nums, int target) { if(nums.length==0) return -1; int left = 0; int right = nums.length-1; while(left+1&lt;right){ int mid = left + (right-left)/2; if(nums[mid]==target) return mid; if(nums[left]&lt;nums[mid]){ if(target&gt;=nums[left] &amp;&amp; target&lt;=nums[mid]){ right = mid; } else { left = mid; } } else { if(target&gt;=nums[mid] &amp;&amp; target&lt;=nums[right]){ left = mid; } else { right = mid; } } } if(nums[left]==target) return left; else if(nums[right]==target){ return right; } else { return -1; } }} Search in Rotated Sorted Array II: 需要多考虑一下如果nums[left]==nums[right]的情况 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution { public boolean search(int[] nums, int target) { if(nums.length==0) return false; int left = 0; int right = nums.length-1; while(left+1&lt;right){ int mid = left + (right-left)/2; if(nums[mid]==target) return true; if(nums[left]&lt;nums[mid]){ if(target&gt;=nums[left] &amp;&amp; target&lt;=nums[mid]){ right = mid; } else { left = mid; } } else if(nums[left]&gt;nums[mid]){ if(target&gt;=nums[mid] &amp;&amp; target&lt;=nums[right]){ left = mid; } else { right = mid; } } else { left++; } } if(nums[left]==target) return true; else if(nums[right]==target){ return true; } else { return false; } }} Find Minimum in Rotated Sorted Array:与上面两道题类似，考虑三种情况：不rotated；rotated的pivot在左半部分；rotated的pivot在右半部分： 1234567891011121314151617181920212223242526class Solution { public int findMin(int[] nums) { int start = 0; int end = nums.length-1; while(start+1&lt;end){ int mid = start + (end-start)/2; //none-rotated if(nums[start]&lt;nums[end]){ return nums[start]; } if(nums[start]&lt;nums[mid]){//pivot on left part start = mid; } else {//pivot on right part end = mid; } } if(nums[start]&lt;nums[end]) return nums[start]; else return nums[end]; }} Find Minimum in Rotated Sorted Array II 12345678910111213141516171819202122232425262728class Solution { public int findMin(int[] nums) { int start = 0; int end = nums.length-1; while(start+1&lt;end){ int mid = start + (end-start)/2; //none-rotated if(nums[start]&lt;nums[end]){ return nums[start]; } if(nums[start]&lt;nums[mid]){//pivot on left part start = mid; } else if((nums[start]&gt;nums[mid])) {//pivot on right part end = mid; } else { start++; } } if(nums[start]&lt;nums[end]) return nums[start]; else return nums[end]; }} Search Matrix类型题： Search a 2D Matrix:很简单，就当做一个连续的array就好。 123456789101112131415161718192021222324252627282930313233class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; if(m==0) return false; int n = matrix[0].length; if(n==0) return false; int start = 0; int end = m*n-1; while(start+1&lt;end){ int mid = start+ (end-start)/2; int row = mid/n; int column = mid%n; if(matrix[row][column]==target){ return true; } else if(matrix[row][column]&lt;target){ start = mid; } else{ end = mid; } } if(matrix[start/n][start%n]==target || matrix[end/n][end%n] ==target) return true; else return false; }} Search a 2D Matrix II：算是binary search的一种变种吧，本质上还是要减少搜索的空间。所以我们不从左上或者右下开始搜索，而是从右上或者左下，这样每次我们都能确定往何处移动。时间复杂度是O(m+n) 12345678910111213141516171819202122class Solution { public boolean searchMatrix(int[][] matrix, int target) { int m = matrix.length; if(m==0) return false; int n = matrix[0].length; int i = m-1; int j = 0; while(i&gt;=0 &amp;&amp; j&lt;=n-1){ if(matrix[i][j] == target){ return true; } else if(matrix[i][j]&lt;target){ j++; } else { i--; } } return false; }} Binary Search By Range:类似的题目和很好的总结：https://leetcode.com/problems/k-th-smallest-prime-fraction/discuss/115819/Summary-of-solutions-for-problems-%22reducible%22-to-LeetCode-378https://leetcode.com/problems/find-k-th-smallest-pair-distance/discuss/109082/Approach-the-problem-using-the-%22trial-and-error%22-algorithm Find the Duplicate Number:这道题有两个做法，第一个做法是LinkedList Cycle II的思想(见LinkedList Cycle类型题)。第二个做法就是Binary Search By Range。这道题我们最大的number是数组的长度减一，也就是说重复的数一定在这个范围内，我们使用binary search，start是1，end是最大number，然后我们每次search都遍历数组并统计小于等于mid的数量，如果这个数量大于mid，由鸽巢原理我们确认这个重复的数一定在左半部分，否则在右半部分，这就相当于每次减少了搜索域。We know that the whole range is “too crowded” and thus that the first half or the second half of the range is too crowded (if both weren’t, then neither would be the whole range). So you check to know whether the first half is too crowded, and if it isn’t, you know that the second half is. 想这种问题的时候不要去想为什么我们这样by range search最后的结果会在array中呢？这样想很容易就会绕进去出不来了！我们要明确这时候我们是search by range而不再是search by index，search by index的时候我们当然知道元素一定在array中，而search by range的时候我们需要知道的就是：已知结果在这个range中，我们确保结果一直在搜索域，经过不断收敛那么最后一定会找到结果，那这个结果也就自然而然一定在array中了。有一个点需要注意：与普通的binary search不同，我们的判断条件没有count==K，因为即使等于也不代表找到的是那个number，有可能略大于，但也正好有K个count，所以一定要等到最后收敛完成 12345678910111213141516171819202122class Solution { public int findDuplicate(int[] nums) { int start = 1; int end = nums.length-1; while(start&lt;end){ int mid = start + (end-start)/2; int count = 0; for(int num:nums){ if(num&lt;=mid) count++; } if(count&gt;mid){ end = mid; } else { start = mid+1; } } return start; }} Kth Smallest Element in a Sorted Matrix：首先拿到这道题，我们看到Kth这个关键词就要往top k问题去想，topK问题的解决方法无外乎PriorityQueue, Quick Select两种办法。所以我们最简单可以想到的就是使用PriorityQueue(见Top K总结)。另一个想法是binary search，但是按照普通的binary search的search by index我们发现并不能解决这个问题，所以应该采用的是search by range(也就是根据number的range进行搜索)。By range搜索会有一个count，这里就是K，我们每次进行binary search，然后统计小于等于mid的count，然后和K进行比较进行搜索域的减小。 这道题在进行小于等于mid的count计数的时候有一个巧妙方法，就是利用240题目类似的方法，从右上或左下开始找，这样只需要O(n)就可以找到小于等于mid的个数，所以时间复杂度是O(nlogn) Kth Smallest Number in Multiplication Table Find K-th Smallest Pair Distance K-th Smallest Prime Fraction 其他binary search类型题： Median of Two Sorted Arrays：很难的题目，告诉了我们binary search不仅局限在可以search index/range，也可以search index与index之间的split点。这道题的核心思想是median的作用是把数组分成两部分，左半部分的值一定小于右半部分，所以我们在第一个array中找到一个split点，第二个array的split点也就随之确定了，我们需要确保第一个array split点的左侧的number小于第二个array split点的右侧的number以及第二个array split点的左侧的number小于第一个array split点的右侧的number，对于split点的选择，自然而然可以选择binary search。ps.1 Why n &gt;= m? Because I have to make sure j is non-nagative since 0 &lt;= i &lt;= m and j = (m + n + 1)/2 - i. If n &lt; m , then j may be nagative, that will lead to wrong result.https://leetcode.com/problems/median-of-two-sorted-arrays/discuss/2481/Share-my-O(log(min(mn)))-solution-with-explanation 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int m = nums1.length; int n = nums2.length; if(m&gt;n){ return findMedianSortedArrays(nums2, nums1); } int start = 0; int end = nums1.length; while(start&lt;=end){ int mid1 = start + (end-start)/2; int mid2 = (m+n+1)/2-mid1; if(mid1&gt;0 &amp;&amp; mid2&lt;n &amp;&amp; nums1[mid1-1]&gt;nums2[mid2]){ end = mid1-1; } else if(mid1&lt;m &amp;&amp; mid2&gt;0 &amp;&amp; nums1[mid1]&lt;nums2[mid2-1]){ start = mid1+1; } else {//perfect match //corner case int leftMax = 0; int rightMin = 0; if(mid1==0) leftMax = nums2[mid2-1]; else if(mid2==0) leftMax = nums1[mid1-1]; else{ leftMax = Math.max(nums2[mid2-1], nums1[mid1-1]); } if((m+n)%2!=0) return leftMax; if(mid1==m){ rightMin = nums2[mid2]; } else if(mid2==n){ rightMin = nums1[mid1]; } else { rightMin = Math.min(nums2[mid2], nums1[mid1]); } return (leftMax+rightMin)/2.0; } } return -1.0; }}","link":"/2019/10/23/Leetcode/Binary%20Search%E6%80%BB%E7%BB%93/"},{"title":"DP慢慢总结","text":"DP类型题总结 Longest Increasing Subsequence https://leetcode.com/problems/longest-increasing-subsequence/Longest Common SubsequenceLongest Commen Substring Longest Bitonic Subsequence: https://www.geeksforgeeks.org/longest-bitonic-subsequence-dp-15/ Maximum weight transformation of a given string: https://www.geeksforgeeks.org/maximum-weight-transformation-of-a-given-string/ House Robber类型题：选择偷还是不偷这家。 House Robber: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*198. House RobberEasy3160103FavoriteShareYou are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.Given a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.Example 1:Input: [1,2,3,1]Output: 4Explanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4.Example 2:Input: [2,7,9,3,1]Output: 12Explanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12.*/class Solution { /* rob(x) calculate the maximum value we can rob at position n. 1. rob(n) = rob(n-1) 2. rob(n) = rob(n-2) + nums[n] return max(case1, case2) recursive and have mant sub-problems. */ public int rob(int[] nums) { if(nums.length==0) return 0; int len = nums.length; int[] dp = new int[len+1]; dp[0] = 0; dp[1] = nums[0]; for(int i = 2;i&lt;=dp.length-1;i++){ dp[i] = Math.max(dp[i-1], dp[i-2]+nums[i-1]); } return dp[len]; }} House Robber II: 与上一道题不同的地方输入是一个环，我们可以考虑第一家偷或者不偷的情况。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/*213. House Robber IIMedium111439FavoriteShareYou are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed. All houses at this place are arranged in a circle. That means the first house is the neighbor of the last one. Meanwhile, adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.Given a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.Example 1:Input: [2,3,2]Output: 3Explanation: You cannot rob house 1 (money = 2) and then rob house 3 (money = 2), because they are adjacent houses.Example 2:Input: [1,2,3,1]Output: 4Explanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4.*/class Solution { public int rob(int[] nums) { if(nums==null || nums.length==0) return 0; if(nums.length==1){ return nums[0]; } int len = nums.length; return Math.max(robWithIndex(nums, 0, len-2), robWithIndex(nums, 1, len-1)); } public int robWithIndex(int[] nums, int start, int end){ int[] dp = new int[end-start+1+1]; dp[0] = 0; dp[1] = nums[start]; for(int i = 2;i&lt;=dp.length-1;i++){ dp[i] = Math.max(dp[i-1], dp[i-2]+nums[i+start-1]); } return dp[dp.length-1]; }} House Robber III: https://leetcode.com/problems/house-robber-iii/discuss/79330/Step-by-step-tackling-of-the-problem 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/*337. House Robber IIIMedium184538FavoriteShareThe thief has found himself a new place for his thievery again. There is only one entrance to this area, called the &quot;root.&quot; Besides the root, each house has one and only one parent house. After a tour, the smart thief realized that &quot;all houses in this place forms a binary tree&quot;. It will automatically contact the police if two directly-linked houses were broken into on the same night.Determine the maximum amount of money the thief can rob tonight without alerting the police.Example 1:Input: [3,2,3,null,3,null,1] 3 / \\ 2 3 \\ \\ 3 1Output: 7 Explanation: Maximum amount of money the thief can rob = 3 + 3 + 1 = 7.Example 2:Input: [3,4,5,1,3,null,1] 3 / \\ 4 5 / \\ \\ 1 3 1Output: 9Explanation: Maximum amount of money the thief can rob = 4 + 5 = 9.*//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int rob(TreeNode root) { Map&lt;TreeNode, Integer&gt; map = new HashMap&lt;&gt;(); return rob(root, map); } private int rob(TreeNode node, Map&lt;TreeNode, Integer&gt; map){ if(node==null) return 0; if(map.containsKey(node)){ return map.get(node); } int notRobRoot = rob(node.left, map) + rob(node.right, map); int robRoot = node.val; if(node.left!=null){ robRoot = robRoot + rob(node.left.left, map) + rob(node.left.right, map); } if(node.right!=null){ robRoot = robRoot + rob(node.right.left, map) + rob(node.right.right, map); } int ans = Math.max(notRobRoot, robRoot); map.put(node, ans); return ans; }} Word Break类型题 Word Break： isWord(n) = isWord(i) &amp;&amp; (s.substring(i) in HashSet), for i belongs to [0, n) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*139. Word BreakMedium2838155FavoriteShareGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, determine if s can be segmented into a space-separated sequence of one or more dictionary words.Note:The same word in the dictionary may be reused multiple times in the segmentation.You may assume the dictionary does not contain duplicate words.Example 1:Input: s = &quot;leetcode&quot;, wordDict = [&quot;leet&quot;, &quot;code&quot;]Output: trueExplanation: Return true because &quot;leetcode&quot; can be segmented as &quot;leet code&quot;.Example 2:Input: s = &quot;applepenapple&quot;, wordDict = [&quot;apple&quot;, &quot;pen&quot;]Output: trueExplanation: Return true because &quot;applepenapple&quot; can be segmented as &quot;apple pen apple&quot;. Note that you are allowed to reuse a dictionary word.Example 3:Input: s = &quot;catsandog&quot;, wordDict = [&quot;cats&quot;, &quot;dog&quot;, &quot;sand&quot;, &quot;and&quot;, &quot;cat&quot;]Output: false*/class Solution { public boolean wordBreak(String s, List&lt;String&gt; wordDict) { Set&lt;String&gt; set = new HashSet&lt;&gt;(wordDict); int n = s.length(); boolean[] dp = new boolean[n+1]; dp[0] = true; for(int i = 0;i&lt;=n-1;i++){ for(int j = 0;j&lt;=i;j++){ if(set.contains(s.substring(j, i+1)) &amp;&amp; dp[j-1+1]){ dp[i+1] = true; break; } } } return dp[n]; }} Word Break II:这道题用List[]储存结果会造成TLE，所以使用HashMap存储结果，也就是使用Top-down DFS+Memorization 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889/*140. Word Break IIHard1248282FavoriteShareGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, add spaces in s to construct a sentence where each word is a valid dictionary word. Return all such possible sentences.Note:The same word in the dictionary may be reused multiple times in the segmentation.You may assume the dictionary does not contain duplicate words.Example 1:Input:s = &quot;catsanddog&quot;wordDict = [&quot;cat&quot;, &quot;cats&quot;, &quot;and&quot;, &quot;sand&quot;, &quot;dog&quot;]Output:[ &quot;cats and dog&quot;, &quot;cat sand dog&quot;]Example 2:Input:s = &quot;pineapplepenapple&quot;wordDict = [&quot;apple&quot;, &quot;pen&quot;, &quot;applepen&quot;, &quot;pine&quot;, &quot;pineapple&quot;]Output:[ &quot;pine apple pen apple&quot;, &quot;pineapple pen apple&quot;, &quot;pine applepen apple&quot;]Explanation: Note that you are allowed to reuse a dictionary word.Example 3:Input:s = &quot;catsandog&quot;wordDict = [&quot;cats&quot;, &quot;dog&quot;, &quot;sand&quot;, &quot;and&quot;, &quot;cat&quot;]Output:[]*/class Solution { public List&lt;String&gt; wordBreak(String s, List&lt;String&gt; wordDict) { Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;&gt;(); Set&lt;String&gt; set= new HashSet&lt;&gt;(wordDict); return dfs(s, map, set); } private List&lt;String&gt; dfs(String s, Map&lt;String, List&lt;String&gt;&gt; map, Set&lt;String&gt; set){ if(map.containsKey(s)){ return map.get(s); } List&lt;String&gt; ans = new LinkedList&lt;&gt;(); if(s.length()==0){ ans.add(&quot;&quot;); return ans; } for(int i = 0 ;i&lt;=s.length()-1;i++){ String s1 = s.substring(0, i); String s2 = s.substring(i); if(set.contains(s2)){ List&lt;String&gt; l = dfs(s1, map, set); for(String ss:l){ if(ss.length()==0){ ans.add(s2); } else { ans.add(ss+&quot; &quot;+s2); } } } else { continue; } } map.put(s, ans); return ans; } } Concatenated Words：与Word Break I相似，拆分成对于每一个List中的String，去看所有长度小于它的Word能否构成这个String，能的话加入结果。所以这道题我们先排序，然后所有排在该String前面的词放入HashSet中，也就变成了Word Break I。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/*472. Concatenated WordsHard36073FavoriteShareGiven a list of words (without duplicates), please write a program that returns all concatenated words in the given list of words.A concatenated word is defined as a string that is comprised entirely of at least two shorter words in the given array.Example:Input: [&quot;cat&quot;,&quot;cats&quot;,&quot;catsdogcats&quot;,&quot;dog&quot;,&quot;dogcatsdog&quot;,&quot;hippopotamuses&quot;,&quot;rat&quot;,&quot;ratcatdogcat&quot;]Output: [&quot;catsdogcats&quot;,&quot;dogcatsdog&quot;,&quot;ratcatdogcat&quot;]Explanation: &quot;catsdogcats&quot; can be concatenated by &quot;cats&quot;, &quot;dog&quot; and &quot;cats&quot;; &quot;dogcatsdog&quot; can be concatenated by &quot;dog&quot;, &quot;cats&quot; and &quot;dog&quot;; &quot;ratcatdogcat&quot; can be concatenated by &quot;rat&quot;, &quot;cat&quot;, &quot;dog&quot; and &quot;cat&quot;.Note:The number of elements of the given array will not exceed 10,000The length sum of elements in the given array will not exceed 600,000.All the input string will only include lower case letters.The returned elements order does not matter.*/class Solution { public List&lt;String&gt; findAllConcatenatedWordsInADict(String[] words) { List&lt;String&gt; ans = new LinkedList&lt;&gt;(); if(words == null || words.length&lt;=1){ return ans; } Arrays.sort(words, (a, b)-&gt;{ return a.length()-b.length(); }); Set&lt;String&gt; set = new HashSet&lt;&gt;(); set.add(words[0]); for(int i =1;i&lt;=words.length-1;i++){ if(dfs(words[i], set)){ ans.add(words[i]); } set.add(words[i]); } return ans; } private boolean dfs(String word, Set&lt;String&gt; set){//this part is the same as 139 int n = word.length(); boolean[] dp = new boolean[n+1]; dp[0] = true; for(int i = 0;i&lt;=n-1;i++){ for(int j = 0;j&lt;=i;j++){ if(set.contains(word.substring(j, i+1)) &amp;&amp; dp[j-1+1]){ dp[i+1] = true; break; } } } return dp[n]; }}","link":"/2019/11/06/Leetcode/DP%E6%85%A2%E6%85%A2%E6%80%BB%E7%BB%93/"},{"title":"Deep copy类型题总结","text":"Deep copy类型题总结这种类型题不难，只有两道代表类型题，一道是deep copy linkedlist，一道是deep copy graph。 最直观的想法就是就是使用HashMap，首先把node都先copy一遍，然后再连接他们。 提升一点的做法是使用dfs，在copy的过程中边copy边连接。注意，对于使用dfs copy graph我们不需要visited[]数组，我们可以直接通过判断Map中有没有该node来确认是否visited。 对于copy linkedlist，有一个提升空间复杂度的做法。Follow Up 如果不适用额外的辅助存储空间： 第一步：将每个节点复制并插入相邻节点中。如1-&gt;2-&gt;3-&gt;NULL变为：1-&gt;1’-&gt;2-&gt;2’-&gt;3-&gt;3’-&gt;NULL。 第二步：接下来连接Random指针，如果存在一条Random指针从A指向B，那么将A-&gt;next的Random指针指向B-&gt;next。 第三步：将链表拆开。A=head, A’=head-&gt;next; A-&gt;next=A-&gt;next-&gt;next；A’-&gt;next=A’-&gt;next-&gt;next; … 时间复杂度O(n)，额外空间复杂度O(1) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*// Definition for a Node.class Node { public int val; public Node next; public Node random; public Node() {} public Node(int _val,Node _next,Node _random) { val = _val; next = _next; random = _random; }};*/class Solution { public Node copyRandomList(Node head) { if(head==null) return null; Node cur = head; while(cur!=null){ Node newNode = new Node(cur.val); newNode.next = cur.next; cur.next = newNode; cur = cur.next.next; } cur = head; while(cur!=null){ if(cur.random!=null){ cur.next.random = cur.random.next; } cur = cur.next.next; } Node newNode = new Node(); Node newNode2 = new Node(); Node n2 = newNode2; Node n1 = newNode; cur = head; while(cur!=null){ n1.next = cur; n2.next = cur.next; cur = cur.next.next; n1 = n1.next; n2 = n2.next; n1.next = null; n2.next = null; } return newNode2.next; }}","link":"/2019/10/03/Leetcode/Deep%20copy%E7%B1%BB%E5%9E%8B%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"Graph类型题总结","text":"Graph类型题总结Graph类型题常见的有1. Topological sorting 2. connected component 3. find cycle。同时要注意有向/无向的区别。 Topological sortingToplogical sorting一定是针对有向图，常见的做法是 DFS遍历有向图，最早被遍历完的是需要排到最后面的，时间复杂度O(m+n) 设置三种遍历时的状态，VISITED = 1, UNVISITED = 0, VISITING = -1 DFS每一个node，如果： node的状态是UNVISITED: 将状态变为VISITING，然后DFS所有它指向的node，所有指向的node都遍历完以后再变为VISITED，加入到结果中 node的状态是VISITED: 说明这个node已经加入到结果中了，直接返回 node的状态是VISITING: 证明图中有环 注意: DFS的结果是最后执行的先加入到结果中去 BFS，通过判断indegree数量，indegree先为零的先拍在前面，时间复杂度O(n+m) 新建一个数组，数组中储存所有node的indegree数量 遍历数组，找到所有的source node(indegree为0)加入到Queue中 依次从Queue中弹出node加入到排序结果中，对于该node指向的nodes，它们的indegree减1，同时判断它们是不是indegree变成0，是的话加入Queue 最终如果排序结果的长度与原长度相等，证明所有node都参与了排序，不存在环，否则证明有环 Course Schedule: topological sorting的代表性题目，可以使用DFS和BFS来做，这道题本质上是检测有没有环，所以我们可以看出来，进行Toplogical sort的前提就是是DAG(无环)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution { //DFS private final int UNVISITED = 0; private final int VISITED = 1; private final int VISITING = -1; public boolean canFinish(int numCourses, int[][] prerequisites) { //construct graph List&lt;List&lt;Integer&gt;&gt; al = new LinkedList(); for(int i =0;i&lt;=numCourses-1;i++){ al.add(new LinkedList&lt;&gt;()); } for(int[] pre:prerequisites){ int start = pre[1]; int end = pre[0]; al.get(start).add(end); } //do dfs int[] visited = new int[numCourses]; for(int i =0;i&lt;=numCourses-1;i++){ if(dfs(i, al, visited)==false){ return false; } } return true; } private boolean dfs(int node, List&lt;List&lt;Integer&gt;&gt; al, int[] visited){ if(visited[node]==VISITED){ return true; } else if(visited[node]==VISITING){ return false; } else { visited[node] = VISITING; for(int i:al.get(node)){ if(dfs(i, al, visited)==false){ return false; } } visited[node] = VISITED; return true; } }} Course Schedule II: topological sorting的代表性题目，可以使用DFS和BFS来做 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Solution { // BFS public int[] findOrder(int numCourses, int[][] prerequisites) { // construct graph and indegree count List&lt;List&lt;Integer&gt;&gt; al = new LinkedList&lt;&gt;(); int[] indegree = new int[numCourses]; for(int i = 0;i&lt;=numCourses-1;i++){ al.add(new LinkedList&lt;&gt;()); } for(int[] pre:prerequisites){ int start = pre[1]; int end = pre[0]; al.get(start).add(end); indegree[end]++; } Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;(); for(int i =0;i&lt;=numCourses-1 ;i++){ if(indegree[i]==0){ q.offer(i); } } List&lt;Integer&gt; ans = new LinkedList&lt;&gt;(); while(!q.isEmpty()){ int node = q.poll(); ans.add(node); for(int j:al.get(node)){ indegree[j]--; if(indegree[j]==0){ q.offer(j); } } } int[] res = new int[ans.size()]; for(int i =0;i&lt;=ans.size()-1;i++){ res[i] = ans.get(i); } if(res.length==numCourses){ return res; } else { return new int[0]; } }} Alien Dictionary: 字母的前后顺序关系是一种有向图，又由于题中说可能有多种结果，所以使用topological sort 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution { public String alienOrder(String[] words) { Map&lt;Character, Set&lt;Character&gt;&gt; map = new HashMap&lt;&gt;();//这里必须用set，因为针对相同的edge如果重复计入会导致indegree问题 Map&lt;Character, Integer&gt; indegree = new HashMap&lt;&gt;(); for(String s: words){ for(char c: s.toCharArray()){ indegree.put(c,0);//所有字母都要有indegree map.put(c, new HashSet&lt;&gt;());//所有字母都要有map } } for(int i =1;i&lt;=words.length-1;i++){ String s1 = words[i-1]; String s2 = words[i]; for(int j = 0;j&lt;=s1.length()-1;j++){ char c1 = s1.charAt(j); char c2 = s2.charAt(j); if(c1!=c2){ Set&lt;Character&gt; l = map.getOrDefault(c1, new HashSet&lt;&gt;()); if(!l.contains(c2)){//非常重要，使用set判断是不是已经有了这个edge，以此来保证indegree不会出错 l.add(c2); map.put(c1,l); indegree.put(c2, indegree.getOrDefault(c2, 0)+1); } break; } } } String ans = &quot;&quot;; Queue&lt;Character&gt; q = new LinkedList&lt;&gt;(); for(Map.Entry&lt;Character, Integer&gt; e: indegree.entrySet()){ char key = e.getKey(); int value = e.getValue(); if(value==0){ q.offer(key); } } while(!q.isEmpty()){ char c= q.poll(); ans = ans + c; for(char ch:map.get(c)){ indegree.put(ch, indegree.get(ch)-1); if(indegree.get(ch)==0){ q.offer(ch); } } } if(ans.length()!=indegree.size()){ return &quot;&quot;; } else { return ans; } }} Connect Component找connected components (dfs, bfs, union find)。对于找无向图的connected component还是很简单的，无非是前面提到的三种方法，如果对于有向图要寻找SCC(Strong Connected Component)则比较复杂。三种方法的时间复杂度都是O(m+n)200. Number of Islands：可以把矩阵抽象成graph，这道题可以不用设置visited[]数组，直接改变grid的值即可(visited过的变成0) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Solution { //DFS public int numIslands(char[][] grid) { /*11110 1-1-1-1 0 | | | 1-1 0 1 0110101100000000visited[][] */ int m = grid.length; if(m==0) return 0; int n = grid[0].length; int ans = 0; boolean[][] visited = new boolean[m][n]; for(int i =0;i&lt;=m-1;i++){ for(int j =0;j&lt;=n-1;j++){ if(visited[i][j]==false &amp;&amp; grid[i][j]=='1'){ DFS(grid, visited, i, j); ans++; } } } return ans; } private void DFS(char[][] grid, boolean[][] visited, int i, int j){ if(!(i&lt;=grid.length-1 &amp;&amp; i&gt;=0 &amp;&amp; j&lt;=grid[0].length-1 &amp;&amp; j&gt;=0)){ return; } if(visited[i][j]==true || grid[i][j]=='0'){ return; } visited[i][j] = true; DFS(grid, visited, i+1, j); DFS(grid, visited, i-1, j); DFS(grid, visited, i, j+1); DFS(grid, visited, i, j-1); }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// Union Findclass Solution { class UnionFind { private int[] parent; private int[] rank; public int count; public UnionFind(char[][] grid){ int m = grid.length; int n = grid[0].length; parent = new int[m*n]; rank = new int[m*n]; for(int i = 0;i&lt;=m-1;i++){ for(int j =0;j&lt;=n-1;j++){ int index = j*m+i; if(grid[i][j]=='1'){ parent[index] = index; rank[index] = 0; count++; } } } } public int find(int i){ if(parent[i] == i){ return i; } else { parent[i] = find(parent[i]); return parent[i]; } } public void union(int i , int j){ int indexi = find(i); int indexj = find(j); if(indexi!=indexj){ if(rank[indexi]&gt;rank[indexj]){ parent[indexj] = indexi; } else if(rank[indexi]&lt;rank[indexj]){ parent[indexi] = indexj; } else { parent[indexi] = indexj; rank[indexj]++; } count--; } } } public int numIslands(char[][] grid) { int m = grid.length; if(m==0) return 0; int n = grid[0].length; UnionFind uf = new UnionFind(grid); for(int i =0;i&lt;=m-1;i++){ for(int j =0;j&lt;=n-1;j++){ int index = j*m+i; if(grid[i][j]=='1'){ grid[i][j] = '0'; if(i+1&lt;=m-1 &amp;&amp; grid[i+1][j]=='1'){ uf.union(index, j*m+i+1); } if(j+1&lt;=n-1 &amp;&amp; grid[i][j+1]=='1'){ uf.union(index, (j+1)*m+i); } } } } return uf.count; }} Number of Connected Components in an Undirected Graph Friend Circles都是无向图 图里是否有环BipartiteBipartite的定义是一个图可以分为两个集合，这个图中所有的edge连接的vertice必须分别在两个集合解法是分别使用DFS或者BFS为两个集合染色，一个集合红色，一个集合蓝色，如果某个点出现两个色证明不是Bipartite BFS 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/*785. Is Graph Bipartite?Medium871116FavoriteShareGiven an undirected graph, return true if and only if it is bipartite.Recall that a graph is bipartite if we can split it's set of nodes into two independent subsets A and B such that every edge in the graph has one node in A and another node in B.The graph is given in the following form: graph[i] is a list of indexes j for which the edge between nodes i and j exists. Each node is an integer between 0 and graph.length - 1. There are no self edges or parallel edges: graph[i] does not contain i, and it doesn't contain any element twice.Example 1:Input: [[1,3], [0,2], [1,3], [0,2]]Output: trueExplanation: The graph looks like this:0----1| || |3----2We can divide the vertices into two groups: {0, 2} and {1, 3}.Example 2:Input: [[1,2,3], [0,2], [0,1,3], [0,2]]Output: falseExplanation: The graph looks like this:0----1| \\ || \\ |3----2We cannot find a way to divide the set of nodes into two independent subsets. Note:graph will have length in range [1, 100].graph[i] will contain integers in range [0, graph.length - 1].graph[i] will not contain i or duplicate values.The graph is undirected: if any element j is in graph[i], then i will be in graph[j].*/class Solution { public boolean isBipartite(int[][] graph) { int n = graph.length; int[] colors = new int[n]; Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); for(int i = 0;i&lt;=n-1;i++){//所有node都要经过一次queue，因为会有多个connected component的情况 if(colors[i]==0){ colors[i] = 1; queue.offer(i); while(!queue.isEmpty()){ int node = queue.poll(); int color = colors[node]; for(int neighbor:graph[node]){ if(colors[neighbor]==0){ colors[neighbor] = -color; queue.offer(neighbor); } else if(colors[neighbor]==color){ return false; } } } } } return true; }} DFS 1234567891011121314151617181920212223242526272829303132class Solution { public boolean isBipartite(int[][] graph) { int n = graph.length; int[] colors = new int[n]; for(int i = 0;i&lt;=n-1;i++){ if(colors[i]==0){ if(!valid(graph, colors, i, 1)){ return false; } } } return true; } private boolean valid(int[][] graph, int[] colors, int i, int color){ if(colors[i]==-color){ return false; } else if(colors[i]==color){ return true; } else { colors[i] = color; for(int neighbor:graph[i]){ if(!valid(graph, colors, neighbor, -color)){ return false; } } return true; } }}","link":"/2019/11/23/Leetcode/Graph%E7%B1%BB%E5%9E%8B%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"Greedy问题慢慢总结","text":"Greedy慢慢总结： Jump Game：这道题还是很简单的，思路就是遍历数组找到最远能到的位置。 12345678910111213141516171819202122232425262728293031323334353637383940/*55. Jump GameMedium2523241FavoriteShareGiven an array of non-negative integers, you are initially positioned at the first index of the array.Each element in the array represents your maximum jump length at that position.Determine if you are able to reach the last index.Example 1:Input: [2,3,1,1,4]Output: trueExplanation: Jump 1 step from index 0 to 1, then 3 steps to the last index.Example 2:Input: [3,2,1,0,4]Output: falseExplanation: You will always arrive at index 3 no matter what. Its maximum jump length is 0, which makes it impossible to reach the last index.*/class Solution { public boolean canJump(int[] nums) { int farest = 0; for(int i =0;i&lt;=farest &amp;&amp; i&lt;=nums.length-1;i++){ farest = Math.max(farest, i+nums[i]); } return farest &gt;= nums.length-1; }} Jump Game II:我们需要记录的是我们跳出一步所能走的最远距离，同时在走到这个局部最远距离的过程中，我们会记录下来下一次的局部最短距离，当我们行进到本次的局部最远距离的时候，我们知道是时候该跳下一步了，所以我们step++并更新局部最远距离。所以这道题我们的i要小于nums.length-1，因为nums.length-1这个点是最后一个我们可能在跳的点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*45. Jump Game IIHard153987FavoriteShareGiven an array of non-negative integers, you are initially positioned at the first index of the array.Each element in the array represents your maximum jump length at that position.Your goal is to reach the last index in the minimum number of jumps.Example:Input: [2,3,1,1,4]Output: 2Explanation: The minimum number of jumps to reach the last index is 2. Jump 1 step from index 0 to 1, then 3 steps to the last index.Note:You can assume that you can always reach the last index.*/class Solution { public int jump(int[] nums) { int step = 0; int lastLargest = 0; int curlargest = 0; for(int i =0;i&lt;nums.length-1;i++){ curlargest = Math.max(curlargest, i+nums[i]); if(i==lastLargest){ lastLargest = curlargest; step++; } } return step; }} Task Scheduler:https://leetcode.com/problems/task-scheduler/discuss/104500/Java-O(n)-time-O(1)-space-1-pass-no-sorting-solution-with-detailed-explanationGreedy点：最大频率的一定要先被选择，被选择后在里面的idle位置填充其他小于最大频率的任务。corner case：存在多个最大频率的任务，解决方法是没存在一个最大频率的任务，相当于我们idle的间隔减一。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/*621. Task SchedulerMedium2060382FavoriteShareGiven a char array representing tasks CPU need to do. It contains capital letters A to Z where different letters represent different tasks. Tasks could be done without original order. Each task could be done in one interval. For each interval, CPU could finish one task or just be idle.However, there is a non-negative cooling interval n that means between two same tasks, there must be at least n intervals that CPU are doing different tasks or just be idle.You need to return the least number of intervals the CPU will take to finish all the given tasks. Example:Input: tasks = [&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;B&quot;], n = 2Output: 8Explanation: A -&gt; B -&gt; idle -&gt; A -&gt; B -&gt; idle -&gt; A -&gt; B. Note:The number of tasks is in the range [1, 10000].The integer n is in the range [0, 100].*/class Solution { public int leastInterval(char[] tasks, int n) { int max = 0; int maxCount = 0; int[] chs = new int[26]; for(char c:tasks){ chs[c-'A']++; if(chs[c-'A']==max){ maxCount++; } else if(chs[c-'A']&gt;max){ maxCount = 1; max = chs[c-'A']; } } int partitionNumber = max-1; int partitionCount = n-(maxCount-1); int taskNotHighestFreq = tasks.length - max*maxCount; int idleNumber = partitionNumber*partitionCount -taskNotHighestFreq; idleNumber = Math.max(0, idleNumber); return tasks.length+idleNumber; }} Candy: https://leetcode.com/problems/candy/solution/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/*135. CandyHard623131FavoriteShareThere are N children standing in a line. Each child is assigned a rating value.You are giving candies to these children subjected to the following requirements:Each child must have at least one candy.Children with a higher rating get more candies than their neighbors.What is the minimum candies you must give?Example 1:Input: [1,0,2]Output: 5Explanation: You can allocate to the first, second and third child with 2, 1, 2 candies respectively.Example 2:Input: [1,2,2]Output: 4Explanation: You can allocate to the first, second and third child with 1, 2, 1 candies respectively. The third child gets 1 candy because it satisfies the above two conditions.*/class Solution { public int candy(int[] ratings) { int[] nums = new int[ratings.length]; Arrays.fill(nums, 1); for(int i =1;i&lt;=nums.length-1;i++){ if(ratings[i]&gt;ratings[i-1]){ nums[i] = nums[i-1]+1; } } for(int i =nums.length-2;i&gt;=0;i--){ if(ratings[i]&gt;ratings[i+1]){ nums[i] = Math.max(nums[i], nums[i+1]+1); } } int sum = 0; for(int i =0;i&lt;=nums.length-1;i++){ sum += nums[i]; } return sum; }} Gas Station:If car starts at A and can not reach B. Any station between A and Bcan not reach B.(B is the first station that A can not reach.)If the total number of gas is bigger than the total number of cost. There must be a solution.由以上两点，我们每次发现我们的油不够了，我们就把新起点放到当前位置(因为上一个起点到当前位置没有哪个点可以有可能油够：我们上一个起点的油一定大于起步距离，那么如果连上一个起点的油都不够开到当前位置，那么之间的点也都不可能作为起点)，并且清空我们的油桶，所以最后我们会逐步淘汰只剩一个最后的起点，如果这时我们发现总油量大于等于总里程，那么ok这个结果就是我们想要的，否则说明不可能有结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/*134. Gas StationMedium982322FavoriteShareThere are N gas stations along a circular route, where the amount of gas at station i is gas[i].You have a car with an unlimited gas tank and it costs cost[i] of gas to travel from station i to its next station (i+1). You begin the journey with an empty tank at one of the gas stations.Return the starting gas station's index if you can travel around the circuit once in the clockwise direction, otherwise return -1.Note:If there exists a solution, it is guaranteed to be unique.Both input arrays are non-empty and have the same length.Each element in the input arrays is a non-negative integer.Example 1:Input: gas = [1,2,3,4,5]cost = [3,4,5,1,2]Output: 3Explanation:Start at station 3 (index 3) and fill up with 4 unit of gas. Your tank = 0 + 4 = 4Travel to station 4. Your tank = 4 - 1 + 5 = 8Travel to station 0. Your tank = 8 - 2 + 1 = 7Travel to station 1. Your tank = 7 - 3 + 2 = 6Travel to station 2. Your tank = 6 - 4 + 3 = 5Travel to station 3. The cost is 5. Your gas is just enough to travel back to station 3.Therefore, return 3 as the starting index.Example 2:Input: gas = [2,3,4]cost = [3,4,3]Output: -1Explanation:You can't start at station 0 or 1, as there is not enough gas to travel to the next station.Let's start at station 2 and fill up with 4 unit of gas. Your tank = 0 + 4 = 4Travel to station 0. Your tank = 4 - 3 + 2 = 3Travel to station 1. Your tank = 3 - 3 + 3 = 3You cannot travel back to station 2, as it requires 4 unit of gas but you only have 3.Therefore, you can't travel around the circuit once no matter where you start.*/class Solution { public int canCompleteCircuit(int[] gas, int[] cost) { int gasCount = 0; int costCount = 0; int start = 0; int tank = 0; for(int i =0;i&lt;=gas.length-1;i++){ gasCount = gasCount + gas[i]; costCount = costCount+cost[i]; tank = tank+gas[i]-cost[i]; if(tank&lt;0){ tank = 0; start = i+1; } } if(gasCount&lt;costCount){ return -1; } else { return start; } }}","link":"/2019/10/23/Leetcode/Greedy%E9%97%AE%E9%A2%98%E6%85%A2%E6%85%A2%E6%80%BB%E7%BB%93/"},{"title":"Integer to something 类型题总结","text":"Integer to something 类型题总结这种类型题的思路就是将可能的情况放到Array中，由小到大或者由大到小排列，将需要得到的结果依次减Array中的index得出结果。之前做过的Broadway Technology的OA也是同样类型的题。 Integer to Roman： 123456789101112131415161718192021class Solution { public String intToRoman(int num) { int[] romanNumber = new int[]{1, 4, 5, 9, 10, 40, 50, 90, 100, 400, 500, 900, 1000}; String[] strs = new String[]{&quot;I&quot;, &quot;IV&quot;, &quot;V&quot;, &quot;IX&quot;, &quot;X&quot;, &quot;XL&quot;, &quot;L&quot;, &quot;XC&quot;, &quot;C&quot;, &quot;CD&quot;, &quot;D&quot;, &quot;CM&quot;, &quot;M&quot;}; String ans = &quot;&quot;; int index = romanNumber.length-1; while(num&gt;0){ if(romanNumber[index]&gt;num){ index--; continue; } else { num = num - romanNumber[index]; ans = ans + strs[index]; } } return ans; }} Integer to English Words 这道题的思想其实与罗马数字也类似，但不同点在于罗马数字是不停地减，这种需要不停地取余，相当于从高位到低位依次处理。分析这道题的时候，关键是发现：数字在西方是以1000为进制的，所以最基本的处理是针对1000来操作，1000以上的数只需要在1000的基础上稍加处理。所以如果是处理中文的话，进制是一万。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Solution { public String numberToWords(int num) { if(num==0) return &quot;Zero&quot;; String ans = &quot;&quot;; while(num&gt;0){ if(num&gt;=1000000000){ int billionNum = num/1000000000; ans = ans + computeNumLessThousand(billionNum) + &quot;Billion &quot;; num = num % 1000000000; } else if(num&gt;=1000000){ int millionNum = num/1000000; ans = ans + computeNumLessThousand(millionNum) + &quot;Million &quot;; num = num % 1000000; } else if(num&gt;=1000){ int thousandNum = num/1000; ans = ans + computeNumLessThousand(thousandNum) + &quot;Thousand &quot;; num = num % 1000; } else{ ans = ans + computeNumLessThousand(num); break; } } ans = ans.substring(0, ans.length()-1); return ans; } private String computeNumLessThousand(int num){ String[] digits = new String[]{&quot;&quot;, &quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;, &quot;Six&quot;, &quot;Seven&quot;, &quot;Eight&quot;, &quot;Nine&quot;, &quot;Ten&quot;, &quot;Eleven&quot;, &quot;Twelve&quot;, &quot;Thirteen&quot;, &quot;Fourteen&quot;, &quot;Fifteen&quot;, &quot;Sixteen&quot;, &quot;Seventeen&quot;, &quot;Eighteen&quot;, &quot;Nineteen&quot;}; String[] tens = new String[]{&quot;&quot;, &quot;&quot;, &quot;Twenty&quot;, &quot;Thirty&quot;, &quot;Forty&quot;, &quot;Fifty&quot;, &quot;Sixty&quot;, &quot;Seventy&quot;, &quot;Eighty&quot;, &quot;Ninety&quot;}; String ans = &quot;&quot;; while(num&gt;0){ if(num&gt;=100){ int hundredNum = num/100; ans = ans + computeNumLessThousand(hundredNum) + &quot;Hundred &quot;; num = num %100; } else if(num&gt;=20){ int tensNum = num/10; ans = ans + tens[tensNum] + &quot; &quot;; num = num %10; } else { ans = ans + digits[num] + &quot; &quot;; break; } } return ans; }}","link":"/2019/09/13/Leetcode/Integer%20to%20something%E6%80%BB%E7%BB%93/"},{"title":"LinkedList Cycle问题","text":"LinkedList Cycle问题在LinkedList中查看是否存在cycle，使用的主要方法是Floyd’s Tortoise and Hare算法，原理就是设置两个快慢指针，如果存在cycle，那么快慢指针一定会相遇。当然不止LinkedList可以使用这个方法，只要我们能把题目类比成LinkedList(也就是前一个数能找到后一个数，其实就是LinkedList的作用)，然后题目中存在环，那么也就可以使用这个方法。 Linked List Cycle： 1234567891011121314public class Solution { public boolean hasCycle(ListNode head) { ListNode slow = head; ListNode fast = head; while(fast!=null &amp;&amp; fast.next!=null){ slow = slow.next ; fast = fast.next.next; if(slow == fast){ return true; } } return false; }} Linked List Cycle II：快慢指针相遇的时候，我们可以找到重合点，题目要求是找到cycle的起点。通过观察我们发现很重要的一个关系是快指针走了慢指针的两倍，所以从ListNode的head到cycle起点==intersect到cycle起点。 123456789101112131415161718public class Solution { public ListNode detectCycle(ListNode head) { ListNode slow = head; ListNode fast = head; while(fast!=null &amp;&amp; fast.next !=null ){ slow = slow.next; fast = fast.next.next; if(slow == fast){ while(head!=slow){ head = head.next; slow = slow.next; } return head; } } return null; }} Happy Number:这道题不是LinkedList，但是我们发现我们总是可以从前一个数得到后一个数，并且如果最后不收敛到1的话就证明一定有环，所以可以使用Floyd’s Tortoise and Hare算法。 123456789101112131415161718192021222324252627282930class Solution { public boolean isHappy(int n) { int slow = n; int fast = n; while(fast!=1){ slow = compute(slow); fast = compute(compute(fast)); if(slow==fast){ break; } } if(fast==1){ return true; } else { return false; } } private int compute(int input){ String s = &quot;&quot;+input; int ans = 0; for(char c:s.toCharArray()){ ans = ans + (c-'0')*(c-'0'); } return ans; }} Find the Duplicate Number：由题目的条件可以知道所有的数在[1, nums.length-1]的范围，所以相当于我们拿到一个数，她的下一个数可以用这个数作为index找到，也就变相实现了Linkedlist，那么LinkedList的头相当于index of 0。 1234567891011121314151617181920class Solution { public int findDuplicate(int[] nums) { int slow = nums[0]; int fast = nums[0]; while(true){ slow = nums[slow]; fast = nums[nums[fast]]; if(slow==fast){ break; } } slow = nums[0]; while(slow!=fast){ slow = nums[slow]; fast = nums[fast]; } return slow; }}","link":"/2019/10/23/Leetcode/LinkedList%20Cycle%E9%97%AE%E9%A2%98/"},{"title":"Majority Vote总结","text":"Majority Element题型是找一个数组中超过n/k的majority元素，使用的算法是Majority Vote。原理就是对于每一个Majority Element都设置一个count：1.如果选中的num与Majority Element相等，对应的count++ 2.如果所有的Majority Element没有与num相等的，那么去检查有没有count为0，如果有，将这个Majority Element设置为num并将count设为1 3.如果以上都不符合，那么所有count– 所以我们看到程序中都是用的if，else if，也就是说有符合条件的情况，对于这个num的判断就结束了 Majority Element 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*169. Majority ElementEasy2074181FavoriteShareGiven an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times.You may assume that the array is non-empty and the majority element always exist in the array.Example 1:Input: [3,2,3]Output: 3Example 2:Input: [2,2,1,1,1,2,2]Output: 2*/class Solution { public int majorityElement(int[] nums) { int majority = 0; int count = 0; for(int i = 0;i&lt;=nums.length-1;i++){ if(nums[i]==majority){ count++; } else if(count==0){ majority = nums[i]; count++; } else { count--; } } return majority; }} Majority Element II 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/*229. Majority Element IIMedium1081125FavoriteShareGiven an integer array of size n, find all elements that appear more than ⌊ n/3 ⌋ times.Note: The algorithm should run in linear time and in O(1) space.Example 1:Input: [3,2,3]Output: [3]Example 2:Input: [1,1,1,3,3,2,2,2]Output: [1,2]*/class Solution { public List&lt;Integer&gt; majorityElement(int[] nums) { int majority1 = 0; int majority2 = 0; int count1 = 0; int count2 = 0; for(int i = 0;i&lt;=nums.length-1;i++){ //先判断是否有Majority等于nums[i] if(nums[i] == majority1){ count1++; } else if(nums[i] == majority2){ count2++; } //再判断是否有count为0 //先后顺序不能变，不能先判断count是否为0，因为可能有一个majority的count是0，但另一个不是0，那么他还可能等于nums[i] else if(count1==0){ majority1 = nums[i]; count1++; } else if(count2==0){ majority2 = nums[i]; count2++; } //都不符合的话count都减1 else { count1--; count2--; } } List&lt;Integer&gt; l = new LinkedList&lt;&gt;(); count1 = 0; count2 = 0; for(int num:nums){ if(num==majority1){ count1++; } else if(num==majority2){ count2++; } } if(count1&gt;nums.length/3){ l.add(majority1); } if(count2&gt;nums.length/3){ l.add(majority2); } return l; }}","link":"/2019/10/30/Leetcode/Majority%20Vote%E6%80%BB%E7%BB%93/"},{"title":"Merge K sorted lists类型题总结","text":"Merge K sorted lists首先要会做merge 2 sorted lists，这个比较简单，就是使用双指针进行merge。Merge K sorted lists有两个做法： 使用一个list长度的Priority Queue，重新构写Comparator(按照lisstnode.val进行比较)，每次取出最小的listnode以后再向Priority Queue加入新的node。 时间复杂度是O(nlogk)，因为所有的node都要进到PQ中，而每个进去都是O(k)时间。空间复杂度O(k)。 divide and conquer的思想，因为我们已经做过merge 2 sorted list的题，那么很自然可以想到将list不断地divide直到只剩一个，然后再两个两个的merge，思想与merge sort很像。时间复杂度也是O(nlogk)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */class Solution { public ListNode mergeKLists(ListNode[] lists) { return partition(lists, 0, lists.length-1); } private ListNode partition(ListNode[] lists, int left, int right){ if(left&gt;right){ return null; } else if(left==right){ return lists[left]; } else{ ListNode leftPart = partition(lists, left, (left+right)/2); ListNode rightPart = partition(lists, (left+right)/2+1, right); return merge(leftPart, rightPart); } } private ListNode merge(ListNode leftPart, ListNode rightPart){ //merge two sorted list ListNode ans = new ListNode(0); ListNode res = ans; while(leftPart!=null &amp;&amp; rightPart!=null){ if(leftPart.val&lt;rightPart.val){ ans.next = leftPart; leftPart = leftPart.next; } else{ ans.next = rightPart; rightPart = rightPart.next; } ans = ans.next; } if(leftPart!=null){ ans.next = leftPart; } else{ ans.next = rightPart; } return res.next; }}","link":"/2019/09/13/Leetcode/Merge%20K%20sorted%20lists%E6%80%BB%E7%BB%93/"},{"title":"Path Sum总结","text":"Path Sum类型题的思路就是进行DFS。编写DFS函数的时候要想明白：1.DFS函数的作用是干什么 2.DFS函数的base case是什么 3.DFS函数的输入输出分别是什么 Path Sum 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*112. Path SumEasy1198380FavoriteShareGiven a binary tree and a sum, determine if the tree has a root-to-leaf path such that adding up all the values along the path equals the given sum.Note: A leaf is a node with no children.Example:Given the below binary tree and sum = 22, 5 / \\ 4 8 / / \\ 11 13 4 / \\ \\7 2 1return true, as there exist a root-to-leaf path 5-&gt;4-&gt;11-&gt;2 which sum is 22.*//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public boolean hasPathSum(TreeNode root, int sum) { if(root==null) return false; if(root.left==null &amp;&amp; root.right==null &amp;&amp; root.val==sum) return true; return hasPathSum(root.left, sum-root.val) || hasPathSum(root.right, sum-root.val); }} Path Sum II: 这道题的关键是判断好recursive的base case，不像其他很多的DFS的base case直接就是node==null，这里的base case应该有两个：1. node==null，直接返回 2. node不为空，且node.left==null&amp;&amp;node.right==null&amp;&amp;node.val==sum，这个时候我们把存下来的路线加入到结果中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/*113. Path Sum IIMedium113142FavoriteShareGiven a binary tree and a sum, find all root-to-leaf paths where each path's sum equals the given sum.Note: A leaf is a node with no children.Example:Given the below binary tree and sum = 22, 5 / \\ 4 8 / / \\ 11 13 4 / \\ / \\7 2 5 1Return:[ [5,4,11,2], [5,8,4,5]]*//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) { List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); dfs(root, ans, sum, new LinkedList&lt;&gt;()); return ans; } private void dfs(TreeNode node, List&lt;List&lt;Integer&gt;&gt; ans, int sum, List&lt;Integer&gt; l){ if(node==null){ return; } if(node.left==null &amp;&amp; node.right==null &amp;&amp; node.val==sum){ l.add(node.val); ans.add(new LinkedList&lt;&gt;(l)); l.remove(l.size()-1); return; } l.add(node.val); dfs(node.left, ans, sum-node.val, l); dfs(node.right, ans, sum-node.val, l); l.remove(l.size()-1); }} Path Sum III: 这道题可以直接DFS做，但是要考虑到可能的path不止可以是从root开始，而是可以从任意一个node开始，所以如果直接DFS的话要用两个DFS函数，而且相当于brute force。比较好的方法是使用类似two sum的presum做法，使用一个map存储遇到过的presum的frequency。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/*437. Path Sum IIIEasy2320144FavoriteShareYou are given a binary tree in which each node contains an integer value.Find the number of paths that sum to a given value.The path does not need to start or end at the root or a leaf, but it must go downwards (traveling only from parent nodes to child nodes).The tree has no more than 1,000 nodes and the values are in the range -1,000,000 to 1,000,000.Example:root = [10,5,-3,3,2,null,11,3,-2,null,1], sum = 8 10 / \\ 5 -3 / \\ \\ 3 2 11 / \\ \\3 -2 1Return 3. The paths that sum to 8 are:1. 5 -&gt; 32. 5 -&gt; 2 -&gt; 13. -3 -&gt; 11*//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int pathSum(TreeNode root, int sum) { Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, 1); return helper(root, 0, sum, map); } private int helper(TreeNode node, int curSum, int sum, Map&lt;Integer, Integer&gt; map){ if(node==null){ return 0; } curSum = curSum + node.val; int res = map.getOrDefault(curSum-sum, 0); map.put(curSum, map.getOrDefault(curSum, 0)+1); res = res + helper(node.left, curSum, sum, map)+helper(node.right, curSum, sum, map); map.put(curSum, map.get(curSum)-1); return res; }} 下面两道题的思路很类似，都是求maximum path sum，思路就是正常进行DFS，DFS求的是从input node到叶节点的max path sum，而不是直接求整棵树的max path sum，在过程中，我们使用一个max变量来计算目前遇到过的最大的pathsum。 Binary Tree Maximum Path Sum： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/*124. Binary Tree Maximum Path SumHard2158169FavoriteShareGiven a non-empty binary tree, find the maximum path sum.For this problem, a path is defined as any sequence of nodes from some starting node to any node in the tree along the parent-child connections. The path must contain at least one node and does not need to go through the root.Example 1:Input: [1,2,3] 1 / \\ 2 3Output: 6Example 2:Input: [-10,9,20,null,null,15,7] -10 / \\ 9 20 / \\ 15 7Output: 42*//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int maxPathSum(TreeNode root) { int[] ans = new int[]{Integer.MIN_VALUE}; longestPath(ans, root); return ans[0]; } private int longestPath(int[] ans, TreeNode node){ if(node==null){ return 0; } int left = Math.max(0, longestPath(ans, node.left)); int right = Math.max(0, longestPath(ans, node.right)); ans[0] = Math.max(ans[0], left+right+node.val); return Math.max(left, right) + node.val; }} Diameter of Binary Tree 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/*543. Diameter of Binary TreeEasy1780111FavoriteShareGiven a binary tree, you need to compute the length of the diameter of the tree. The diameter of a binary tree is the length of the longest path between any two nodes in a tree. This path may or may not pass through the root.Example:Given a binary tree 1 / \\ 2 3 / \\ 4 5 Return 3, which is the length of the path [4,2,1,3] or [5,2,1,3].Note: The length of path between two nodes is represented by the number of edges between them.*//** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public int diameterOfBinaryTree(TreeNode root) { int[] ans = new int[]{0}; longestPath(ans, root); return ans[0]; } private int longestPath(int[] ans, TreeNode node){ if(node==null){ return 0; } int left = longestPath(ans, node.left); int right = longestPath(ans, node.right); ans[0] = Math.max(ans[0], left+right+1-1); return Math.max(left, right)+1; }}","link":"/2019/10/30/Leetcode/Path%20Sum%E6%80%BB%E7%BB%93/"},{"title":"Sliding Window总结","text":"Sliding Windowsliding window问题的思想并不复杂，就是设立一个start和一个end指针进行遍历，end不停地在前进，start只有在条件不符合的时候前进，但是在进行过程中由于变量的更改会出现有思路写不出来的问题，所以总结一下模板。 sliding window思路： 12345while(end&lt;length){ 1. 处理end位置的character，end++ 2. 如果达到了某种条件，我们使用while loop或者if打破这种条件，start++ 3. 更新结果，这个时候的end是还没处理过的，start是处理过的，所以如果求长度什么的是end-start而不是end-start+1} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Solution { public List&lt;Integer&gt; slidingWindowTemplateByHarryChaoyangHe(String s, String t) { //init a collection or int value to save the result according the question. List&lt;Integer&gt; result = new LinkedList&lt;&gt;(); if(t.length()&gt; s.length()) return result; //create a hashmap to save the Characters of the target substring. //(K, V) = (Character, Frequence of the Characters) Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for(char c : t.toCharArray()){ map.put(c, map.getOrDefault(c, 0) + 1); } //maintain a counter to check whether match the target string. int counter = map.size();//must be the map size, NOT the string size because the char may be duplicate. //Two Pointers: begin - left pointer of the window; end - right pointer of the window int begin = 0, end = 0; //the length of the substring which match the target string. int len = Integer.MAX_VALUE; //loop at the begining of the source string while(end &lt; s.length()){ char c = s.charAt(end);//get a character if( map.containsKey(c) ){ map.put(c, map.get(c)-1);// plus or minus one if(map.get(c) == 0) counter--;//modify the counter according the requirement(different condition). } end++; //increase begin pointer to make it invalid/valid again while(counter == 0 /* counter condition. different question may have different condition */){ char tempc = s.charAt(begin);//***be careful here: choose the char at begin pointer, NOT the end pointer if(map.containsKey(tempc)){ map.put(tempc, map.get(tempc) + 1);//plus or minus one if(map.get(tempc) &gt; 0) counter++;//modify the counter according the requirement(different condition). } begin++; } /* save / update(min/max) the result if find a target*/ // result collections or result int value } return result; }} Longest Substring Without Repeating Characters: 这道题是可以使用我们的模板，也就是使用map记录出现的次数，如果次数大于1，代表不合乎条件，那么start进行运动。一个优化方式是我们直接存储上一次遇到这个character的位置，这样我们使用start更新的时候可以一步到位，不用进行loop 1234567891011121314151617181920212223242526272829//模板写法class Solution { public int lengthOfLongestSubstring(String s) { Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int start = 0; int end = 0; int counter = 0; int ans = 0; while(end&lt;s.length()){ char c = s.charAt(end); map.put(c, map.getOrDefault(c, 0)+1); if(map.get(c)&gt;1){ counter++; } end++; while(counter&gt;0){//no repeat就是counter必须为零的意思 char temp = s.charAt(start); map.put(temp, map.get(temp)-1); if(map.get(temp)==1){ counter--; } start++; } ans = Math.max(ans, end-start); } return ans; }} 12345678910111213141516171819202122//优化的class Solution { public int lengthOfLongestSubstring(String s) { if(s.length()==0){ return 0; } Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int start = 0; int end = 0; int ans = 0; while(end&lt;=s.length()-1){ char c = s.charAt(end); if(map.containsKey(c)){//当条件不成立的时候，就是我们使用start的时候 start = Math.max(start, map.get(c)+1); } map.put(c, end); ans = Math.max(ans, end-start+1); end++; } return ans; }} Longest Substring with At Most Two Distinct Characters+340. Longest Substring with At Most K Distinct Characters: 套用我们的模板即可，counter一开始为零，每当我们的end遇到在map中不存在的character的时候，我们的count++；如果counter&gt;k，说明我们现在有超过k中character，所以我们移动start直到某一个character在map中size为零，counter–。 123456789101112131415161718192021222324252627class Solution { public int lengthOfLongestSubstringKDistinct(String s, int k) { Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int res = 0; int start = 0; int end = 0; int counter = 0;//map中数量大于0的character while(end&lt;=s.length()-1){ char c = s.charAt(end); map.put(c, map.getOrDefault(c, 0)+1); if(map.get(c)==1){//如果某个character的数量为1，说明是我们新加进去的，也就是map中数量大于0的元素加一 counter++; } end++; while(counter&gt;k){ char temp = s.charAt(start); map.put(temp, map.get(temp)-1); if(map.get(temp)==0){ counter--; } start++; } res = Math.max(res, end-start); } return res; }} Minimum Window Substring: 求最小与求最大是类似的镜像问题，他们进行结果更新的地方不一样。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution { public String minWindow(String s, String t) { Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for(char c: t.toCharArray()){ map.put(c, map.getOrDefault(c, 0)+1); } int minLength = Integer.MAX_VALUE; int minStart = 0; int minEnd = 0; int start = 0; int end = 0; int counter = map.size(); while(end&lt;s.length()){ char c = s.charAt(end); if(map.containsKey(c)){ map.put(c, map.get(c)-1); if(map.get(c)==0){ counter--; } } end++; while(counter==0){ char temp = s.charAt(start); if(minLength&gt;end-start){//求最小的substring，符合条件的在while loop里面，求最长的substring，符合条件的在外面 minStart = start; minEnd = end; minLength = end-start; } if(map.containsKey(temp)){ map.put(temp, map.get(temp)+1); if(map.get(temp)&gt;0){ counter++; } } start++; } } return minLength==Integer.MAX_VALUE?&quot;&quot;:s.substring(minStart, minEnd); }} K different element题目：这种题目可以转换成我们之前做过的At Most K类型题，Exactly(K) = AtMost(K) - AtMost(K-1) Subarrays with K Different Integers 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/*992. Subarrays with K Different IntegersHard52111FavoriteShareGiven an array A of positive integers, call a (contiguous, not necessarily distinct) subarray of A good if the number of different integers in that subarray is exactly K.(For example, [1,2,3,1,2] has 3 different integers: 1, 2, and 3.)Return the number of good subarrays of A. Example 1:Input: A = [1,2,1,2,3], K = 2Output: 7Explanation: Subarrays formed with exactly 2 different integers: [1,2], [2,1], [1,2], [2,3], [1,2,1], [2,1,2], [1,2,1,2].Example 2:Input: A = [1,2,1,3,4], K = 3Output: 3Explanation: Subarrays formed with exactly 3 different integers: [1,2,1,3], [2,1,3], [1,3,4].*/class Solution { public int subarraysWithKDistinct(int[] A, int K) { return atMostK(A, K)-atMostK(A, K-1); } private int atMostK(int[] A, int K){ int start = 0; int end = 0; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int count = 0; int ans = 0; while(end&lt;=A.length-1){ int num = A[end]; if(map.getOrDefault(num, 0)==0){ count++; } map.put(num, map.getOrDefault(num, 0)+1); end++; while(count&gt;K){ int startNum = A[start]; map.put(startNum, map.get(startNum)-1); if(map.get(startNum)==0){ count--; } start++; } ans = ans + end - start;//the total number of subarrays ending at j that contain at most K distinct. } return ans; }} Count Number of Nice Subarrays 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/*1248. Count Number of Nice SubarraysMedium560FavoriteShareGiven an array of integers nums and an integer k. A subarray is called nice if there are k odd numbers on it.Return the number of nice sub-arrays. Example 1:Input: nums = [1,1,2,1,1], k = 3Output: 2Explanation: The only sub-arrays with 3 odd numbers are [1,1,2,1] and [1,2,1,1].Example 2:Input: nums = [2,4,6], k = 1Output: 0Explanation: There is no odd numbers in the array.Example 3:Input: nums = [2,2,2,1,2,2,1,2,2,2], k = 2Output: 16 Constraints:1 &lt;= nums.length &lt;= 500001 &lt;= nums[i] &lt;= 10^51 &lt;= k &lt;= nums.length*/class Solution { public int numberOfSubarrays(int[] nums, int k) { return atMostK(nums, k) - atMostK(nums, k-1); } private int atMostK(int[] nums, int k){ int start = 0; int end = 0; int count = 0; int ans = 0; while(end&lt;=nums.length-1){ if(nums[end]%2==1){ count++; } end++; while(count&gt;k){ if(nums[start]%2==1){ count--; } start++; } ans = ans + end -start; } return ans; }}","link":"/2019/10/03/Leetcode/Sliding%20Window%E6%80%BB%E7%BB%93/"},{"title":"String Matching类型问题总结","text":"String Matching类型问题总结这类问题的鼻祖问题Sequence Alignment(Edit distance)在算法课上学习过，但是理解不够深刻，本质上就是二维DP的问题。时间空间复杂度都是O(mn)。这种String Matching或者DP的问题，一定不要上来就想*号该怎么处理，而是应该用一种recursive的思想去处理（算法的问题就是要把大问题逐渐变成更小的问题）： 对于两个string，想要把两个长string比较的大问题变成两个更短的string比较的问题，那么做法无疑就是比较两个string的最后一位，根据不同的情况可以使他们缩短，然后再比较缩短了的string，再缩短不断重复，这就是recursive的思想。 对于recursive，我们可以发现会有很多的子问题在其中，所以可以用dp[][]数组进行memorize。 进一步总结变成bottom up的DP解法。 Edit Distance： 最经典的String matching问题，recursive formula: *如果a[i]==b[j]*： dp[i][j] = dp[i-1][j-1] *如果a[i]!=b[i]*： dp[i][j] = dp[i-1][j-1]，如果a[i]替换成b[j] dp[i][j-1]，如果b[j]被删掉 dp[j-1][i]，如果a[i]被删掉 1234567891011121314151617181920212223242526class Solution { public int minDistance(String word1, String word2) { int m = word1.length(); int n = word2.length(); int[][] dp = new int[m+1][n+1]; dp[0][0] = 0; for(int i =1;i&lt;=n;i++){ dp[0][i] = i; } for(int i = 1;i&lt;=m;i++){ dp[i][0] = i; } for(int i =1;i&lt;=m;i++){ for(int j =1;j&lt;=n;j++){ if(word1.charAt(i-1)==word2.charAt(j-1)){ dp[i][j] = dp[i-1][j-1]; } else { dp[i][j] = Math.min(Math.min(dp[i-1][j], dp[i][j-1]), dp[i-1][j-1]) + 1; } } } return dp[m][n]; }} Regular Expression Matching: recursive formula： *如果s[i]==p[j]或者p[j]==’.’*：dp[i][j] = dp[i-1][j-1] *如果p[j]==’*‘*： 如果*代表0个前面字符：dp[i][j] = dp[i][j-2] 如果*代表多个前面字符：只有在pattern中前面的字符与string最后一个字符match(相等或者p是.)的情况下，我们可以直接把string的最后一位消掉，dp[i][j] = dp[i-1][j] 12345678910111213141516171819202122232425262728293031323334353637class Solution { public boolean isMatch(String s, String p) { /** if s[i]==p[j]||p[j]=='.' : dp[i][j] = dp[i-1][j-1]; else if p[j]=='*' : dp[i][j] = dp[i][j-2] (* stands for 0 preceding element) || (s[i]==p[j-1] || p[i-1]=='.' )&amp;&amp; dp[i-1][j] (* stands for more of preceding element) **/ int m = s.length(); int n = p.length(); boolean[][] dp = new boolean[m+1][n+1]; dp[0][0] = true; //if pattern is empty and string is not, the result must be false, so no need to deal with it. //deal with the situation that string is empty and pattern is not. for(int i = 1;i&lt;=n;i++){ if(p.charAt(i-1)=='*'){ dp[0][i] = dp[0][i-2]; } } for(int i =1;i&lt;=m;i++){ for(int j =1;j&lt;=n;j++){ if(s.charAt(i-1)==p.charAt(j-1) || p.charAt(j-1)=='.'){ dp[i][j] = dp[i-1][j-1]; } else if(p.charAt(j-1)=='*'){ dp[i][j] = dp[i][j-2] || ((s.charAt(i-1)==p.charAt(j-2)|| p.charAt(j-2)=='.') &amp;&amp; dp[i-1][j]); } else { dp[i][j] = false; } } } return dp[m][n]; }} Wildcard Matching: recursive formula: *如果s[i]==p[j]或者p[j]==’？’*：dp[i][j] = dp[i-1][j-1] *如果p[j]==’*‘*： 如果*代表0个字符：dp[i][j] = dp[i][j-1] 如果*代表多个字符：因为*代表多个字符，所以string的最后一位可以直接消掉，dp[i][j] = dp[i-1][j] 12345678910111213141516171819202122232425262728293031class Solution { public boolean isMatch(String s, String p) { int m = s.length(); int n = p.length(); boolean[][] dp = new boolean[m+1][n+1]; dp[0][0] = true; for(int i = 1;i&lt;=n;i++){ if(p.charAt(i-1)=='*' ){ dp[0][i] = dp[0][i-1]; } } //对于string不为空，pattern为空的情况，一定是false for(int i =1;i&lt;=m;i++){ for(int j =1;j&lt;=n;j++){ if(s.charAt(i-1)==p.charAt(j-1) || p.charAt(j-1)=='?'){ dp[i][j] = dp[i-1][j-1]; } else if(p.charAt(j-1)=='*'){ dp[i][j] = dp[i][j-1] || dp[i-1][j]; } else { dp[i][j] = false; } } } return dp[m][n]; }}","link":"/2019/09/13/Leetcode/String%20matching%E6%80%BB%E7%BB%93/"},{"title":"Top K类型题（bucket sort, inplace quick sort and Comparator）","text":"Top K类型题（bucket sort, inplace quick sort and Comparator）基本类top k今天总结了一下Top K这种类型的题目的做法，总的来说一般有三种做法： 最简单的就是进行sorting，然后取前K个，时间复杂度是O(nlogn) 第二种做法是使用Priority Queue(最小堆)，Priority Queue只存储目前遇到的最大的K个元素，每次堆中元素大于K的时候我们就poll出目前最小的元素(已经有K个比他大，他肯定不是结果了)，那么时间复杂度是O(nlogk) 最复杂的做法是使用Quick Select，由于我们只关心前K个元素，所以相当于对于Quick Sort，我们每次partition只取一半，所以时间复杂度只有O(n)。(T(n) = T(n/2) + n) 注意：当我们是求某一个频率的前K个元素的时候，我们可以不用复杂的Quick Select，而是使用简单的Bucket sort。这里能够使用bucket sort的原因在于元素的frequency肯定不大于数组的长度，也就是说有一个固定的边界。我们知道bucket sort能够使用的条件就是有固定的边界。而求取前K个最大的元素，由于元素的大小是没有边界的，所以无法使用bucket sort，我们只能用Quick Select。 这类题目通常需要使用到Comparator对元素进行比较，下面也总结一下Comparator的三种构造用法： 最原始的定义：Comparator是一个接口，所以我们需要声明一个类来实现这个接口，然后我们在实例化这个声明的类 12345678class myComparator&lt;Integer&gt; implements Comparator&lt;Integer&gt; { // Compare:第一个比第二个大是1，第一个比第二个小是-1 @Override public int compare(Integer i1, Integer i2){ return freq.get(i2) - freq.get(i1); }}PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;(new myComparator&lt;&gt;()); 简单一点的写法是使用匿名类，也就是不去手动声明一个类来实现这个接口，而是直接在这个接口后面声明一个匿名类来起到想同的效果 123456PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;(new Comparator&lt;Integer&gt;(){ @Override public int compare(Integer i1, Integer i2){ return freq.get(i2)- freq.get(i1); }}); 最简单的写法是使用java8的lambda function 123PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;((a, b)-&gt;{ return freq.get(b) - freq.get(a);}); 下面是几道这种类型的题。 Top K Frequent Elements: 由于是要先求频率的题，而频率是有边界的，所以最好的做法是使用bucket sort,时间复杂度O(n)，空间复杂度O(n)。 Top K Frequent Words Kth Largest Element in an Array： 由于是取最大的K个数，是没有边界的，所以用应该用quick select，时间的复杂度O(n)，空间复杂度O(1)。 K Closest Points to Origin quick select的inplace实现：https://blog.csdn.net/qq_20011607/article/details/82357239 普通quickSelect普通的quickSort实现起来比较简单，每次固定选择最左侧或最右侧元素为pivot，设置low指针为splitPoint，splitPoint左侧的点都小于pivot，splitPoint及它右侧的点都大于等于pivot。Lomuto partition scheme： https://en.wikipedia.org/wiki/Quicksort#Algorithm 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.io.*;import java.util.*;public class Solution { public static void main(String[] args) { /* Enter your code here. Read input from STDIN. Print output to STDOUT. Your class should be named Solution. */ Scanner scanner = new Scanner(System.in); int len = scanner.nextInt(); int[] input = new int[len]; for(int i = 0;i&lt;=input.length-1;i++){ input[i] = scanner.nextInt(); } quickSort(input, 0, input.length-1); } private static void quickSort(int[] input, int low, int high){ if(low&gt;=high){ return; } int mid = partition(input, low, high); quickSort(input, low, mid-1); quickSort(input, mid+1, high); } private static int partition(int[] input, int low, int high){ int pivot = input[high]; int splitPoint = low; for(int i = low; i&lt;=high; i++){ if(input[i]&lt;pivot){ swap(input, i , splitPoint); splitPoint++; } } swap(input, high, splitPoint); for(int i = 0;i&lt;=input.length-1;i++){ System.out.print(input[i]+&quot; &quot;); } System.out.println(); return splitPoint; } private static void swap(int[] input, int i, int j){ int num = input[i]; input[i] = input[j]; input[j] = num; }} 双路quickSelect思路是选择最左侧的点为pivot，然后设置两个pointer i和j，i一直运动直到遇到比pivot大的元素，j一直向左运动直到遇到比pivot小的元素，如果此时i&lt;=j,那么swap(i，j)。那么最后j及j之前的都是小于pivot的，i及i之后的都是大于pivot的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution { public int findKthLargest(int[] nums, int k) { int left = 0; int right = nums.length-1; while(left&lt;=right){ int mid = partition(nums, left, right); if(mid==nums.length - k){ return nums[mid]; } else if(mid&lt;nums.length - k){ left = mid+1; } else { right = mid-1; } } return -1; } private int partition(int[] nums, int left, int right){ int i = left+1; int j = right; while(true){ while(i&lt;=right){ if(nums[i]&lt;=nums[left]){ i++; } else{ break; } } while(j&gt;=left+1){ if(nums[j]&gt;nums[left]){ j--; } else { break; } } if(i&gt;j){ break; } swap(nums, i, j); } swap(nums, left, j); return j; } private void swap(int[] nums, int i, int j){ int a = nums[j]; nums[j] = nums[i]; nums[i] = a; }} topK + 多个sorted array/sorted list这种类型题本质上就是topK问题，最简单的想法当然是像topK一样把所有元素都加入到一个K大小的PQ中就好了，这样确实能得到结果，但是时间复杂度是O(nlogn)，n是总共元素的个数。一个很重要的优化方式是我们应该注意到给我们的都是排好序的元素，所以我们要利用他们排好序的性质。思路类似于Merge K sorted LinkedList，在那道题中我们使用Priority Queue，并且利用了Sorted LinkedList的next指针去找到下一个元素，这类题目我们可以利用index去找到下一个元素，时间复杂度是O(klogk)378. Kth Smallest Element in a Sorted Matrix：我们把sorted matrix看成是多个sorted array，我们先把所有sorted array的第一个元素加入PQ中，然后每次我们从PQ中取出一个元素以后，我们都把这个元素所在的sorted array的下一个元素加入到PQ中去(所以我们需要存储目前的index)，可以发现和Merge K Sorted LinkedList非常相似。当然这里我们把横着或者竖着当成sorted array都可以。 12345678910111213141516171819202122232425262728293031323334353637class Solution { public int kthSmallest(int[][] matrix, int k) { int n = matrix.length; PriorityQueue&lt;Tuple&gt; pq = new PriorityQueue&lt;&gt;(); for(int i =0;i&lt;=n-1 &amp;&amp; i&lt;=k-1;i++){ pq.offer(new Tuple(0, i, matrix[0][i])); } while(k&gt;1){ Tuple tmp = pq.poll(); k--; if(tmp.row==n-1) continue; pq.offer(new Tuple(tmp.row+1, tmp.column, matrix[tmp.row+1][tmp.column])); } return pq.poll().value; } class Tuple implements Comparable&lt;Tuple&gt;{ int row; int column; int value; public Tuple(int row, int column, int value){ this.row = row; this.column = column; this.value = value; } @Override public int compareTo(Tuple that){ return this.value-that.value; } }} Find K Pairs with Smallest Sums：这道题本质上和上道题完全一样，但是需要变化一下，如下图，我们把所有他们的和求出来就会发现其实和上一道题完全一样了。1234567891011121314151617181920212223242526272829class Solution { public List&lt;List&lt;Integer&gt;&gt; kSmallestPairs(int[] nums1, int[] nums2, int k) { //int[] num; num[0]存num1，num[1]存num2，num[2]存num2的index List&lt;List&lt;Integer&gt;&gt; ans = new LinkedList&lt;&gt;(); if(nums1.length==0 || nums2.length==0 || k==0) return ans; PriorityQueue&lt;int[]&gt; pq = new PriorityQueue&lt;&gt;((a, b)-&gt;{ return a[0]+a[1] - b[0]-b[1]; }); for(int i =0;i&lt;=nums1.length-1&amp;&amp;i&lt;=k-1;i++){ pq.offer(new int[]{nums1[i], nums2[0], 0}); } while(k&gt;0 &amp;&amp; pq.size()!=0){ int[] tmp = pq.poll(); List&lt;Integer&gt; l = new LinkedList&lt;&gt;(); l.add(tmp[0]); l.add(tmp[1]); ans.add(l); k--; if(tmp[2]==nums2.length-1) continue; pq.offer(new int[]{tmp[0], nums2[tmp[2]+1], tmp[2]+1}); } return ans; }} 处理流数据中的Top K问题：system design使用一个hashmap加一个最小堆。HashaMap + PriorityQueue 每次进来的数据先在hashmap中加1。如果： 新进来的数据已经在堆中，调整堆(java的priority queue实现不了，但是这是系统设计题，调整操作在堆中是很简单的，因为只需要去判断一下改变的这个元素和它堆下面的元素的大小关系) 新进来的数据不再堆中 Priority Queue的size小于K，新进来的数据放入最小堆中 Priority Queue的size等于K，我们比较新进来数据在hashmap的value与最小堆在hashmap的value。如果大于，排除最小堆的最小值加入这个新的string，否则什么都不做。 1234HashMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;();PriorityQueue&lt;String&gt; pq = new PriorityQueue&lt;&gt;((a, b)-&gt;{ return map.get(a) - map.get(b);});","link":"/2019/09/13/Leetcode/Top%20K%20problem%E6%80%BB%E7%BB%93/"},{"title":"Word Ladder类型题","text":"Word Ladder I和Word Ladder II两道题给我们的经验： It’s much faster than one-end search indeed as explained in wiki. BFS isn’t equivalent to Queue. Sometimes Set is more accurate representation for nodes of level. (also handy since we need to check if we meet from two ends) It’s safe to share a visited set for both ends since if they meet same string it terminates early. (vis is useful since we cannot remove word from dict due to bidirectional search) It seems like if(set.add()) is a little slower than if(!contains()) then add() but it’s more concise. Word Ladder最简单的单向BFS使用Queue来做的解法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/*127. Word LadderMedium1980932FavoriteShareGiven two words (beginWord and endWord), and a dictionary's word list, find the length of shortest transformation sequence from beginWord to endWord, such that:Only one letter can be changed at a time.Each transformed word must exist in the word list. Note that beginWord is not a transformed word.Note:Return 0 if there is no such transformation sequence.All words have the same length.All words contain only lowercase alphabetic characters.You may assume no duplicates in the word list.You may assume beginWord and endWord are non-empty and are not the same.Example 1:Input:beginWord = &quot;hit&quot;,endWord = &quot;cog&quot;,wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]Output: 5Explanation: As one shortest transformation is &quot;hit&quot; -&gt; &quot;hot&quot; -&gt; &quot;dot&quot; -&gt; &quot;dog&quot; -&gt; &quot;cog&quot;,return its length 5.Example 2:Input:beginWord = &quot;hit&quot;endWord = &quot;cog&quot;wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]Output: 0Explanation: The endWord &quot;cog&quot; is not in wordList, therefore no possible transformation.*/class Solution { public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) { Set&lt;String&gt; set = new HashSet&lt;&gt;(wordList); if(!set.contains(endWord)){ return 0; } Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); queue.offer(beginWord); int count = 1; while(!queue.isEmpty()){ int size = queue.size(); while(size!=0){ String temp = queue.poll(); if(temp.equals(endWord)){ return count; } for(int i = 0;i&lt;=temp.length()-1;i++){ for(char c = 'a';c&lt;='z';c++){ if(temp.charAt(i)!=c){ String newString = temp.substring(0, i)+c+temp.substring(i+1); if(set.contains(newString)){ queue.offer(newString); set.remove(newString);//避免出现环在图中 } } } } size--; } count++; } return 0; }} 使用HashSet来作为Queue的做法 1234567891011121314151617181920212223242526272829303132333435class Solution { public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) { Set&lt;String&gt; set = new HashSet&lt;&gt;(wordList); if(!wordList.contains(endWord)){ return 0; } Set&lt;String&gt; queue = new HashSet&lt;&gt;(); queue.add(beginWord); int count = 1; while(queue.size()!=0){ Set&lt;String&gt; temp = new HashSet&lt;&gt;(); for(String word:queue){ if(word.equals(endWord)){ return count; } for(int i =0;i&lt;=word.length()-1;i++){ for(char c = 'a';c&lt;='z';c++){ if(word.charAt(i)==c) continue; String newString = word.substring(0, i)+c+word.substring(i+1); if(set.contains(newString)){ temp.add(newString); set.remove(newString); } } } } count++; queue = temp; } return 0; }} 进一步提升使用双向BFS来做，双向BFS使用Queue来做BFS就很麻烦了，这个时候使用HashSet就很简单。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution { public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) { Set&lt;String&gt; set = new HashSet&lt;&gt;(wordList); if(!set.contains(endWord)){ return 0; } Set&lt;String&gt; forwardSet = new HashSet&lt;&gt;(); forwardSet.add(beginWord); Set&lt;String&gt; backwardSet = new HashSet&lt;&gt;(); backwardSet.add(endWord); int count = 1; while(!(forwardSet.isEmpty() ||backwardSet.isEmpty())){ if(backwardSet.size()&lt;forwardSet.size()){ Set&lt;String&gt; temp = new HashSet&lt;&gt;(); temp = backwardSet; backwardSet = forwardSet; forwardSet = temp; } Set&lt;String&gt; tmp = new HashSet&lt;&gt;(); for(String word:forwardSet){ if(backwardSet.contains(word)){ return count; } for(int i = 0;i&lt;=word.length()-1;i++){ for(char c='a';c&lt;='z';c++){ if(word.charAt(i)==c) continue; String newString = word.substring(0, i)+c+word.substring(i+1); if(set.contains(newString)){ tmp.add(newString); //和单向不同，这里不用remove from set } } } } count++; forwardSet = tmp; } return 0; }} Word Ladder II 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/*126. Word Ladder IIHard1276216FavoriteShareGiven two words (beginWord and endWord), and a dictionary's word list, find all shortest transformation sequence(s) from beginWord to endWord, such that:Only one letter can be changed at a timeEach transformed word must exist in the word list. Note that beginWord is not a transformed word.Note:Return an empty list if there is no such transformation sequence.All words have the same length.All words contain only lowercase alphabetic characters.You may assume no duplicates in the word list.You may assume beginWord and endWord are non-empty and are not the same.Example 1:Input:beginWord = &quot;hit&quot;,endWord = &quot;cog&quot;,wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]Output:[ [&quot;hit&quot;,&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;cog&quot;], [&quot;hit&quot;,&quot;hot&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]]Example 2:Input:beginWord = &quot;hit&quot;endWord = &quot;cog&quot;wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]Output: []Explanation: The endWord &quot;cog&quot; is not in wordList, therefore no possible transformation.*/class Solution { public List&lt;List&lt;String&gt;&gt; findLadders(String beginWord, String endWord, List&lt;String&gt; wordList) { Map&lt;String, List&lt;String&gt;&gt; graph = buildGraph(beginWord, endWord, wordList); List&lt;List&lt;String&gt;&gt; ans = new LinkedList&lt;&gt;(); System.out.println(graph); List&lt;String&gt; l = new LinkedList&lt;&gt;(); dfs(graph, beginWord, endWord, ans, l); return ans; } private void dfs(Map&lt;String, List&lt;String&gt;&gt; graph, String word, String endWord, List&lt;List&lt;String&gt;&gt; ans, List&lt;String&gt; l){ if(word.equals(endWord)){ l.add(word); ans.add(new LinkedList&lt;&gt;(l)); l.remove(l.size()-1); return; } if(!graph.containsKey(word)){ return; } List&lt;String&gt; tmp = graph.get(word); l.add(word); for(String t:tmp){ dfs(graph, t, endWord, ans, l); } l.remove(l.size()-1); } private Map&lt;String, List&lt;String&gt;&gt; buildGraph(String beginWord, String endWord, List&lt;String&gt; wordList){ Set&lt;String&gt; set = new HashSet&lt;&gt;(wordList); Map&lt;String, List&lt;String&gt;&gt; graph = new HashMap&lt;&gt;(); Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); queue.offer(beginWord); set.remove(beginWord); boolean finished = false; while(!queue.isEmpty() &amp;&amp; finished==false){ int size = queue.size(); Set&lt;String&gt; visited = new HashSet&lt;&gt;();//这里是这道题构造图的关键地方，因为我们不想要出现过的点再次出现的图里面，但是又不能直接删除遇到的newWord，因为在同一层可能两个词的child都是这个newWord，如果直接删除会造成少一条路径，所以我们先把它们放入一个set，等着一层遍历完再一起删掉 while(size&gt;0){ String word = queue.poll(); for(int i =0;i&lt;=word.length()-1;i++){ for(char c = 'a';c&lt;='z';c++){ if(c==word.charAt(i)) continue; String newWord = word.substring(0, i) + c + word.substring(i+1); if(newWord.equals(endWord)){ finished = true; } List&lt;String&gt; neighbors = new LinkedList&lt;&gt;(); if(graph.containsKey(word)){ neighbors = graph.get(word); } if(set.contains(newWord)){ neighbors.add(newWord); graph.put(word, neighbors); } if(set.contains(newWord)&amp;&amp;!visited.contains(newWord)){//这个条件也要格外注意，必须是set有且visited没有的才加入到graph中 queue.offer(newWord); } visited.add(newWord); } } size--; } set.removeAll(visited); } return graph; }}","link":"/2019/11/05/Leetcode/Word%20Ladder%E7%B1%BB%E5%9E%8B%E9%A2%98/"},{"title":"区间问题总结","text":"Interval类型题Interval类型的题目很烧脑，这里尽量总结一下，要多复习。 https://zhuanlan.zhihu.com/p/26657786 这种题的思路是：1.由于本身start和end都是无序的，所以第一步是先要针对start或者end进行排序，具体针对start还是end需要具体问题具体分析，一般来说针对start进行排序的情况比较多；2.对于已经排好序的数组使用greedy https://www.1point3acres.com/bbs/thread-432526-1-1.html我的体验是， 如果能改成类似经典问题的话 [寻找最多non overlapping interval]类型的题目，就是按end排序。 按end排序只&gt; 需要考虑一个情况就是[3,5],[7,8],[1,10]这样。 如果这个是个反例，那得考虑start排序。 646 + 435 + 452 253 + 253 56 + 57 By end 排序：这种题的鼻祖问题是schedule problem，也就是leetcode 646. Maximum Length of Pair Chain。646.Maximum Length of Pair Chain，schedule：schedule问题的思想就是为了能有更多的interval，我们更关心的是interval结束的时间，越早结束代表着我们有更多interval的可能性更大，所以我们将intervals按照结束时间sort。排序结束后，我们就要分析使用greedy进行分析：对于结束时间最早的元素，我们肯定要加到结果的count中；对于结束时间第二早的元素，如果他的开始时间大于第一个元素的结束时间，那么我们也加入结果count并且目前最后结束的时间是第二个元素的结束时间，如果不大于那么我们最后结束时间还是第一个元素的结束时间。依次类推，我们知道需要maintain一个endTime。 123456789101112131415161718class Solution { public int findLongestChain(int[][] pairs) { if(pairs.length==0) return 0; Arrays.sort(pairs, (a, b) -&gt; { return a[1] - b[1]; }); int count = 1; int end = pairs[0][1]; for(int i =1;i&lt;=pairs.length-1;i++){ if(pairs[i][0]&gt;end){ count++; end = pairs[i][1]; } } return count; }} 435.Non-overlapping Intervals: 这道题与schedule problem可以说一模一样，只是改变了问的方式，所以我们可以先求最大可能不overlap的个数，然后size减去这个数就是结果了。 123456789101112131415161718192021class Solution { public int eraseOverlapIntervals(int[][] intervals) { if(intervals.length==0) return 0; Arrays.sort(intervals, (a, b)-&gt;{ return a[1]-b[1]; }); int count = 1; int minEnd = intervals[0][1]; for(int i =1;i&lt;=intervals.length-1;i++){ if(intervals[i][0]&gt;=minEnd){ count++; minEnd = intervals[i][1]; } } return intervals.length-count; }} 452.Minimum Number of Arrows to Burst Balloons: 1234567891011121314151617181920class Solution { public int findMinArrowShots(int[][] points) { if(points.length==0) return 0; Arrays.sort(points, (a, b)-&gt;{ return a[1]-b[1]; }); int count = 1; int minEnd = points[0][1]; for(int i =1;i&lt;=points.length-1;i++){ if(points[i][0]&gt;minEnd){ count++; minEnd = points[i][1]; } } return count; }} By start 排序252.Meeting Rooms：想象一下只有一个房间，肯定是先开始的人先用，后来的人看看房间有没有人，有人说明被占了，没人则可以使用。所以这道题我们按照start time进行排序，然后看有没有重叠既可。 1234567891011121314class Solution { public boolean canAttendMeetings(int[][] intervals) { Arrays.sort(intervals, (a, b)-&gt;{ return a[0] - b[0]; }); for(int i =1;i&lt;=intervals.length-1;i++){ if(intervals[i][0]&lt;intervals[i-1][1]){ return false; } } return true; }} 253.Meeting Rooms II: 这道题和252一样，都是先对start进行排序，因为先来的人肯定先用教室。不同的是这道题可以有多个教室，问题是需要的最少的教室数量。考虑到我们可以有多个教室，并且这些教室的endTime是不同的，所以我们需要maintain一个Priority Queue去记录目前使用的教室的结束时间去最快找到最小的结束时间。 12345678910111213141516171819202122232425class Solution { public int minMeetingRooms(int[][] intervals) { Arrays.sort(intervals, (a, b)-&gt;{ return a[0] - b[0]; }); PriorityQueue&lt;Integer&gt; endTime = new PriorityQueue&lt;&gt;(); for(int[] interval:intervals){ if(endTime.size()==0){ endTime.offer(interval[1]); } else { int minEndTime = endTime.poll(); if(interval[0]&gt;=minEndTime){ endTime.offer(interval[1]); } else { endTime.offer(minEndTime); endTime.offer(interval[1]); } } } return endTime.size(); }} 56.Merge Intervals: 这个题不算可以直接应用scheduling problem的方法。如果你按end排序， 那么最容易举的反例就是 [3,5],[6,7],[1,10]。显然这三个应该归并到一起， 但是因为按照end排序， 这三个反而不会相交。题目是希望找到可以merge起来的所有interval，那某种程度上来说是想找相交的interval的最小起始点和最大终止点。所以这里的做法是按start排序， 然后更新end， 把所有与之相交的interval合并成一个大interval。 12345678910111213141516171819202122232425262728293031class Solution { public int[][] merge(int[][] intervals) { if(intervals.length==0) return intervals; Arrays.sort(intervals, (a, b) -&gt; { return a[0] - b[0]; }); List&lt;int[]&gt; ans = new LinkedList&lt;&gt;(); int start = intervals[0][0]; int end = intervals[0][1]; for(int i =1;i&lt;=intervals.length-1;i++){ if(intervals[i][0]&lt;=end){ end = Math.max(end, intervals[i][1]); } else { ans.add(new int[]{start, end}); start = intervals[i][0]; end = intervals[i][1]; } } ans.add(new int[]{start, end}); int[][] res = new int[ans.size()][2]; for(int i =0;i&lt;=ans.size()-1;i++){ res[i] = ans.get(i); } return res; }} 57.Insert Interval：与56题的思路一样，我们比较newInterval的start和排好序的Interval的end，如果start大于end，说明一定不存在overlap，直接将Interval放入结果中；如果start&lt;=end，代表可能存在overlap，但这道题与56的区别在于这时我们只是知道NewInterval的start小于Interval的end，并不一定存在overlap 12345678910111213141516171819202122232425262728293031class Solution { public int[][] insert(int[][] intervals, int[] newInterval) { List&lt;int[]&gt; ans = new LinkedList&lt;&gt;(); for(int[] interval:intervals){ if(newInterval==null||newInterval[0]&gt;interval[1]){ ans.add(interval); } else { if(newInterval[1]&lt;interval[0]){//如果newInterval的end小于interval的start，那么这种情况是没有overlap的 ans.add(newInterval); ans.add(interval); newInterval=null; } else {//其他情况一定有overlap，画图可以看出来 newInterval[0] = Math.min(newInterval[0], interval[0]); newInterval[1] = Math.max(newInterval[1], interval[1]); } } } if(newInterval!=null){ ans.add(newInterval); } int[][] res = new int[ans.size()][2]; for(int i =0;i&lt;=ans.size()-1;i++){ res[i] = ans.get(i); } return res; }} My Calendar I : 这道题可以brute force去做，但是每次book都需要和所有元素进行比较。一个很好的提升思路是可以从56题中得到思路,使用一个LinkedList存储元素并且按照start进行排序。这时想要没有overlap，条件是插入的新元素的start大于(第一个start小于它的元素的end)，并且新元素的end小于(第一个start大于它的元素的start)。比如我们已经有[(2, 5), (8, 10), (14, 16)]，我们想要插入(9, 13)，我们需要找到9前面的start也就是8，比较8的end与9是否overlap，在找到9后面的start也就是14，比较14与10是否overlap。由此进一步提升，我们可以使用一个binary search tree，tree的每个node都是一个HashMap，key是start，value是end。所以我们可以使用java的TreeMap，这样book的时间复杂度是O(logn)。 如何用一个式子表示两个interval没有overlap：Math.max(start1, start2)&gt;Math.min(end1, end2) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/*729. My Calendar IMedium44629FavoriteShareImplement a MyCalendar class to store your events. A new event can be added if adding the event will not cause a double booking.Your class will have the method, book(int start, int end). Formally, this represents a booking on the half open interval [start, end), the range of real numbers x such that start &lt;= x &lt; end.A double booking happens when two events have some non-empty intersection (ie., there is some time that is common to both events.)For each call to the method MyCalendar.book, return true if the event can be added to the calendar successfully without causing a double booking. Otherwise, return false and do not add the event to the calendar.Your class will be called like this: MyCalendar cal = new MyCalendar(); MyCalendar.book(start, end)Example 1:MyCalendar();MyCalendar.book(10, 20); // returns trueMyCalendar.book(15, 25); // returns falseMyCalendar.book(20, 30); // returns trueExplanation: The first event can be booked. The second can't because time 15 is already booked by another event.The third event can be booked, as the first event takes every time less than 20, but not including 20. Note:The number of calls to MyCalendar.book per test case will be at most 1000.In calls to MyCalendar.book(start, end), start and end are integers in the range [0, 10^9].*/class MyCalendar { TreeMap&lt;Integer, Integer&gt; calendar; public MyCalendar() { calendar = new TreeMap&lt;&gt;(); } public boolean book(int start, int end) { Integer prev = calendar.floorKey(start); Integer next = calendar.ceilingKey(start); if(prev!=null &amp;&amp; calendar.get(prev)&gt;start){ return false; } if(next!=null &amp;&amp; next&lt;end){ return false; } calendar.put(start ,end); return true; }}/** * Your MyCalendar object will be instantiated and called as such: * MyCalendar obj = new MyCalendar(); * boolean param_1 = obj.book(start,end); */ My Calendar II: 相当于求overlap的overlap。如何用一个式子表示两个interval没有overlap：Math.max(start1, start2)&gt;Math.min(end1, end2) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/*731. My Calendar IIMedium44467FavoriteShareImplement a MyCalendarTwo class to store your events. A new event can be added if adding the event will not cause a triple booking.Your class will have one method, book(int start, int end). Formally, this represents a booking on the half open interval [start, end), the range of real numbers x such that start &lt;= x &lt; end.A triple booking happens when three events have some non-empty intersection (ie., there is some time that is common to all 3 events.)For each call to the method MyCalendar.book, return true if the event can be added to the calendar successfully without causing a triple booking. Otherwise, return false and do not add the event to the calendar.Your class will be called like this: MyCalendar cal = new MyCalendar(); MyCalendar.book(start, end)Example 1:MyCalendar();MyCalendar.book(10, 20); // returns trueMyCalendar.book(50, 60); // returns trueMyCalendar.book(10, 40); // returns trueMyCalendar.book(5, 15); // returns falseMyCalendar.book(5, 10); // returns trueMyCalendar.book(25, 55); // returns trueExplanation: The first two events can be booked. The third event can be double booked.The fourth event (5, 15) can't be booked, because it would result in a triple booking.The fifth event (5, 10) can be booked, as it does not use time 10 which is already double booked.The sixth event (25, 55) can be booked, as the time in [25, 40) will be double booked with the third event;the time [40, 50) will be single booked, and the time [50, 55) will be double booked with the second event. Note:The number of calls to MyCalendar.book per test case will be at most 1000.In calls to MyCalendar.book(start, end), start and end are integers in the range [0, 10^9].*/class MyCalendarTwo { List&lt;int[]&gt; calendar; List&lt;int[]&gt; overlap; public MyCalendarTwo() { calendar = new LinkedList&lt;&gt;(); overlap = new LinkedList&lt;&gt;(); } public boolean book(int start, int end) { for(int[] c:calendar){ if(Math.max(c[0], start)&lt;Math.min(c[1], end)){ int overlapStart = Math.max(c[0], start); int overlapEnd = Math.min(c[1], end); for(int[] o:overlap){ if(Math.max(o[0], overlapStart)&lt;Math.min(o[1], overlapEnd )){ overlap.clear(); return false; } } overlap.add(new int[]{overlapStart, overlapEnd}); } } calendar.add(new int[]{start, end}); return true; }}/** * Your MyCalendarTwo object will be instantiated and called as such: * MyCalendarTwo obj = new MyCalendarTwo(); * boolean param_1 = obj.book(start,end); */","link":"/2019/09/13/Leetcode/%E5%8C%BA%E9%97%B4%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"单调栈问题总结","text":"Monotonic Stack问题总结单调栈问题的思路就是栈中的元素都是单调增或者单调减的，当我们想要新加入元素到栈的时候，我们回去查看是否符合单调标准，不符合的弹出。https://blog.csdn.net/qq_17550379/article/details/86519771 Next Greater Element I：这道题是单调栈的代表问题与基础问题，是解决后面复杂问题的工具，也就是让我们找某个元素右侧最近的大于自身的元素，由于在遇到比自身大的元素之前可能中间会与其他元素，而这些其他元素的信息我们也是需要的，所以自然而然可以联想到栈的性质。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/*496. Next Greater Element IEasy9611543FavoriteShareYou are given two arrays (without duplicates) nums1 and nums2 where nums1’s elements are subset of nums2. Find all the next greater numbers for nums1's elements in the corresponding places of nums2.The Next Greater Number of a number x in nums1 is the first greater number to its right in nums2. If it does not exist, output -1 for this number.Example 1:Input: nums1 = [4,1,2], nums2 = [1,3,4,2].Output: [-1,3,-1]Explanation: For number 4 in the first array, you cannot find the next greater number for it in the second array, so output -1. For number 1 in the first array, the next greater number for it in the second array is 3. For number 2 in the first array, there is no next greater number for it in the second array, so output -1.Example 2:Input: nums1 = [2,4], nums2 = [1,2,3,4].Output: [3,-1]Explanation: For number 2 in the first array, the next greater number for it in the second array is 3. For number 4 in the first array, there is no next greater number for it in the second array, so output -1.*/class Solution { public int[] nextGreaterElement(int[] nums1, int[] nums2) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int num:nums2){ while(!stack.isEmpty() &amp;&amp; stack.peek()&lt;num){ map.put(stack.peek(), num); stack.pop(); } stack.push(num); } int[] ans = new int[nums1.length]; for(int i =0;i&lt;=ans.length-1;i++){ if(map.containsKey(nums1[i])){ ans[i] = map.get(nums1[i]); } else { ans[i] = -1; } } return ans; }} Next Greater Element II：这道题与前一道思路基本一致，有两点不同：保存的是index因为会有duplicates；array是一个环，所以遍历两遍。 12345678910111213141516171819202122232425262728293031323334353637383940414243/*503. Next Greater Element IIMedium86049FavoriteShareGiven a circular array (the next element of the last element is the first element of the array), print the Next Greater Number for every element. The Next Greater Number of a number x is the first greater number to its traversing-order next in the array, which means you could search circularly to find its next greater number. If it doesn't exist, output -1 for this number.Example 1:Input: [1,2,1]Output: [2,-1,2]Explanation: The first 1's next greater number is 2; The number 2 can't find next greater number; The second 1's next greater number needs to search circularly, which is also 2.Note: The length of given array won't exceed 10000.*/class Solution { public int[] nextGreaterElements(int[] nums) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); int[] ans = new int[nums.length]; Arrays.fill(ans, -1); for(int i=0;i&lt;=nums.length-1;i++){ while(!stack.isEmpty() &amp;&amp; nums[stack.peek()]&lt;nums[i]){ ans[stack.pop()] = nums[i]; } stack.push(i); } for(int i=0;i&lt;=nums.length-1;i++){ while(!stack.isEmpty() &amp;&amp; nums[stack.peek()]&lt;nums[i]){ ans[stack.pop()] = nums[i]; } stack.push(i); } return ans; }} 有了上面两道题的铺垫，我们找到了单调栈解法这一工具，下面的题虽然看起来很复杂，但如果我们运用单调栈会将它们变得很简单。 Trapping Rain Water：42与84属于镜像问题，一个是找某个index的最近的两边比他大的，一个是找某个index的最近的两边比他小的。 1234567891011121314151617181920212223242526272829303132333435363738394041/*42. Trapping Rain WaterHard472783FavoriteShareGiven n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining.The above elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped. Thanks Marcos for contributing this image!Example:Input: [0,1,0,2,1,0,1,3,2,1,2,1]Output: 6*/class Solution { public int trap(int[] height) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); stack.push(-1); int ans = 0; for(int i =0;i&lt;=height.length-1;i++){ while(stack.peek()!=-1 &amp;&amp; height[i]&gt;height[stack.peek()]){ int index = stack.pop(); if(stack.peek()!=-1){ int minHeight = Math.min(height[stack.peek()], height[i]); int waterHeight = minHeight - height[index]; ans = ans + waterHeight*(i-1-(stack.peek()+1)+1); } } stack.push(i); } return ans; }} 84.Largest Rectangle in Histogram：我们在栈中储存高度单调递增的方块的索引，当我们遇到比栈顶小的方块，说明我们找到了右边界(就是遇到的这个比栈顶小的方块)，左边界(栈先pop出本方块，此时的peek是左边界)，所以我们就可以求得以这个方块高度为高的面积大小。由于我们要查看栈顶来看我们的左侧边界，所以我们需要开率边界条件，也就是现在栈里面加一个-1。 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*84. Largest Rectangle in HistogramHard242463FavoriteShareGiven n non-negative integers representing the histogram's bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Above is a histogram where width of each bar is 1, given height = [2,1,5,6,2,3]. The largest rectangle is shown in the shaded area, which has area = 10 unit.*/class Solution { public int largestRectangleArea(int[] heights) { int ans = 0; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); stack.push(-1); for(int i = 0;i&lt;=heights.length-1;i++){ while(stack.peek()!=-1 &amp;&amp; heights[i]&lt;heights[stack.peek()]){ int index = stack.pop(); ans = Math.max(ans , heights[index]*(i-1-(stack.peek()+1)+1)); } stack.push(i); } while(stack.peek()!=-1){ int index = stack.pop(); ans = Math.max(ans, heights[index]*(heights.length-1-(stack.peek()+1)+1)); } return ans; }} Minimum Cost Tree From Leaf Values：拿到这道题很容易想到变成dp去做，但那样时间空间复杂度都很高，我们可以使用greedy，这篇文章里面讲的很好。https://leetcode.com/problems/minimum-cost-tree-from-leaf-values/discuss/339959/One-Pass-O(N)-Time-and-Space12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/*1130. Minimum Cost Tree From Leaf ValuesMedium28629FavoriteShareGiven an array arr of positive integers, consider all binary trees such that:Each node has either 0 or 2 children;The values of arr correspond to the values of each leaf in an in-order traversal of the tree. (Recall that a node is a leaf if and only if it has 0 children.)The value of each non-leaf node is equal to the product of the largest leaf value in its left and right subtree respectively.Among all possible binary trees considered, return the smallest possible sum of the values of each non-leaf node. It is guaranteed this sum fits into a 32-bit integer. Example 1:Input: arr = [6,2,4]Output: 32Explanation:There are two possible trees. The first has non-leaf node sum 36, and the second has non-leaf node sum 32. 24 24 / \\ / \\ 12 4 6 8 / \\ / \\6 2 2 4 Constraints:2 &lt;= arr.length &lt;= 401 &lt;= arr[i] &lt;= 15It is guaranteed that the answer fits into a 32-bit signed integer (ie. it is less than 2^31).*/class Solution { public int mctFromLeafValues(int[] arr) { Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); stack.push(Integer.MAX_VALUE); int ans = 0; for(int number:arr){ while(stack.peek()!=Integer.MAX_VALUE &amp;&amp; number&gt;=stack.peek()){ int num = stack.pop(); ans = ans + num * Math.min(number, stack.peek()); } stack.push(number); } while(stack.size()&gt;2){ ans = ans + stack.pop()*stack.peek(); } return ans; }} 由以上这三道题可以看出来，当我们需要同时求左侧和右侧的第一个最大(最小)值的时候，我们需要先在栈里面加入一个边界元素(也就是左侧没有更大(更小)的时候该怎么办)。还有这种问题不要忘记考虑最后剩在stack的元素。 Sliding Window Maximum: 这道题本质上也是单调栈/队列，总共有三个操作(1. Deque的头元素在k的范围内，否则poll 2. Deque的尾元素如果小于遇到的新元素，poll 3. 在Deque尾部加入新元素)。经过这三个操作我们可以确保Deque中的元素都在sliding window的范围内且是单调的，所以这个时候我们取头元素即是该sliding window的最大值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*239. Sliding Window MaximumHard2278134FavoriteShareGiven an array nums, there is a sliding window of size k which is moving from the very left of the array to the very right. You can only see the k numbers in the window. Each time the sliding window moves right by one position. Return the max sliding window.Example:Input: nums = [1,3,-1,-3,5,3,6,7], and k = 3Output: [3,3,5,5,6,7] Explanation: Window position Max--------------- -----[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7Note:You may assume k is always valid, 1 ≤ k ≤ input array's size for non-empty array.Follow up:Could you solve it in linear time?*/class Solution { public int[] maxSlidingWindow(int[] nums, int k) { if(nums==null || nums.length==0){ return new int[0]; } Deque&lt;Integer&gt; dq = new ArrayDeque&lt;&gt;(); int[] ans = new int[nums.length-k+1]; for(int i = 0;i&lt;=nums.length-1;i++){ while(dq.peekFirst()!=null &amp;&amp; dq.peekFirst()&lt;i-k+1){ dq.pollFirst(); } while(dq.peekLast()!=null &amp;&amp; nums[dq.peekLast()]&lt;nums[i]){ dq.pollLast(); } dq.offer(i); if(i&gt;=k-1){ ans[i-k+1] = nums[dq.peekFirst()]; } } return ans; }}","link":"/2019/10/25/Leetcode/%E5%8D%95%E8%B0%83%E6%A0%88%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"},{"title":"约瑟夫环问题","text":"约瑟夫环https://blog.csdn.net/u011500062/article/details/72855826","link":"/2019/10/03/Leetcode/%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AF%E9%97%AE%E9%A2%98/"},{"title":"股票买卖问题","text":"买卖股票问题总结买卖股票问题是dp的代表类型题目。 Best Time to Buy and Sell Stock: 这道题看起来很简单，但其实之中蕴含dp的思想。我们可以将问题拆解为两个数组的dp问题：low[i]代表进行到第i天为止的最低股票价格，res[i]代表到第i天为止最大获利。所以 low[i] = Math.min(low[i], low[i-1]) res[i] = Math.max(res[i], price[i]-low[i]) 当然这道题直接想就可以很简单的做出来，但这种dp的思路很重要。这道题还可以转化成53题maximum subarray，也就是转化成从第二天开始的profit情况 1234567891011class Solution { public int maxProfit(int[] prices) { int minPrice = Integer.MAX_VALUE; int res = 0; for(int price:prices){ minPrice = Math.min(minPrice, price); res = Math.max(res, price-minPrice); } return res; }} Best Time to Buy and Sell Stock II：这道题有非常非常简单的做法：因为我们有无限次的transaction次数，所以只要后一天的价格比前一天高，我们就买，这非常合理，因为加入我们在买股票也会这么选择。 当然，这道题更重要的一点是它与188题一脉相承，思路非常类似，只不过188相当于多了一个限制条件，所以我们需要转为二维数组，但本质上两道题还是基本一样，dp的思想也非常的值得深思！ 第i天不卖：dp[i] = dp[i-1] 第i天卖，那么可以在前面任意一天买，所以我们需要把这些都算出来求最大值(O(n^2))。然后有一种很巧妙的优化方式(O(n)))，188也用了一样的思路，主要是通过观察迭代方程得到的：dp[i] = max(price[i]-price[m]+dp[m]), m is from 0 to i-1 ===&gt; initalize tempValue = dp[0]-price[0]；dp[i] = price[i] + tempValue;tempValue = max(tempValue, dp[i] - price[i]); 12345678910111213141516171819202122232425class Solution { /* 1. dp[i] = dp[i-1] 2. dp[i] = max(price[i]-price[m]+dp[m]), m is from 0 to i-1 ===&gt; initalize tempValue = dp[0]-price[0] dp[i] = price[i] + tempValue; tempValue = max(tempValue, dp[i] - price[i]); */ public int maxProfit(int[] prices) { int n = prices.length; if(n==0) return 0; int[] dp = new int[n+1]; int tmp = dp[1] - prices[0]; for(int i =1;i&lt;=dp.length-1;i++){ dp[i] = Math.max(dp[i-1], prices[i-1]+tmp); tmp = Math.max(tmp, dp[i]-prices[i-1]); } return dp[n]; }} Best Time to Buy and Sell Stock IV： 有了122的加持，再做188其实就会发现思路完全一样。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Solution { public int maxProfit(int k, int[] prices) { /* 0 3 2 6 5 0 3 0 0 0 0 0 0 0 0 1 0 0 0 4 4 4 4 2 0 0 0 4 4 4 7 recursive function 1. if we do not do transaction: dp[i][j] = dp[i][j-1] 2. if we do transaction at this day: dp[i][j] = max(price[j] - price[m] + dp[i-1][m]) m is from 1 to j-1 ==&gt; dp[i][j] = price[j]+tempMax; tempMax = Math.max(tempMax, dp[i-1][j]-price[j]); max(1, 2) */ int n = prices.length; if(n==0) return 0; if(k&gt;n/2){ return quickSolve(prices); } int[][] dp = new int[k+1][n+1]; for(int i =0;i&lt;=k;i++){ dp[i][0] = 0; } for(int i = 0;i&lt;=n;i++){ dp[0][i] = 0; } for(int i =1;i&lt;=k;i++){ int maxTemp = dp[i][0]-prices[0]; for(int j = 1;j&lt;=n;j++){ int value1 = dp[i][j-1]; int value2 = prices[j-1] + maxTemp; maxTemp = Math.max(maxTemp, dp[i-1][j]-prices[j-1]); dp[i][j] = Math.max(value1 , value2); } } return dp[k][n]; } private int quickSolve(int[] prices){ int ans = 0; for(int i =1;i&lt;=prices.length-1;i++){ if(prices[i]-prices[i-1]&gt;0) ans = ans+prices[i]-prices[i-1]; } return ans; }}","link":"/2019/10/05/Leetcode/%E8%82%A1%E7%A5%A8%E4%B9%B0%E5%8D%96%E9%97%AE%E9%A2%98/"},{"title":"背包问题总结","text":"背包问题主要分为01背包和完全背包问题。思路上转载from背包九讲。 01背包题目有N件物品和一个容量为V的背包。第i件物品的费用是c[i]，价值是w[i]。求解将哪些物品装入背包可使价值总和最大。 基本思路这是最基础的背包问题，特点是：每种物品仅有一件，可以选择放或不放。用子问题定义状态：即f[i][v]表示前i件物品恰放入一个容量为v的背包可以获得的最大价值。则其状态转移方程便是：f[i][v]=max{f[i-1][v],f[i-1][v-c[i]]+w[i]}。这个方程非常重要，基本上所有跟背包相关的问题的方程都是由它衍生出来的。所以有必要将它详细解释一下：“将前i件物品放入容量为v的背包中”这个子问题，若只考虑第i件物品的策略（放或不放），那么就可以转化为一个只牵扯前i-1件物品的问题。如果不放第i件物品，那么问题就转化为“前i-1件物品放入容量为v的背包中”，价值为f[i-1][v]；如果放第i件物品，那么问题就转化为“前i-1件物品放入剩下的容量为v-c[i]的背包中”，此时能获得的最大价值就是f[i-1][v-c[i]]再加上通过放入第i件物品获得的价值w[i]。 优化空间复杂度以上方法的时间和空间复杂度均为O(VN)，其中时间复杂度应该已经不能再优化了，但空间复杂度却可以优化到O。先考虑上面讲的基本思路如何实现，肯定是有一个主循环i=1..N，每次算出来二维数组f[i][0..V]的所有值。那么，如果只用一个数组f[0..V]，能不能保证第i次循环结束后f[v]中表示的就是我们定义的状态f[i][v]呢？f[i][v]是由f[i-1][v]和f[i-1][v-c[i]]两个子问题递推而来，能否保证在推f[i][v]时（也即在第i次主循环中推f[v]时）能够得到f[i-1][v]和f[i-1][v-c[i]]的值呢？事实上，这要求在每次主循环中我们以v=V..0的顺序推f[v]，这样才能保证推f[v]时f[v-c[i]]保存的是状态f[i-1][v-c[i]]的值。伪代码如下： 123for i=1..N for v=V..0 f[v]=max{f[v],f[v-c[i]]+w[i]}; 其中的f[v]=max{f[v],f[v-c[i]]}一句恰就相当于我们的转移方程f[i][v]=max{f[i-1][v],f[i-1][v-c[i]]}，因为现在的f[v-c[i]]就相当于原来的f[i-1][v-c[i]]。如果将v的循环顺序从上面的逆序改成顺序的话，那么则成了f[i][v]由f[i][v-c[i]]推知，与本题意不符，但它却是另一个重要的背包问题P02最简捷的解决方案，故学习只用一维数组解01背包问题是十分必要的。 初始化的细节问题我们看到的求最优解的背包问题题目中，事实上有两种不太相同的问法。有的题目要求“恰好装满背包”时的最优解，有的题目则并没有要求必须把背包装满。一种区别这两种问法的实现方法是在初始化的时候有所不同。如果是第一种问法，要求恰好装满背包，那么在初始化时除了f[0]为0其它f[1..V]均设为-∞，这样就可以保证最终得到的f[N]是一种恰好装满背包的最优解。如果并没有要求必须把背包装满，而是只希望价格尽量大，初始化时应该将f[0..V]全部设为0。为什么呢？可以这样理解：初始化的f数组事实上就是在没有任何物品可以放入背包时的合法状态。如果要求背包恰好装满，那么此时只有容量为0的背包可能被价值为0的nothing“恰好装满”，其它容量的背包均没有合法的解，属于未定义的状态，它们的值就都应该是-∞了。如果背包并非必须被装满，那么任何容量的背包都有一个合法解“什么都不装”，这个解的价值为0，所以初始时状态的值也就全部为0了。这个小技巧完全可以推广到其它类型的背包问题，后面也就不再对进行状态转移之前的初始化进行讲解。 实战Lintcode 92. Backpack：01背包，背包不含价值，求背包能装的最大量。这是最简单的01背包问题，状态转移方程是：W[i][j] = max(W[i-1][j], W[i-1][j-A[i]]+a[i])时间空间复杂度都是O(mn) 1234567891011121314151617181920212223242526272829303132333435363738394041/*Given n items with size Ai, an integer m denotes the size of a backpack. How full you can fill this backpack?Example 1: Input: [3,4,8,5], backpack size=10 Output: 9Example 2: Input: [2,3,5,7], backpack size=12 Output: 12*/public class Solution { /** * @param m: An integer m denotes the size of a backpack * @param A: Given n items with size A[i] * @return: The maximum size */ public int backPack(int m, int[] A) { // write your code here int len = A.length; if(A==null || len==0){ return 0; } int[][] dp = new int[len+1][m+1]; for(int i = 0;i&lt;=len;i++){ dp[i][0] = 0; } for(int i = 0;i&lt;=m;i++){ dp[0][i] = 0; } for(int i = 1;i&lt;=len;i++){ for(int j = 1;j&lt;=m;j++){ int buyValue = j-A[i-1]&gt;=0?(dp[i-1][j-A[i-1]]+A[i-1]):0; dp[i][j] = Math.max(dp[i-1][j], buyValue); } } return dp[len][m]; }} 可以进一步优化时间复杂度，从状态转移方程中我们可以看到，每一个W[i][j]其实只和W[i-1][j]及W[i-1][j-A[i]]有关，也就是说与上一行的左侧有关，所以如果我们只想用一个一维数组而不是二维数组的话，我们应该从数组的尾部不断向头部进行计算，这样保证我们每次拿到的都是i-1的值。这样空间复杂度减为O(n)。 12345678910111213141516171819202122public class Solution { /** * @param m: An integer m denotes the size of a backpack * @param A: Given n items with size A[i] * @return: The maximum size */ public int backPack(int m, int[] A) { // write your code here if(A==null || A.length==0) return 0; int len = A.length; int[] dp = new int[m+1]; dp[0] = 0; for(int i = 1;i&lt;=len;i++){ for(int j = m;j&gt;=1;j--){ int buyValue = j-A[i-1]&gt;=0?(dp[j-A[i-1]]+A[i-1]):0; dp[j] = Math.max(dp[j], buyValue); } } return dp[m]; }} Lintcode 125. Backpack II：与上一道题基本完全相同，只不过多加了一个商品的价值，求的是最大的商品价值。状态转移方程是：W[i][j] = max(W[i-1][j], W[i-1][j-A[i]]+V[i]) 1234567891011121314151617181920212223242526public class Solution { /** * @param m: An integer m denotes the size of a backpack * @param A: Given n items with size A[i] * @param V: Given n items with value V[i] * @return: The maximum value */ public int backPackII(int m, int[] A, int[] V) { // write your code here if(A==null || A.length==0){ return 0; } int len = A.length; int[] dp = new int[m+1]; dp[0] = 0; for(int i = 1;i&lt;=len;i++){ for(int j = m;j&gt;=1;j--){ int buyValue = j-A[i-1]&gt;=0?dp[j-A[i-1]]+V[i-1]:0; dp[j] = Math.max(dp[j], buyValue); } } return dp[m]; }} Partition Equal Subset Sum: 这道题被转化为：总重量为sum/2，能装的最大重量的01背包问题，与第一题相同。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/*416. Partition Equal Subset SumMedium162750FavoriteShareGiven a non-empty array containing only positive integers, find if the array can be partitioned into two subsets such that the sum of elements in both subsets is equal.Note:Each of the array element will not exceed 100.The array size will not exceed 200. Example 1:Input: [1, 5, 11, 5]Output: trueExplanation: The array can be partitioned as [1, 5, 5] and [11]. Example 2:Input: [1, 2, 3, 5]Output: falseExplanation: The array cannot be partitioned into equal sum subsets.*/class Solution { public boolean canPartition(int[] nums) { int sum = 0; for(int num:nums){ sum += num; } if(sum%2!=0){ return false; } int partitionSum = sum/2; int max = partitionSum + 1; int len = nums.length; int[] dp = new int[partitionSum+1]; dp[0] = 0; for(int i = 1;i&lt;=dp.length-1;i++){ dp[i] = 0; } for(int i = 1;i&lt;=len;i++){ for(int j = partitionSum;j&gt;=1;j--){ int value = j&gt;=nums[i-1]?(dp[j-nums[i-1]]+nums[i-1]):0; dp[j] = Math.max(value, dp[j]); } } if(dp[partitionSum]==partitionSum){ return true; } return false; }} Target Sum : 这道题可以转化成01背包来做。https://leetcode.com/problems/target-sum/discuss/97334/Java-(15-ms)-C%2B%2B-(3-ms)-O(ns)-iterative-DP-solution-using-subset-sum-with-explanation 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/*494. Target SumMedium172081FavoriteShareYou are given a list of non-negative integers, a1, a2, ..., an, and a target, S. Now you have 2 symbols + and -. For each integer, you should choose one from + and - as its new symbol.Find out how many ways to assign symbols to make sum of integers equal to target S.Example 1:Input: nums is [1, 1, 1, 1, 1], S is 3. Output: 5Explanation: -1+1+1+1+1 = 3+1-1+1+1+1 = 3+1+1-1+1+1 = 3+1+1+1-1+1 = 3+1+1+1+1-1 = 3There are 5 ways to assign symbols to make the sum of nums be target 3.Note:The length of the given array is positive and will not exceed 20.The sum of elements in the given array will not exceed 1000.Your output answer is guaranteed to be fitted in a 32-bit integer.*/class Solution { public int findTargetSumWays(int[] nums, int S) { int sum = 0; for(int num:nums){ sum = sum + num; } if((sum+S)%2!=0){ return 0; } if(sum&lt;S){ return 0; } int backpack = (sum+S)/2; int len = nums.length; int[] dp = new int[backpack+1]; dp[0] = 1; for(int i = 1;i&lt;=len;i++){ for(int j = backpack;j&gt;=0;j--){ int value = j&gt;=nums[i-1]?dp[j-nums[i-1]]:0; dp[j] = value + dp[j]; } } return dp[backpack]; }} Ones and Zeroes : 01背包问题 完全背包题目有N种物品和一个容量为V的背包，每种物品都有无限件可用。第i种物品的费用是c[i]，价值是w[i]。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 基本思路这个问题非常类似于01背包问题，所不同的是每种物品有无限件。也就是从每种物品的角度考虑，与它相关的策略已并非取或不取两种，而是有取0件、取1件、取2件……等很多种。如果仍然按照解01背包时的思路，令f[i][v]表示前i种物品恰放入一个容量为v的背包的最大权值。仍然可以按照每种物品不同的策略写出状态转移方程，像这样：f[i][v]=max{f[i-1][v-k*c[i]]+k*w[i]|0&lt;=k*c[i]&lt;=v}，这跟01背包问题一样有O(VN)个状态需要求解，但求解每个状态的时间已经不是常数了，求解状态f[i][v]的时间是O(v/c[i])，总的复杂度可以认为是O(V*Σ(V/c[i]))，是比较大的。将01背包问题的基本思路加以改进，得到了这样一个清晰的方法。这说明01背包问题的方程的确是很重要，可以推及其它类型的背包问题。但我们还是试图改进这个复杂度。 转化为01背包问题求解既然01背包问题是最基本的背包问题，那么我们可以考虑把完全背包问题转化为01背包问题来解。最简单的想法是，考虑到第i种物品最多选V/c[i]件，于是可以把第i种物品转化为V/c[i]件费用及价值均不变的物品，然后求解这个01背包问题。这样完全没有改进基本思路的时间复杂度，但这毕竟给了我们将完全背包问题转化为01背包问题的思路：将一种物品拆成多件物品。更高效的转化方法是：把第i种物品拆成费用为c[i]*2^k、价值为w[i]*2^k的若干件物品，其中k满足c[i]*2^k&lt;=V。这是二进制的思想，因为不管最优策略选几件第i种物品，总可以表示成若干个2^k件物品的和。这样把每种物品拆成O(log V/c[i])件物品，是一个很大的改进。但我们有更优的O(VN)的算法。 O(VN)的算法这个算法使用一维数组，先看伪代码： 123for i=1..N for v=0..V f[v]=max{f[v],f[v-cost]+weight} 你会发现，这个伪代码与P01的伪代码只有v的循环次序不同而已。为什么这样一改就可行呢？首先想想为什么P01中要按照v=V..0的逆序来循环。这是因为要保证第i次循环中的状态f[i][v]是由状态f[i-1][v-c[i]]递推而来。换句话说，这正是为了保证每件物品只选一次，保证在考虑“选入第i件物品”这件策略时，依据的是一个绝无已经选入第i件物品的子结果f[i-1][v-c[i]]。而现在完全背包的特点恰是每种物品可选无限件，所以在考虑“加选一件第i种物品”这种策略时，却正需要一个可能已选入第i种物品的子结果f[i][v-c[i]]，所以就可以并且必须采用v=0..V的顺序循环。这就是这个简单的程序为何成立的道理。 实战 Coin Change: 完全背包问题，同时要注意初始化思路(见前面01背包的总结)。 未优化写法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*322. Coin ChangeMedium243987FavoriteShareYou are given coins of different denominations and a total amount of money amount. Write a function to compute the fewest number of coins that you need to make up that amount. If that amount of money cannot be made up by any combination of the coins, return -1.Example 1:Input: coins = [1, 2, 5], amount = 11Output: 3 Explanation: 11 = 5 + 5 + 1Example 2:Input: coins = [2], amount = 3Output: -1Note:You may assume that you have an infinite number of each kind of coin.*/class Solution { public int coinChange(int[] coins, int amount) { if(coins==null || coins.length==0){ return 0; } int max = amount+1; int len = coins.length; int[][] dp = new int[len+1][amount+1]; for(int i = 0;i&lt;=len;i++){ dp[i][0] = 0; } for(int i = 1;i&lt;=amount;i++){ dp[0][i] = max; } for(int i = 1;i&lt;=len;i++){ for(int j = 1;j&lt;=amount;j++){ int value = (j-coins[i-1]&gt;=0)?(dp[i][j-coins[i-1]]+1) : max; dp[i][j] = Math.min(value, dp[i-1][j]); } } if(dp[len][amount]&lt;max){ return dp[len][amount]; } return -1; }} 空间复杂度优化后的写法 123456789101112131415161718192021222324252627class Solution { public int coinChange(int[] coins, int amount) { if(coins==null || coins.length==0){ return 0; } int max = amount+1; int len = coins.length; int[] dp = new int[amount+1]; dp[0] = 0; for(int i = 1;i&lt;=dp.length-1;i++){ dp[i] = max; } for(int i = 1;i&lt;=len;i++){ for(int j = 1;j&lt;=amount;j++){ int value = (j&gt;=coins[i-1]?(dp[j-coins[i-1]]):max)+1; dp[j] = Math.min(value, dp[j]); } } if(dp[amount]&lt;max){ return dp[amount]; } return -1; }}","link":"/2019/11/09/Leetcode/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"C","slug":"C","link":"/tags/C/"},{"name":"Computer Network","slug":"Computer-Network","link":"/tags/Computer-Network/"},{"name":"Host file","slug":"Host-file","link":"/tags/Host-file/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Unicode","slug":"Unicode","link":"/tags/Unicode/"},{"name":"Encode","slug":"Encode","link":"/tags/Encode/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"Angular","slug":"Angular","link":"/tags/Angular/"},{"name":"Javascript","slug":"Javascript","link":"/tags/Javascript/"},{"name":"CSS","slug":"CSS","link":"/tags/CSS/"}],"categories":[{"name":"BQ","slug":"BQ","link":"/categories/BQ/"},{"name":"System Design","slug":"System-Design","link":"/categories/System-Design/"},{"name":"Basics","slug":"Basics","link":"/categories/Basics/"},{"name":"Distributed System","slug":"Distributed-System","link":"/categories/Distributed-System/"},{"name":"Backend","slug":"Backend","link":"/categories/Backend/"},{"name":"Frontend","slug":"Frontend","link":"/categories/Frontend/"},{"name":"Leetcode","slug":"Leetcode","link":"/categories/Leetcode/"}]}